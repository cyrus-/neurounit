{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Assumptions about this code:\n",
    "The NB was launched with a command that mounts two volumes inside a docker container. \n",
    "In the future invocation of this script will be simplified greatly. NU is from a specific fork and branch -b results https://github.com/russelljjarvis/neuronunit \n",
    "BluePyOpt is also from a specific fork and branch: -b elitism https://github.com/russelljjarvis/BluePyOpt\n",
    "\n",
    "Below BASH code for Ubuntu host:\n",
    "\n",
    "``` bash\n",
    "cd ~/git/neuronunit; sudo docker run -it -v `pwd`:/home/jovyan/neuronunit -v ~/git/BluePyOpt:/home/jovyan/BluePyOpt neuronunit-optimization /bin/bash'\n",
    "```\n",
    "\n",
    "## Parallel Environment.\n",
    "Parallelisation module: dask distributed.\n",
    "\n",
    "\n",
    "# Bootstrap the ipython cluster via operating system shell utils:\n",
    "This notebook may need a kernel restart and run before it runs to completion for reasons that are unclear. Wait about 15 seconds between each kernel restart.\n",
    "\n",
    "Additionally to facilitate execution of this script, it may be necessary to navigate to ipython-clusters under the juptyer launchpad webpage and select an ipython cluster of any size using the drop down fields.\n",
    "\n",
    "Trusting the notebook is necessary when jupyter is run by network forwarding through Docker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('jupyter trust test_ga_versus_grid.ipynb'); #suppress the untrusted notebook warning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################\n",
    "# GA parameters:\n",
    "about 25*15=375 models will be made, excluding rheobase search.\n",
    "################\n",
    "\n",
    "\n",
    "# Choice of selection criteria is important. \n",
    "Here we use BluepyOpts IBEA, such that it can be compared to NSGA2.\n",
    "\n",
    "https://link.springer.com/article/10.1007/s00500-005-0027-5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MU = 10; NGEN = 10; CXPB = 0.9\n",
    "USE_CACHED_GA = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "################\n",
    "# Grid search parameters:\n",
    "$ 2^{10}=1024 $ models, will be made excluding rheobase search\n",
    "################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "npoints = 2\n",
    "nparams = 10\n",
    "from neuronunit.optimization.model_parameters import model_params\n",
    "provided_keys = list(model_params.keys())\n",
    "USE_CACHED_GS = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An oppurtunity to improve grid search, by increasing resolution of search intervals given a first pass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "REFINE_GRID = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/neuronunit/neuronunit/optimization/nsga_parallel.py:6: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/opt/conda/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/opt/conda/lib/python3.5/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 478, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n",
      "    super(ZMQIOLoop, self).start()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tornado/ioloop.py\", line 888, in start\n",
      "    handler_func(fd_obj, events)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2739, in run_cell\n",
      "    self.events.trigger('post_run_cell')\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/events.py\", line 73, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/ipykernel/pylab/backend_inline.py\", line 160, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/IPython/core/pylabtools.py\", line 308, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/matplotlib/pyplot.py\", line 232, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/matplotlib/__init__.py\", line 1305, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/opt/conda/lib/python3.5/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/opt/conda/lib/python3.5/site-packages/matplotlib/backends/__init__.py\", line 14, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use('agg')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Rheobase cached data value for from AIBS dataset 354190013\n",
      "attempting to recover from pickled file\n",
      "['k', 'C', 'd', 'a', 'v0', 'vr', 'vpeak', 'b', 'vt', 'c']\n",
      "[0.00063000000000000003, 9.0000004500000001e-05, 0.050000000000000003, 0.0, -75.0, -75.0, 30.0, -5.0000000000000001e-09, -50.0, -60.0]\n",
      "[0.0014, 0.0001100000055, 0.20000000000000001, 0.94499999999999995, -45.0, -50.0, 40.0, -2.5000000000000001e-09, -30.0, -55.0]\n",
      "['k', 'C', 'd', 'a', 'v0', 'vr', 'vpeak', 'b', 'vt', 'c']\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Mechanisms already loaded from path: /home/jovyan/neuronunit/neuronunit/models/NeuroML2.  Aborting.\n",
      "\n",
      "\n",
      "    Starting simulation in NEURON of 650.0ms generated from NeuroML2 model...\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n",
      "\n",
      "Population RS_pop contains 1 instance(s) of component: RS of type: izhikevich2007Cell\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "if USE_CACHED_GA:\n",
    "\n",
    "    from deap import creator\n",
    "    from deap import base\n",
    "    from neuronunit.optimization import evaluate_as_module as eam\n",
    "    from bluepyopt.deapext.optimisations import DEAPOptimisation\n",
    "    DO = DEAPOptimisation()\n",
    "    DO.setnparams(nparams = nparams, provided_keys = provided_keys)\n",
    "    [pop, log, history, hof, td] = pickle.load(open('ga_dump.p','rb'))\n",
    "else:\n",
    "    from bluepyopt.deapext.optimisations import DEAPOptimisation\n",
    "    #print(DEAPOptimisation)\n",
    "    DO = DEAPOptimisation()\n",
    "    DO.setnparams(nparams = nparams, provided_keys = provided_keys)\n",
    "    pop, hof, log, history, td, gen_vs_hof = DO.run(offspring_size = MU, max_ngen = NGEN, cp_frequency=4,cp_filename='checkpointedGA.p')\n",
    "    with open('ga_dump.p','wb') as f:\n",
    "       pickle.dump([pop, log, history, hof, td],f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuronunit.plottools import plot_surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen_vs_hof"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "dtcpop[0].attrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history.genealogy_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below two error surface slices from the hypervolume are plotted.\n",
    "The data that is plotted consists of the error as experienced by the GA.\n",
    "Note: the GA performs an incomplete, and efficient sampling of the parameter space, and therefore sample points are irregularly spaced. Polygon interpolation is used to visualize error gradients. Existing plotting code from the package BluePyOpt has been extended for this purpose.\n",
    "Light blue dots indicate local minima's of error experienced by the NSGA algrorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_surface('a','b',td,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_surface('v0','vt',td,history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtcpopg = [ dtc for dtc in dtcpopg if not None in (dtc.scores.values()) ]\n",
    "dtcpopg = [ (dtc,sum(list(dtc.scores.values()))) for dtc in dtcpopg ]\n",
    "sorted_grid = sorted(dtcpopg,key=lambda x:x[1])\n",
    "sorted_grid = [dtc[0] for dtc in sorted_grid]\n",
    "#print(sorted_grid)\n",
    "mini = dtcpopg[0][1]\n",
    "maxi = dtcpopg[-1][1]\n",
    "minimagr = sorted_grid[0]\n",
    "minimagr_dtc = sorted_grid[0]\n",
    "minimagr_dtc_1 = sorted_grid[1]\n",
    "minimagr_dtc_2 = sorted_grid[2]\n",
    "\n",
    "from neuronunit.optimization.exhaustive_search import create_refined_grid\n",
    "refined_grid = create_refined_grid(minimagr_dtc, minimagr_dtc_1,minimagr_dtc_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#log = logbook\n",
    "#plt.clf()\n",
    "plt.style.use('ggplot')\n",
    "fig, axes = plt.subplots(figsize=(10, 10), facecolor='white')\n",
    "gen_numbers =[ i for i in range(0,len(log.select('gen'))) ]\n",
    "mean = np.array([ np.sqrt(np.mean(np.square(i))) for i in log.select('avg')])\n",
    "std = np.array([ np.sqrt(np.mean(np.square(i))) for i in log.select('std')])\n",
    "minimum = np.array([ np.sqrt(np.mean(np.square(i))) for i in log.select('min')])\n",
    "best_line = np.array([ np.sqrt(np.mean(np.square(list(p.fitness.values))))  for p in hof])\n",
    "print(best_line,gen_numbers)\n",
    "#bl = [b for b in best_line if not np.isnan(b) ] \n",
    "#bl = [ min(bl) for i in gen_numbers]\n",
    "blg = [ best_line[h] for i, h in enumerate(gen_numbers) ]\n",
    "print(blg)\n",
    "#blg = [ hs)))) for i in gen_numbers ]\n",
    "\n",
    "\n",
    "stdminus = mean - std\n",
    "stdplus = mean + std\n",
    "try:\n",
    "    assert len(gen_numbers) == len(stdminus) == len(stdplus)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "axes.plot(\n",
    "    gen_numbers,\n",
    "    mean,\n",
    "    color='black',\n",
    "    linewidth=2,\n",
    "    label='population average')\n",
    "axes.fill_between(gen_numbers, stdminus, stdplus)\n",
    "axes.plot(gen_numbers, blg,'y--', linewidth=2,  label='grid search error')\n",
    "axes.plot(gen_numbers, bl, 'go', linewidth=2, label='hall of fame error')\n",
    "\n",
    "axes.plot(gen_numbers, stdminus, label='std variation lower limit')\n",
    "axes.plot(gen_numbers, stdplus, label='std variation upper limit')\n",
    "\n",
    "axes.set_xlim(np.min(gen_numbers) - 1, np.max(gen_numbers) + 1)\n",
    "axes.set_xlabel('Generations')\n",
    "axes.set_ylabel('Sum of objectives')\n",
    "axes.legend()\n",
    "fig.tight_layout()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment on plot\n",
    "The plot shows the mean error value of the population as the GA evolves it's population. The red interval at any instant is the standard deviation of the error. The fact that the mean GA error is able to have a net upwards trajectory, after experiencing a temporary downwards trajectory, demonstrates that the GA retains a drive to explore, and is resiliant against being stuck in a local minima. Also in the above plot population variance in error stays remarkably constant, in this way BluePyOpts selection criteria SELIBEA contrasts with DEAPs native selection strategy NSGA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if USE_CACHED_GS:\n",
    "    import pickle\n",
    "    # shelve cache \n",
    "    first_third = pickle.load(open('/home/jovyan/neuronunit/neuronunit/unit_test/grid_dump_first_3rd.p','rb'))\n",
    "    second_third = pickle.load(open('/home/jovyan/neuronunit/neuronunit/unit_test/grid_dump_second_3rd.p','rb'))\n",
    "    final_third = pickle.load(open('/home/jovyan/neuronunit/neuronunit/unit_test/grid_dump_final_3rd.p','rb'))\n",
    "\n",
    "    second_third.extend(first_third)\n",
    "    second_third.extend(final_third)\n",
    "    dtcpopg = second_third\n",
    "\n",
    "else:\n",
    "    from neuronunit.optimization import exhaustive_search\n",
    "    grid_points = exhaustive_search.create_grid(npoints = npoints,nparams = nparams)\n",
    "\n",
    "    dlist = list(dview.map_sync(exhaustive_search.update_dtc_pop,grid_points))\n",
    "    from neuronunit.optimization import get_neab\n",
    "    for d in dlist:\n",
    "        d.model_path = get_neab.LEMS_MODEL_PATH\n",
    "        d.LEMS_MODEL_PATH = get_neab.LEMS_MODEL_PATH\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(dlist)/350 < 1:\n",
    "        \n",
    "    elif len(dlist)/350 >= 1:\n",
    "        N = len(dlist)/350\n",
    "\n",
    "\n",
    "    # this is a big load on memory so divide it into thirds.\n",
    "\n",
    "    dlist_first_third = dlist[0:int(len(dlist)/N)]\n",
    "    dlist_second_third = dlist[int(len(dlist)/N):int(2*len(dlist)/N)]\n",
    "    dlist_final_third = dlist[int(2*len(dlist)/N):-1]\n",
    "    from neuronunit.optimization.exhaustive_search import dtc_to_rheo\n",
    "    from neuronunit.optimization.nsga_parallel import nunit_evaluate\n",
    "\n",
    "\n",
    "    def compute_chunk(dlist_half):\n",
    "        dlist_half = list(map(dtc_to_rheo,dlist_half))\n",
    "        dlist_half = dview.map_sync(nunit_evaluate,dlist_half)\n",
    "        return dlist_half\n",
    "\n",
    "    dlist_first_3rd = compute_chunk(dlist_first_third)\n",
    "    import pickle\n",
    "    with open('grid_dump_first_3rd.p','wb') as f:\n",
    "       pickle.dump(dlist_first_3rd,f)\n",
    "    # Garbage collect a big memory burden.\n",
    "    dlist_first_3rd = None\n",
    "    dlist_second_3rd = compute_chunk(dlist_second_third)\n",
    "\n",
    "    with open('grid_dump_second_3rd.p','wb') as f:\n",
    "       pickle.dump(dlist_second_3rd,f)\n",
    "   # Garbage collect a big memory burden.\n",
    "    dlist_second_3rd = None\n",
    "\n",
    "    dlist_final_3rd = compute_chunk(dlist_final_third)\n",
    "    with open('grid_dump_final_3rd.p','wb') as f:\n",
    "       pickle.dump(dlist_final_3rd,f)\n",
    "    # Garbage collect a big memory burden.\n",
    "    dlist_final_3rd = None\n",
    "    first_third = pickle.load(open('grid_dump_first_3rd.p','rb'))\n",
    "    second_third = pickle.load(open('grid_dump_second_3rd.p','rb'))\n",
    "    final_third = pickle.load(open('grid_dump_final_3rd.p','rb'))\n",
    "\n",
    "    second_third.extend(first_third)\n",
    "    second_third.extend(final_third)\n",
    "    dtcpopg = second_third\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(td)\n",
    "def pop2dtc(pop1,DO,td):\n",
    "    '''\n",
    "    This function takes the DEAP population data type, and converts it to a more convenient\n",
    "    data transport object, which can more readily be used in plotting functions.\n",
    "    This a wasteful, recompute, which is in part necessitated because\n",
    "    deaps pareto front object, only returns gene individual objects (elements of population)\n",
    "    '''\n",
    "    from neuronunit.optimization import evaluate_as_module as eam\n",
    "    from neuronunit.optimization import nsga_parallel\n",
    "    DO.td = td\n",
    "    assert DO.td == td\n",
    "    return_package = nsga_parallel.update_pop(pop1,td);\n",
    "    dtc_pop = []\n",
    "    for i,r in enumerate(return_package):\n",
    "        dtc_pop.append(r[0])\n",
    "        dtc_pop[i].error = None\n",
    "        dtc_pop[i].error = np.sqrt(np.mean(np.square(list(pop1[i].fitness.values))))\n",
    "    sorted_list  = sorted([(dtc,dtc.error) for dtc in dtc_pop],key=lambda x:x[1])\n",
    "    dtc_pop = [dtc[0] for dtc in sorted_list]\n",
    "    print(dtc_pop,sorted_list)\n",
    "    return dtc_pop\n",
    "\n",
    "DO.td = td\n",
    "print(hof[0])\n",
    "print(len(hof))\n",
    "dtc_pop = pop2dtc(hof[0:-1],DO,td)\n",
    "\n",
    "miniga = dtc_pop[0].error\n",
    "maxiga = dtc_pop[-1].error\n",
    "maximaga = dtc_pop[-1]\n",
    "minimaga = dtc_pop[0]\n",
    "\n",
    "CACHE_PF = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "if CACHE_PF == False:\n",
    "    h = list(history.genealogy_history.values())\n",
    "    evaluated_history = []\n",
    "    for i in h:\n",
    "        if hasattr(i,'rheobase'):\n",
    "            i.error = None\n",
    "            i.error = np.sqrt(np.mean(np.square(list(i.fitness.values))))\n",
    "            evaluated_history.append(i)\n",
    "    sorted_list  = sorted([(i,i.error) for i in evaluated_history ],key=lambda x:x[1])\n",
    "\n",
    "    with open('pf_dump.p','wb') as f:\n",
    "       pickle.dump([ sorted_list, evaluated_history ],f)\n",
    "else: \n",
    "     \n",
    "     unpack = pickle.load(open('pf_dump.p','rb'))\n",
    "     print(unpack)\n",
    "     sorted_list_pf = unpack[0]\n",
    "     pareto_dtc = unpack[1] \n",
    "\n",
    "minimaga_ind = sorted_list[0][0]\n",
    "maximaga_ind = sorted_list[-1][0]\n",
    "miniga = sorted_list[0][1]\n",
    "maxiga = sorted_list[-1][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(miniga)\n",
    "print(maxiga)\n",
    "print(minimaga_ind.fitness.values)\n",
    "print(maximaga_ind.fitness.values)\n",
    "print(len(minimaga_ind.fitness.values))\n",
    "print(dtcpopg[0][0].rheobase)\n",
    "print(dtcpopg[0][0].scores)\n",
    "print(sorted_list[-1][0].rheobase)\n",
    "print(sorted_list[-1][0].fitness.values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def use_dtc_to_plotting(dtcpop,minimagr):\n",
    "    from neuronunit.capabilities import spike_functions\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    plt.clf()\n",
    "    plt.style.use('ggplot')\n",
    "    fig, axes = plt.subplots(figsize=(10, 10), facecolor='white')\n",
    "    stored_min = []\n",
    "    stored_max = []\n",
    "    for dtc in dtcpop[1:-1]:\n",
    "        plt.plot(dtc.tvec, dtc.vm0,linewidth=3.5, color='grey')\n",
    "        stored_min.append(np.min(dtc.vm0))\n",
    "        stored_max.append(np.max(dtc.vm0))\n",
    "        \n",
    "    from neuronunit.models.reduced import ReducedModel\n",
    "    from neuronunit.optimization.get_neab import tests as T\n",
    "    from neuronunit.optimization import get_neab\n",
    "    from neuronunit.optimization import evaluate_as_module\n",
    "    from neuronunit.optimization.evaluate_as_module import pre_format\n",
    "    model = ReducedModel(get_neab.LEMS_MODEL_PATH,name=str('vanilla'),backend='NEURON')\n",
    "    import neuron\n",
    "    model._backend.reset_neuron(neuron)\n",
    "    model.set_attrs(minimagr.attrs)\n",
    "    model.rheobase = minimagr.rheobase['value']\n",
    "    minimagr = pre_format(minimagr)\n",
    "    parameter_list = list(minimagr.vtest.values())\n",
    "    model.inject_square_current(parameter_list[0])\n",
    "    model._backend.local_run()\n",
    "    assert model.get_spike_count() == 1\n",
    "    print(model.get_spike_count(),bool(model.get_spike_count() == 1))\n",
    "    brute_best = list(model.results['vm'])\n",
    "\n",
    "    plt.plot(dtcpop[0].tvec, brute_best,linewidth=1, color='blue',label='best candidate via grid')#+str(mini.scores))\n",
    "    plt.plot(dtcpop[0].tvec,dtcpop[0].vm0,linewidth=1, color='red',label='best candidate via GA')#+str(miniga.scores))\n",
    "    plt.legend()\n",
    "    plt.ylabel('$V_{m}$ mV')\n",
    "    plt.xlabel('ms')\n",
    "    plt.show()\n",
    "from neuronunit import plottools\n",
    "from neuronunit.plottools import dtc_to_plotting\n",
    "\n",
    "CACHE_PLOTTING = False\n",
    "if CACHE_PLOTTING == False:\n",
    "    dtc_pop = dview.map_sync(dtc_to_plotting,dtc_pop )\n",
    "    with open('plotting_dump.p','wb') as f:\n",
    "       pickle.dump(dtc_pop,f)\n",
    "else: \n",
    "     dtc_pop  = pickle.load(open('plotting_dump.p','rb'))\n",
    "\n",
    "use_dtc_to_plotting(dtc_pop,minimagr_dtc)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment on plot\n",
    "There is good agreement between traces produced by the best candidate found by Genetic Algorithm, and exhaustive grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(dtc_pop[0].scores)\n",
    "print(minimagr_dtc.scores)\n",
    "print(sum(list(dtc_pop[0].scores.values())))\n",
    "print(sum(list(minimagr_dtc.scores.values())))\n",
    "miniga = sum(list(dtc_pop[0].scores.values()))\n",
    "print(miniga)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantize distance between minimimum error and maximum error.\n",
    "This step will allow the GA's performance to be located within or below the range of error found by grid search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(maxi)\n",
    "print(mini)\n",
    "print(miniga)\n",
    "quantize_distance = list(np.linspace(mini,maxi,10))\n",
    "\n",
    "# check that the nsga error is in the bottom 1/5th of the entire error range.\n",
    "print('Report: ')\n",
    "print(\"Success\" if bool(miniga < quantize_distance[0]) else \"Failure\")\n",
    "print(\"The nsga error %f is in the bottom 1/5th of the entire error range\" % miniga)\n",
    "print(\"Minimum = %f; 20th percentile = %f; Maximum = %f\" % (mini,quantize_distance[0],maxi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below reports on the differences between between attributes of best models found via grid versus attributes of best models found via GA search:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from neuronunit.optimization import evaluate_as_module as eam\n",
    "NSGAO = NSGA(0.85)\n",
    "NSGAO.setnparams(nparams=nparams,provided_keys=provided_keys)\n",
    "#td = eam.get_trans_dict(NSGAO.subset)\n",
    "#print(td)\n",
    "td = { v:k for k,v in enumerate(td) }\n",
    "from neuronunit.optimization import model_parameters as modelp\n",
    "mp = modelp.model_params\n",
    "#minimaga = pareto_dtc[0]\n",
    "for k,v in minimagr_dtc.attrs.items():\n",
    "    #hvgrid = np.linspace(np.min(mp[k]),np.max(mp[k]),10)\n",
    "    dimension_length = np.max(mp[k]) - np.min(mp[k])\n",
    "    solution_distance_in_1D = np.abs(float(hof[0][td[k]]))-np.abs(float(v))\n",
    "        \n",
    "    #solution_distance_in_1D = np.abs(float(minimaga.attrs[k]))-np.abs(float(v))\n",
    "    relative_distance = dimension_length/solution_distance_in_1D\n",
    "    print('the difference between brute force candidates model parameters and the GA\\'s model parameters:')\n",
    "    print(float(hof[0][td[k]])-float(v),hof[0][td[k]],v,k)\n",
    "    print('the relative distance scaled by the length of the parameter dimension of interest:')\n",
    "    print(relative_distance)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print('the difference between the bf error and the GA\\'s error:')\n",
    "print('grid search:')\n",
    "from numpy import square, mean, sqrt\n",
    "rmsg = sqrt(mean(square(list(minimagr_dtc.scores.values()))))\n",
    "print(rmsg)\n",
    "print('ga:')\n",
    "rmsga = sqrt(mean(square(list(dtc_pop[0].scores.values()))))\n",
    "print(rmsga)\n",
    "print('Hall of Fame front')\n",
    "print(sqrt(mean(square(list(hof[0].fitness.values)))))\n",
    "print(miniga)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any time is left over, may as well compute a more accurate grid, to better quantify GA performance in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''print(refined_grid)\n",
    "REFINED_GRID = True\n",
    "if REFINE_GRID:\n",
    "    from neuronunit.optimization import exhaustive_search\n",
    "    #maximagr_dtc, maxi = sorted_dtcs(dtcpopg)[-1]\n",
    "\n",
    "    dlist = list(dview.map_sync(exhaustive_search.update_dtc_pop,refined_grid))\n",
    "    from neuronunit.optimization import get_neab\n",
    "    for d in dlist:\n",
    "        d.model_path = get_neab.LEMS_MODEL_PATH\n",
    "        d.LEMS_MODEL_PATH = get_neab.LEMS_MODEL_PATH\n",
    "\n",
    "    # this is a big load on memory so divide it into thirds.\n",
    "\n",
    "    dlist_first_third = dlist[0:int(len(dlist)/3)]\n",
    "    dlist_second_third = dlist[int(len(dlist)/3):int(2*len(dlist)/3)]\n",
    "    dlist_final_third = dlist[int(2*len(dlist)/3):-1]\n",
    "    from neuronunit.optimization.exhaustive_search import dtc_to_rheo\n",
    "    from neuronunit.optimization.nsga_parallel import nunit_evaluation\n",
    "\n",
    "    def compute_half(dlist_half):\n",
    "        dlist_half = list(map(dtc_to_rheo,dlist_half))\n",
    "        dlist_half = dview.map_sync(nunit_evaluation,dlist_half)\n",
    "        return dlist_half\n",
    "\n",
    "    dlist_first_3rd = compute_half(dlist_first_third)\n",
    "\n",
    "    with open('grid_dump_first_3rd.p','wb') as f:\n",
    "       pickle.dump(dlist_first_3rd,f)\n",
    "    # Garbage collect a big memory burden.\n",
    "    dlist_first_3rd = None\n",
    "    dlist_second_3rd = compute_half(dlist_second_third)\n",
    "\n",
    "    with open('grid_dump_second_3rd.p','wb') as f:\n",
    "       pickle.dump(dlist_second_3rd,f)\n",
    "    # Garbage collect a big memory burden.\n",
    "    dlist_second_3rd = None\n",
    "\n",
    "    dlist_final_3rd = compute_half(dlist_final_third)\n",
    "    with open('grid_dump_final_3rd.p','wb') as f:\n",
    "       pickle.dump(dlist_final_3rd,f)\n",
    "    # Garbage collect a big memory burden.\n",
    "    dlist_final_3rd = None\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
