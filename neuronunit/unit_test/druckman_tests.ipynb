{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/04/bd774106ae0ae1ada68c67efe89f1a16b2aa373cc2db15d974002a9f136d/numpy-1.15.4-cp35-cp35m-manylinux1_x86_64.whl (13.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.8MB 1.3MB/s ta 0:00:01    30% |█████████▊                      | 4.2MB 1.4MB/s eta 0:00:07    32% |██████████▌                     | 4.5MB 1.7MB/s eta 0:00:06    33% |██████████▋                     | 4.6MB 1.5MB/s eta 0:00:07    43% |█████████████▉                  | 6.0MB 1.2MB/s eta 0:00:07    46% |██████████████▉                 | 6.4MB 1.3MB/s eta 0:00:06    48% |███████████████▍                | 6.7MB 1.4MB/s eta 0:00:06    52% |████████████████▉               | 7.3MB 1.4MB/s eta 0:00:05    68% |██████████████████████          | 9.5MB 1.4MB/s eta 0:00:04    80% |█████████████████████████▋      | 11.1MB 1.9MB/s eta 0:00:02    82% |██████████████████████████▌     | 11.4MB 1.5MB/s eta 0:00:02\n",
      "\u001b[31mcffi 1.11.5 requires pycparser, which is not installed.\u001b[0m\n",
      "\u001b[31mcryptography 2.2.1 requires asn1crypto>=0.21.0, which is not installed.\u001b[0m\n",
      "\u001b[31mallensdk 0.14.2 has requirement pandas<0.20.0,>=0.16.2, but you'll have pandas 0.23.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: 'fftpack.cpython-35.pyc'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numpy\n",
      "  Using cached https://files.pythonhosted.org/packages/86/04/bd774106ae0ae1ada68c67efe89f1a16b2aa373cc2db15d974002a9f136d/numpy-1.15.4-cp35-cp35m-manylinux1_x86_64.whl\n",
      "\u001b[31mcryptography 2.2.1 requires asn1crypto>=0.21.0, which is not installed.\u001b[0m\n",
      "\u001b[31mcffi 1.11.5 requires pycparser, which is not installed.\u001b[0m\n",
      "\u001b[31mallensdk 0.14.2 has requirement pandas<0.20.0,>=0.16.2, but you'll have pandas 0.23.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: numpy\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: 'fftpack.cpython-35.pyc'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numpy==1.13.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/b9/50edeee58c1bed8db12c636f890547e5de33c12ffc4214cf5531c34ba0b1/numpy-1.13.0-cp35-cp35m-manylinux1_x86_64.whl (16.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 16.9MB 693kB/s ta 0:00:011  12% |████                            | 2.1MB 1.5MB/s eta 0:00:10    28% |█████████                       | 4.8MB 1.7MB/s eta 0:00:08    40% |█████████████                   | 6.8MB 1.7MB/s eta 0:00:06    54% |█████████████████▎              | 9.1MB 2.1MB/s eta 0:00:04    99% |███████████████████████████████▊| 16.8MB 1.5MB/s eta 0:00:01\n",
      "\u001b[31mcryptography 2.2.1 requires asn1crypto>=0.21.0, which is not installed.\u001b[0m\n",
      "\u001b[31mcffi 1.11.5 requires pycparser, which is not installed.\u001b[0m\n",
      "\u001b[31mallensdk 0.14.2 has requirement pandas<0.20.0,>=0.16.2, but you'll have pandas 0.23.1 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "\u001b[31mCould not install packages due to an EnvironmentError: [Errno 13] Permission denied: 'fftpack.cpython-35.pyc'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting numba\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/b9/b532d8889c8a78045c5a6c7887a999de4dfb72db4f74fd6d6e7efb4b1f07/numba-0.41.0-cp35-cp35m-manylinux1_x86_64.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 1.5MB/s ta 0:00:011   11% |███▊                            | 368kB 1.6MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting llvmlite>=0.26.0dev0 (from numba)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/ad/17deffd4c88b1c50d57b97547e33ef652f27a561347b8441f01901a3014e/llvmlite-0.26.0-cp35-cp35m-manylinux1_x86_64.whl (16.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 16.1MB 925kB/s ta 0:00:011  21% |██████▉                         | 3.4MB 1.9MB/s eta 0:00:07    26% |████████▋                       | 4.3MB 1.8MB/s eta 0:00:07    32% |██████████▎                     | 5.2MB 1.5MB/s eta 0:00:08    32% |██████████▌                     | 5.3MB 1.7MB/s eta 0:00:07    33% |██████████▋                     | 5.3MB 1.7MB/s eta 0:00:07    51% |████████████████▍               | 8.2MB 1.6MB/s eta 0:00:06    66% |█████████████████████▍          | 10.8MB 1.6MB/s eta 0:00:04    68% |██████████████████████          | 11.1MB 1.7MB/s eta 0:00:03    71% |██████████████████████▉         | 11.5MB 1.7MB/s eta 0:00:03    80% |█████████████████████████▊      | 13.0MB 1.7MB/s eta 0:00:02    82% |██████████████████████████▌     | 13.3MB 2.5MB/s eta 0:00:02    85% |███████████████████████████▏    | 13.7MB 3.2MB/s eta 0:00:01    86% |███████████████████████████▋    | 13.9MB 3.3MB/s eta 0:00:01    87% |████████████████████████████    | 14.0MB 886kB/s eta 0:00:03\n",
      "\u001b[?25hRequirement not upgraded as not directly required: numpy in /opt/conda/lib/python3.5/site-packages (from numba) (1.12.1)\n",
      "\u001b[31mcryptography 2.2.1 requires asn1crypto>=0.21.0, which is not installed.\u001b[0m\n",
      "\u001b[31mcffi 1.11.5 requires pycparser, which is not installed.\u001b[0m\n",
      "\u001b[31mallensdk 0.14.2 has requirement pandas<0.20.0,>=0.16.2, but you'll have pandas 0.23.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: llvmlite, numba\n",
      "  Found existing installation: llvmlite 0.8.0\n",
      "    Uninstalling llvmlite-0.8.0:\n",
      "      Successfully uninstalled llvmlite-0.8.0\n",
      "  Found existing installation: numba 0.23.1\n",
      "    Uninstalling numba-0.23.1:\n",
      "      Successfully uninstalled numba-0.23.1\n",
      "Successfully installed llvmlite-0.26.0 numba-0.41.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting lmfit\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/3b/6b9980956118aa050ebdf52a8b0cd43fdeabe3baedc2ef8f7fb39de4bff2/lmfit-0.9.12.tar.gz (1.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.6MB 3.4MB/s ta 0:00:011 4% |█▌                              | 71kB 439kB/s eta 0:00:04    65% |████████████████████▉           | 1.0MB 1.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>1.10 (from lmfit)\n",
      "  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.10 in /opt/conda/lib/python3.5/site-packages (from lmfit) (1.12.1)\n",
      "Requirement already satisfied: scipy>=0.17 in /opt/conda/lib/python3.5/site-packages (from lmfit) (1.1.0)\n",
      "Collecting asteval>=0.9.12 (from lmfit)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/9c/3958025163ecc1f38fab5a90da71c1939a99eabadb3a3e581c742048ce04/asteval-0.9.13.tar.gz (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 5.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting uncertainties>=3.0 (from lmfit)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/67/a6ee496235533d3f11e90c5c8ac6f395db03d78da770148c3f77848d1009/uncertainties-3.0.3.tar.gz (232kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 21.0MB/s a 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: lmfit, asteval, uncertainties\n",
      "  Running setup.py bdist_wheel for lmfit ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/97/fd/8b/fb5d58fac3172d7408c938f7678ff477e3d2913a4ec7d95bcc\n",
      "  Running setup.py bdist_wheel for asteval ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/f8/04/bf/0bae97344b951ec270d12cf6c0ee6565433631aa4d95979b5b\n",
      "  Running setup.py bdist_wheel for uncertainties ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/21/59/34/ec5b91498ae18a36d995b845081f288d5ea972374ae8a779ed\n",
      "Successfully built lmfit asteval uncertainties\n",
      "\u001b[31mcryptography 2.2.1 requires asn1crypto>=0.21.0, which is not installed.\u001b[0m\n",
      "\u001b[31mcffi 1.11.5 requires pycparser, which is not installed.\u001b[0m\n",
      "\u001b[31mallensdk 0.14.2 has requirement pandas<0.20.0,>=0.16.2, but you'll have pandas 0.23.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: six, asteval, uncertainties, lmfit\n",
      "  Found existing installation: six 1.10.0\n",
      "    Uninstalling six-1.10.0:\n",
      "      Successfully uninstalled six-1.10.0\n",
      "Successfully installed asteval-0.9.13 lmfit-0.9.12 six-1.12.0 uncertainties-3.0.3\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: lazyarray in /opt/conda/lib/python3.5/site-packages (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.8 in /opt/conda/lib/python3.5/site-packages (from lazyarray) (1.12.1)\n",
      "\u001b[31mcffi 1.11.5 requires pycparser, which is not installed.\u001b[0m\n",
      "\u001b[31mcryptography 2.2.1 requires asn1crypto>=0.21.0, which is not installed.\u001b[0m\n",
      "\u001b[31mallensdk 0.14.2 has requirement pandas<0.20.0,>=0.16.2, but you'll have pandas 0.23.1 which is incompatible.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    #pass\n",
    "    assert 1==2\n",
    "except:\n",
    "    !pip install --upgrade --force-reinstall numpy\n",
    "    !pip install numpy --upgrade \n",
    "    !pip install numpy==1.13.0\n",
    "    !pip install numba --upgrade \n",
    "    !pip install lmfit \n",
    "    !pip install lazyarray \n",
    "    \n",
    "    import numpy as np\n",
    "    print(np.__version__)\n",
    "\n",
    "    np.isin = None\n",
    "    def isin(element, test_elements, assume_unique=False, invert=False):\n",
    "        \"...\"\n",
    "        element = np.asarray(element)\n",
    "        return np.in1d(element, test_elements, assume_unique=assume_unique,\n",
    "                    invert=invert).reshape(element.shape)\n",
    "    np.isin = isin\n",
    "\n",
    "    assert np.isin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "electro_tests = []\n",
    "obs_frame = {}\n",
    "test_frame = {}\n",
    "import os\n",
    "import pickle\n",
    "try: \n",
    "\n",
    "    electro_path = str(os.getcwd())+'all_tests.p'\n",
    "\n",
    "    assert os.path.isfile(electro_path) == True\n",
    "    with open(electro_path,'rb') as f:\n",
    "        (obs_frame,test_frame) = pickle.load(f)\n",
    "\n",
    "except:\n",
    "    for p in pipe:\n",
    "        p_tests, p_observations = get_neab.get_neuron_criteria(p)\n",
    "        obs_frame[p[\"name\"]] = p_observations#, p_tests))\n",
    "        test_frame[p[\"name\"]] = p_tests#, p_tests))\n",
    "    electro_path = str(os.getcwd())+'all_tests.p'\n",
    "    with open(electro_path,'wb') as f:\n",
    "        pickle.dump((obs_frame,test_frame),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sciunit, neuronunit, quantities\n",
    "from neuronunit.tests.dm import *\n",
    "import time\n",
    "from neuronunit.tests import dm #this is me importing the Druckman tests\n",
    "from neuronunit.tests import RheobaseTestP, fi, RheobaseTest \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuronunit.models.reduced import ReducedModel\n",
    "from neuronunit.optimization.data_transport_container import DataTC\n",
    "from neuronunit.optimization.model_parameters import model_params, path_params, transcribe_units\n",
    "from neuronunit.optimization.optimization_management import mint_generic_model\n",
    "LEMS_MODEL_PATH = path_params['model_path']\n",
    "\n",
    "\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('RAW'))\n",
    "dtc = DataTC()\n",
    "dtc.attrs = model.attrs\n",
    "dtc.ampl=0\n",
    "dtc.attrs_raw = {'C':89.7960714285714, 'a':0.01, 'b':15, 'c':-60, 'd':10,\\\n",
    "         'k':1.6, 'vPeak':(86.364525297619-65.2261863636364),\\\n",
    "         'vr':-65.2261863636364, 'vt':-50}\n",
    "\n",
    "\n",
    "dtc.attrs = transcribe_units(dtc.attrs_raw)\n",
    "\n",
    "start0 = time.time()\n",
    "model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('NEURON', {'DTC':dtc}))\n",
    "rt = RheobaseTestP(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "pred0 = rt.generate_prediction(model)\n",
    "end0 = time.time()\n",
    "print(model.attrs)\n",
    "\n",
    "model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('NEURON', {'DTC':dtc}))\n",
    "start1 = time.time()\n",
    "rt = fi.RheobaseTest(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "pred1 = rt.generate_prediction(model)\n",
    "end1 = time.time()\n",
    "\n",
    "print('parallel Rhsearch time NEURON', end0-start0)\n",
    "print('serial Rhsearch time NEURON',end1-start1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "explore_ranges = {'E_Na' : (40,70), 'E_K': (-90.0,-75.0)}\n",
    "\n",
    "attrs = { 'g_K' : 36.0, 'g_Na' : 120.0, 'g_L' : 0.3, \\\n",
    "         'C_m' : 1.0, 'E_L' : -54.387, 'E_K' : -77.0, 'E_Na' : 50.0, 'vr':-65.0 } \n",
    "\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('HH'))\n",
    "model.attrs = attrs\n",
    "dtc.attrs = attrs\n",
    "iparams = {}\n",
    "iparams['injected_square_current'] = {}\n",
    "iparams['injected_square_current']['amplitude'] = 1.98156805*pq.pA\n",
    "iparams['injected_square_current']['amplitude'] = 2.98156805*pq.pA\n",
    "\n",
    "DELAY = 100.0*pq.ms\n",
    "DURATION = 1000.0*pq.ms\n",
    "iparams['injected_square_current']['delay'] = DELAY\n",
    "iparams['injected_square_current']['duration'] = int(DURATION)\n",
    "bf = time.time()\n",
    "model.inject_square_current(iparams)\n",
    "vm = model.get_membrane_potential()\n",
    "af = time.time()\n",
    "#volts = [v[0] for v in vm ]\n",
    "print(len(vm[0]),len(vm.times))\n",
    "\n",
    "\n",
    "bfp = time.time()\n",
    "model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('HH', {'DTC':dtc}))\n",
    "model._backend.cell_name = str('vanilla')\n",
    "rt = RheobaseTestP(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "pred0 = rt.generate_prediction(model)\n",
    "afp = time.time()\n",
    "print(model.attrs)\n",
    "plt.plot(vm.times,vm)\n",
    "plt.show()\n",
    "print('elapsed parallel: ',afp-bfp)\n",
    "\n",
    "\n",
    "bfs = time.time()\n",
    "model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('HH', {'DTC':dtc}))\n",
    "model._backend.cell_name = str('vanilla')\n",
    "\n",
    "rt = RheobaseTest(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "pred0 = rt.generate_prediction(model)\n",
    "afs = time.time()\n",
    "print(model.attrs)\n",
    "plt.plot(vm.times,vm)\n",
    "plt.show()\n",
    "print('elapsed serial: ',afs-bfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import pdb\n",
    "with open(electro_path,'rb') as f:\n",
    "    (obs_frame,test_frame) = pickle.load(f)\n",
    "use_test = test_frame[\"Neocortex pyramidal cell layer 5-6\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_test[0].observation\n",
    "#from neuronunit.tests import RheobaseP\n",
    "from neuronunit.tests.fi import RheobaseTestP# as discovery\n",
    "\n",
    "rtp = RheobaseTestP(use_test[0].observation)\n",
    "use_test[0] = rtp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explore_ranges = {'E_Na' : (40.0,70.0), 'E_K': (-90.0,-75.0), 'g_K':(30,40), 'g_Na':(100.0,140.0), 'g_L':(0.1,0.5), 'E_L':(-60.0,-45.0)}\n",
    "\n",
    "attrs = { 'g_K' : 36.0, 'g_Na' : 120.0, 'g_L' : 0.3, \\\n",
    "         'C_m' : 1.0, 'E_L' : -54.387, 'E_K' : -77.0, 'E_Na' : 50.0, 'vr':-65.0 } \n",
    "\n",
    "    \n",
    "from neuronunit.optimization import optimization_management as om\n",
    "print(test_frame)    \n",
    "MU = 12\n",
    "NGEN = 25\n",
    "cnt = 1\n",
    "#hc = { 'g_L' : 0.3, 'E_L' : -54.387,\n",
    "hc = {'vr':-65.0, 'C_m':1.0 } \n",
    "\n",
    "npcl, DO = om.run_ga(explore_ranges,NGEN,use_test,free_params=explore_ranges.keys(), hc = hc, NSGA = True, MU = MU,model_type='HH')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attrs = {'cm': 0.20000000000000001,\n",
    " 'e_rev_E': 0.0,\n",
    " 'e_rev_I': -80.0,\n",
    " 'e_rev_K': -90.0,\n",
    " 'e_rev_Na': 50.0,\n",
    " 'e_rev_leak': -65.0,\n",
    " 'g_leak': 0.01,\n",
    " 'gbar_K': 6.0,\n",
    " 'gbar_Na': 20.0,\n",
    " 'i_offset': 0.0,\n",
    " 'tau_syn_E': 0.20000000000000001,\n",
    " 'tau_syn_I': 2.0,\n",
    " 'v_offset': -63.0}\n",
    "\n",
    "#   def __init__(self, \n",
    "# I_ampl=10., g_leak=0.3,\n",
    "# g_K=36., g_Na=120., V_leak=-54.402, V_K=-77., V_Na=50.):\n",
    "\n",
    "dtc.attrs = attrs\n",
    "bfp = time.time()\n",
    "#model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('HH', {'DTC':dtc}))\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('HHpyNN', {'DTC':dtc}))\n",
    "\n",
    "rt0 = RheobaseTestP(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "pred0 = rt.generate_prediction(model)\n",
    "afp = time.time()\n",
    "print('elapsed parallel: ',afp-bfp)\n",
    "\n",
    "\n",
    "bfs = time.time()\n",
    "#model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('HH', {'DTC':dtc}))\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('HHpyNN', {'DTC':dtc}))\n",
    "\n",
    "rt1 = RheobaseTest(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "pred1 = rt.generate_prediction(model)\n",
    "afs = time.time()\n",
    "\n",
    "\n",
    "print(model.attrs)\n",
    "plt.plot(vm.times,vm)\n",
    "plt.show()\n",
    "print('elapsed Serial: ',afs-bfs)\n",
    "print(rt0,rt1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attrs = { 'gK' : 36.0, 'gNa' : 120.0, 'gL' : 0.3, 'Cm' : 1.0, 'Vl' : -10.402, 'VK' : -12.0, 'VNa' : -115, 'vr':-58.402 } \n",
    "\n",
    "C_m = 1\n",
    "V_Na = -115\n",
    "V_K = 12\n",
    "V_l = -10.613\n",
    "g_Na = 120\n",
    "g_K = 36\n",
    "g_l = 0.3\n",
    "\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('HH'))\n",
    "model.attrs = attrs\n",
    "iparams['injected_square_current']['amplitude'] = 15.6805*pq.pA\n",
    "\n",
    "model.inject_square_current(iparams)\n",
    "vm = model.get_membrane_potential()\n",
    "af = time.time()\n",
    "#volts = [v[0] for v in vm ]\n",
    "print(len(vm[0]),len(vm.times))\n",
    "plt.plot(vm.times,vm)\n",
    "\n",
    "len(vm)\n",
    "len(vm.times)\n",
    "np.shape(vm)\n",
    "print(vm[6000])\n",
    "print(vm[5000])\n",
    "print(vm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start4 = time.time()\n",
    "\n",
    "model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('RAW'))\n",
    "rt = fi.RheobaseTestP(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "pred1 = rt.generate_prediction(model)\n",
    "end4 = time.time()\n",
    "\n",
    "\n",
    "start3 = time.time()\n",
    "\n",
    "model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('RAW'))\n",
    "\n",
    "rt = fi.RheobaseTest(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "pred1 = rt.generate_prediction(model)\n",
    "end3 = time.time()\n",
    "\n",
    "print(pred1)\n",
    "ir_currents = {}\n",
    "ir_currents = pred1['value']\n",
    "standard = 1.5*ir_currents\n",
    "standard*=1.5\n",
    "strong = 3*ir_currents\n",
    "print(standard,strong,ir_currents)\n",
    "\n",
    "\n",
    "\n",
    "print('parallel Rhsearch time RAW', end4-start4)\n",
    "print('serial Rhsearch time RAW',end3-start3)\n",
    "\n",
    "print(pred)\n",
    "#for i in npcl['pf'][0:2]:\n",
    "iparams = {}\n",
    "iparams['injected_square_current'] = {}\n",
    "iparams['injected_square_current']['amplitude'] = pred1['value']\n",
    "model = None\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('RAW'))\n",
    "#model.set_attrs(i.dtc.attrs)\n",
    "\n",
    "#['amplitude']  = dtc.vtest[k]['injected_square_current']['amplitude']\n",
    "DELAY = 100.0*pq.ms\n",
    "DURATION = 1000.0*pq.ms\n",
    "iparams['injected_square_current']['delay'] = DELAY\n",
    "iparams['injected_square_current']['duration'] = int(DURATION)\n",
    "model.inject_square_current(iparams)\n",
    "n_spikes = len(model.get_spike_train())\n",
    "\n",
    "if n_spikes:\n",
    "    print(n_spikes)\n",
    "    #print(i[0].scores['RheobaseTestP']*pq.pA)\n",
    "    plt.plot(model.get_membrane_potential().times,model.get_membrane_potential())#,label='ground truth')\n",
    "    plt.legend()\n",
    "print(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#speed_up= (end1-start1)/(end0-start0)\n",
    "#print(speed_up, 'speed up for NEURON')\n",
    "speed_up= (end3-start3)/(end4-start4)\n",
    "print(speed_up, 'speed up (slow down) for rawpy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show that parallel rheobase is ~3.5-7 times faster for NEURON, but slower for numba jit depending on model.\n",
    "\n",
    "This makes sense, because numba jit evaluations are over so quickly, it rivals the time, for interprocessor communication, not so with NEURON simulations, where simulation takes a long time.\n",
    "\n",
    "The reason parallel is faster given interprocessor comm speed < sim evaluation time, is because in the case of binary search.\n",
    "\n",
    "For each sim evaluation, the search engine only narrows by 50%.\n",
    "\n",
    "In the parallel case, 8 simultaneous sim evaluations, are able to narrow the search interval space, by 7/8ths.\n",
    "\n",
    "This fast narrowing of intervals is what makes the parallel case faster than the binary case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "tests = [AP12AmplitudeDropTest(standard), \n",
    "    AP1SSAmplitudeChangeTest(standard), \n",
    "    AP1AmplitudeTest(standard), \n",
    "    AP1WidthHalfHeightTest(standard), \n",
    "    AP1WidthPeakToTroughTest(standard), \n",
    "    AP1RateOfChangePeakToTroughTest(standard), \n",
    "    AP1AHPDepthTest(standard), \n",
    "    AP2AmplitudeTest(standard), \n",
    "    AP2WidthHalfHeightTest(standard), \n",
    "    AP2WidthPeakToTroughTest(standard), \n",
    "    AP2RateOfChangePeakToTroughTest(standard), \n",
    "    AP2AHPDepthTest(standard), \n",
    "    AP12AmplitudeChangePercentTest(standard), \n",
    "    AP12HalfWidthChangePercentTest(standard), \n",
    "    AP12RateOfChangePeakToTroughPercentChangeTest(standard), \n",
    "    AP12AHPDepthPercentChangeTest(standard), \n",
    "    AP1DelayMeanTest(standard), \n",
    "    AP1DelaySDTest(standard), \n",
    "    AP2DelayMeanTest(standard), \n",
    "    AP2DelaySDTest(standard), \n",
    "    Burst1ISIMeanTest(standard), \n",
    "    Burst1ISISDTest(standard), \n",
    "    InitialAccommodationMeanTest(standard), \n",
    "    SSAccommodationMeanTest(standard), \n",
    "    AccommodationRateToSSTest(standard), \n",
    "    AccommodationAtSSMeanTest(standard), \n",
    "    AccommodationRateMeanAtSSTest(standard), \n",
    "    ISICVTest(standard), \n",
    "    ISIMedianTest(standard), \n",
    "    ISIBurstMeanChangeTest(standard), \n",
    "    SpikeRateStrongStimTest(strong), \n",
    "    AP1DelayMeanStrongStimTest(strong), \n",
    "    AP1DelaySDStrongStimTest(strong), \n",
    "    AP2DelayMeanStrongStimTest(strong), \n",
    "    AP2DelaySDStrongStimTest(strong), \n",
    "    Burst1ISISDStrongStimTest(strong),\n",
    "    Burst1ISIMeanStrongStimTest(strong)]\n",
    "\n",
    "AHP_list = [AP1AHPDepthTest(standard), \n",
    "    AP2AHPDepthTest(standard), \n",
    "    AP12AHPDepthPercentChangeTest(standard) ] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(ir_currents)\n",
    "print(standard)\n",
    "print(strong)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start2 = time.time()\n",
    "\n",
    "model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('RAW'))\n",
    "\n",
    "    \n",
    "for i, test in enumerate(tests):\n",
    "    mean = test.generate_prediction(model)['mean']\n",
    "    \n",
    "    \n",
    "\n",
    "    #print(mean,test)\n",
    "stop2 = time.time()\n",
    "delta2 = stop2-start2\n",
    "print('serial time: ',stop2-start2)\n",
    "\n",
    "'''\n",
    "USING NEURON WOULD TAKE HALF AN HOUR\n",
    "start3 = time.time()\n",
    "model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('NEURON', {'DTC':dtc}))\n",
    "model.atts = dtc.attrs\n",
    "\n",
    "\n",
    "for i, test in enumerate(tests):\n",
    "    mean = test.generate_prediction(model)['mean']\n",
    "    #print(mean, tests)\n",
    "stop3 = time.time()\n",
    "print(stop3-start3)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# can do these tests in parallel:\n",
    "import dask.bag as db\n",
    "import multiprocessing\n",
    "npart = multiprocessing.cpu_count()\n",
    "\n",
    "\n",
    "start5 = time.time()\n",
    "bag = db.from_sequence(tests, npartitions = npart)\n",
    "means = list(bag.map(takes_tests).compute())    \n",
    "end5 = time.time()\n",
    "#print(end5-start5)\n",
    "\n",
    "print(means)\n",
    "print('parallel time: ',end5-start5)\n",
    "print('speed up:',delta2/(end5-start5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dmtests = dm.Druckmann2013Test\n",
    "d_tests = []\n",
    "for d in dir(dm):\n",
    "    if \"Test\" in d:\n",
    "        exec('d_tests.append(dm.'+str(d)+')')\n",
    "#print()\n",
    "dt = d_tests[1:-1]\n",
    "print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import quantities as pq\n",
    "current_amplitude = {'mean': 106.7 * pq.pA, 'n': 1, 'std': 0.0 * pq.pA}\n",
    "test = dm.AP12AmplitudeChangePercentTest(current_amplitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "electro_path = str(os.getcwd())+'all_tests.p'\n",
    "\n",
    "assert os.path.isfile(electro_path) == True\n",
    "with open(electro_path,'rb') as f:\n",
    "    (obs_frame,test_frame) = pickle.load(f)\n",
    "\n",
    "\n",
    "rt = RheobaseTestP(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "\n",
    "pred = rt.generate_prediction(model)\n",
    "print(pred)\n",
    "#for i in npcl['pf'][0:2]:\n",
    "iparams = {}\n",
    "iparams['injected_square_current'] = {}\n",
    "iparams['injected_square_current']['amplitude'] = pred['value']\n",
    "model = None\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('RAW'))\n",
    "#model.set_attrs(i.dtc.attrs)\n",
    "\n",
    "#['amplitude']  = dtc.vtest[k]['injected_square_current']['amplitude']\n",
    "DELAY = 100.0*pq.ms\n",
    "DURATION = 1000.0*pq.ms\n",
    "iparams['injected_square_current']['delay'] = DELAY\n",
    "iparams['injected_square_current']['duration'] = int(DURATION)\n",
    "model.inject_square_current(iparams)\n",
    "n_spikes = len(model.get_spike_train())\n",
    "\n",
    "if n_spikes:\n",
    "    print(n_spikes)\n",
    "    #print(i[0].scores['RheobaseTestP']*pq.pA)\n",
    "    plt.plot(model.get_membrane_potential().times,model.get_membrane_potential())#,label='ground truth')\n",
    "    plt.legend()\n",
    "print(obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(model)\n",
    "help(dt[0])\n",
    "dt = dt[0]()\n",
    "dt[0].generate_prediction(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import pdb\n",
    "for d in dt:\n",
    "    pdb.set_trace()\n",
    "    #dmtO = d(pred['value'])#obs_frame['Dentate gyrus basket cell']['Rheobase'])\n",
    "print(dmt0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
