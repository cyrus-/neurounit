{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions, the environment for running this notebook was arrived at by building a dedicated docker file.\n",
    "\n",
    "https://cloud.docker.com/repository/registry-1.docker.io/russelljarvis/nuo\n",
    "\n",
    "You can run use dockerhub to get the appropriate file, and launch this notebook using Kitematic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This is code, change cell type to markdown.\n",
    "# ![alt text](plan.jpg \"Pub plan\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries\n",
    "To keep the standard running version of minimal and memory efficient, not all available packages are loaded by default. In the cell below I import a mixture common python modules, and custom developed modules associated with NeuronUnit (NU) development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install dask distributed seaborn\n",
    "#!bash after_install.sh\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from neuronunit.tests.fi import RheobaseTestP\n",
    "from neuronunit.optimization.model_parameters import reduced_dict, reduced_cells  \n",
    "from neuronunit.optimization import optimization_management as om\n",
    "from sciunit import scores# score_type \n",
    "\n",
    "from neuronunit.optimization.data_transport_container import DataTC\n",
    "from neuronunit.tests.fi import RheobaseTestP# as discovery\n",
    "from neuronunit.optimization.optimization_management import dtc_to_rheo, format_test, nunit_evaluation\n",
    "import quantities as pq\n",
    "from neuronunit.models.reduced import ReducedModel\n",
    "from neuronunit.optimization.model_parameters import model_params, path_params\n",
    "LEMS_MODEL_PATH = path_params['model_path']\n",
    "list_to_frame = []\n",
    "from neuronunit.tests.fi import RheobaseTestP\n",
    "\n",
    "    \n",
    "from IPython.display import HTML, display\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# The Izhiketich model is instanced using some well researched parameter sets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets get the points in parameter space, that Izhikich himself has published about. These points are often used by the open source brain project to establish between model reproducibility. The itial motivating factor for choosing these points as constellations, of all possible parameter space subsets, is that these points where initially tuned and used as best guesses for matching real observed experimental recordings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "explore_param = {k:(np.min(v),np.max(v)) for k,v in reduced_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get the experimental Data pertaining to four different classes or neurons, that can constrain models.\n",
    "Next we get some electro physiology data for four different classes of cells that are very common targets of scientific neuronal modelling. We are interested in finding out what are the most minimal, and detail reduced, low complexity model equations, that are able to satisfy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Below are some of the data set ID's I used to query neuroelectro.\n",
    "To save time for the reader, I prepared some data earlier to save time, and saved the data as a pickle, pythons preferred serialisation format.\n",
    "\n",
    "The interested reader can find some methods for getting cell specific ephys data from neuroelectro in a code file (neuronunit/optimization/get_neab.py) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "purkinje ={\"id\": 18, \"name\": \"Cerebellum Purkinje cell\", \"neuron_db_id\": 271, \"nlex_id\": \"sao471801888\"}\n",
    "fi_basket = {\"id\": 65, \"name\": \"Dentate gyrus basket cell\", \"neuron_db_id\": None, \"nlex_id\": \"nlx_cell_100201\"}\n",
    "pvis_cortex = {\"id\": 111, \"name\": \"Neocortex pyramidal cell layer 5-6\", \"neuron_db_id\": 265, \"nlex_id\": \"nifext_50\"}\n",
    "#does not have rheobase\n",
    "olf_mitral = {\"id\": 129, \"name\": \"Olfactory bulb (main) mitral cell\", \"neuron_db_id\": 267, \"nlex_id\": \"nlx_anat_100201\"}\n",
    "ca1_pyr = {\"id\": 85, \"name\": \"Hippocampus CA1 pyramidal cell\", \"neuron_db_id\": 258, \"nlex_id\": \"sao830368389\"}\n",
    "pipe = [ fi_basket, ca1_pyr, purkinje,  pvis_cortex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "electro_tests = []\n",
    "obs_frame = {}\n",
    "test_frame = {}\n",
    "\n",
    "try: \n",
    "\n",
    "    electro_path = str(os.getcwd())+'all_tests.p'\n",
    "\n",
    "    assert os.path.isfile(electro_path) == True\n",
    "    with open(electro_path,'rb') as f:\n",
    "        (obs_frame,test_frame) = pickle.load(f)\n",
    "\n",
    "except:\n",
    "    for p in pipe:\n",
    "        p_tests, p_observations = get_neab.get_neuron_criteria(p)\n",
    "        obs_frame[p[\"name\"]] = p_observations#, p_tests))\n",
    "        test_frame[p[\"name\"]] = p_tests#, p_tests))\n",
    "    electro_path = str(os.getcwd())+'all_tests.p'\n",
    "    with open(electro_path,'wb') as f:\n",
    "        pickle.dump((obs_frame,test_frame),f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cast the tabulatable data to pandas data frame\n",
    "There are many among us who prefer potentially tabulatable data to be encoded in pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for k,v in test_frame.items():\n",
    "    if \"olf_mit\" not in k:\n",
    "        obs = obs_frame[k]\n",
    "        v[0] = RheobaseTestP(obs['Rheobase'])\n",
    "df = pd.DataFrame.from_dict(obs_frame)\n",
    "print(test_frame.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the data frame below, you can see many different cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['Hippocampus CA1 pyramidal cell']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweak Izhikitich equations\n",
    "with educated guesses based on information that is already encoded in the predefined experimental observations.\n",
    "\n",
    "In otherwords use information that is readily amenable into hardcoding into equations \n",
    "\n",
    "Select out the 'Neocortex pyramidal cell layer 5-6' below, as a target for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "free_params = ['a','b','k','c','C','d','vPeak','vr']\n",
    "hc_ = reduced_cells['RS']\n",
    "hc_['vr'] = -65.2261863636364\n",
    "hc_['vPeak'] = hc_['vr'] + 86.364525297619\n",
    "explore_param['C'] = (hc_['C']-20,hc_['C']+20)\n",
    "explore_param['vr'] = (hc_['vr']-5,hc_['vr']+5)\n",
    "use_test = test_frame[\"Neocortex pyramidal cell layer 5-6\"]\n",
    "\n",
    "#for t in use_test[::-1]:\n",
    "#    t.score_type = scores.RatioScore\n",
    "test_opt = {}\n",
    "\n",
    "with open('data_dump.p','wb') as f:\n",
    "    pickle.dump(test_opt,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "use_test[0].observation\n",
    "print(use_test[0].name)\n",
    "\n",
    "rtp = RheobaseTestP(use_test[0].observation)\n",
    "use_test[0] = rtp\n",
    "print(use_test[0].observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reduced_cells.keys()\n",
    "test_frame.keys()\n",
    "test_frame.keys()\n",
    "test_frame['olf_mit'].insert(0,test_frame['Cerebellum Purkinje cell'][0])\n",
    "test_frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!pip install neo --upgrade\n",
    "\n",
    "df = pd.DataFrame(index=list(test_frame.keys()),columns=list(reduced_cells.keys()))\n",
    "\n",
    "for k,v in reduced_cells.items():\n",
    "    temp = {}\n",
    "    temp[str(v)] = {}\n",
    "    dtc = DataTC()\n",
    "    dtc.tests = use_test\n",
    "    dtc.attrs = v        \n",
    "    dtc.backend = 'RAW'\n",
    "    dtc.cell_name = 'vanilla'\n",
    "\n",
    "\n",
    "    for key, use_test in test_frame.items():\n",
    "        dtc.tests = use_test\n",
    "        dtc = dtc_to_rheo(dtc)\n",
    "        dtc = format_test(dtc)\n",
    "\n",
    "        if dtc.rheobase is not None:\n",
    "            if dtc.rheobase!=-1.0:\n",
    "\n",
    "                dtc = nunit_evaluation(dtc)\n",
    "\n",
    "        df[k][key] = int(dtc.get_ss())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sparse grid sampling over the parameter space, using the published and well corrobarated parameter points, from Izhikitch publications, and the Open Source brain, shows that without optimization, using off the shelf parameter sets to fit real-life biological cell data, does not work so well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "#df.pivot\n",
    "\n",
    "#sns.heatmap(df)\n",
    "s = df.style.background_gradient(cmap=cm)\n",
    "#values = df.values\n",
    "\n",
    "#values\n",
    "#pivoted = df.pivot()\n",
    "#s\n",
    "type(s)\n",
    "type(df['RS'])\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RS          4.265197\n",
       "IB          5.838844\n",
       "LTS         5.472374\n",
       "TC          5.703031\n",
       "TC_burst    5.521753\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuronunit.tests import dm \n",
    "dmtests = dm.Druckmann2013Test\n",
    "d_tests = []\n",
    "for d in dir(dm):\n",
    "    if \"Test\" in d:\n",
    "        exec('d_tests.append(dm.'+str(d)+')')\n",
    "        \n",
    "        \n",
    "df.min()        \n",
    "\n",
    "        \n",
    "#print(d_tests)\n",
    "\n",
    "\n",
    "#from neuronunit.tests.dm import InputResistanceTest as DMInputResistanceTest\n",
    "#use_test.append(DMInputResistanceTest(injection_currents=[-11.0*pq.pA,-6*pq.pA,-1*pq.pA,]))\n",
    "#print(use_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MU = 10\n",
    "NGEN = 200\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "print(free_params)\n",
    "    \n",
    "index, DO = om.run_ga(explore_param,NGEN,use_test,free_params=free_params, NSGA = False, MU = MU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MU = 6\n",
    "NGEN = 200\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "print(free_params)\n",
    "    \n",
    "index, DO = om.run_ga(explore_param,NGEN,use_test,free_params=free_params, NSGA = False, MU = MU)\n",
    "'''\n",
    "MU = 6\n",
    "NGEN = 200\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "try:\n",
    "    with open('multi_objective.p','rb') as f:\n",
    "        test_opt = pickle.load(f)\n",
    "except:\n",
    "\n",
    "for index, use_test in enumerate(test_frame.values()):\n",
    "\n",
    "    if index % 2 == 0:\n",
    "        index, DO = om.run_ga(explore_param,NGEN,use_test,free_params=free_params, NSGA = False, MU = MU)\n",
    "    else:\n",
    "        index, DO = om.run_ga(explore_param,NGEN,use_test,free_params=free_params, NSGA = False, MU = MU)\n",
    "    #print(NSGA)\n",
    "\n",
    "    print('can get as low as 2.70295, 2.70679')\n",
    "\n",
    "    test_opt =  {str('multi_objective')+str(index):npcl}\n",
    "    with open('multi_objective.p','wb') as f:\n",
    "        pickle.dump(test_opt,f)\n",
    "\n",
    "\n",
    "print(np.sum(list(test_opt['multi_objective']['pf'][2].dtc.scores.values())))\n",
    "print(np.sum(list(test_opt['multi_objective']['pf'][1].dtc.scores.values())))\n",
    "#print(np.sum(list(test_opt['multi_objective']['hof'][0].dtc.scores.values())))\n",
    "print(test_opt['multi_objective']['pf'][2].dtc.scores.items())\n",
    "print(test_opt['multi_objective']['pf'][1].dtc.scores.items())\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_opt.keys()\n",
    "for value in test_opt.values():\n",
    "    value['stds']\n",
    "    value['ranges']\n",
    "    print(value['ranges'])    \n",
    "    print(value['stds'])\n",
    "    \n",
    "    #fig = pl.figure()\n",
    "    #ax = pl.subplot(111)\n",
    "    #ax.bar(range(len(value.keys())), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data_dump.p','rb') as f:\n",
    "    test_opt = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#errorbar\n",
    "#for \n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import errorbar\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig0,ax0 = plt.subplots(dim,dim,figsize=(10,10))\n",
    "plt.figure(num=None, figsize=(11, 11), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "for v in test_opt.values():\n",
    "    x = 0\n",
    "    labels = []\n",
    "    plt.clf()\n",
    "    for k_,v_ in v['ranges'].items(): \n",
    "        #print(k_)\n",
    "        value = v_\n",
    "\n",
    "        y = np.mean(value)\n",
    "        err = max(value)-min(value)\n",
    "        errorbar(x, y, err, marker='s', mfc='red',\n",
    "                 mec='green', ms=2, mew=4,label='in '+str(k_))\n",
    "        x+=1\n",
    "        labels.append(k_)\n",
    "    plt.xticks(np.arange(len(labels)), labels)\n",
    "    ax0[i] = plt\n",
    "\n",
    "    #plt.title(str(v))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "dfs.replace([np.inf, -np.inf], np.nan)\n",
    "dfs = dfs.dropna()\n",
    "\n",
    "#X = dfs[['standard','sp','ss','info_density','gf','standard','uniqueness','info_density','penalty']]\n",
    "X = dfs[['standard','sp','ss']]\n",
    "\n",
    "X = X.as_matrix()\n",
    "#import pdb; pdb.set_trace()\n",
    "\n",
    "est = KMeans(n_clusters=3)\n",
    "\n",
    "est.fit(X)\n",
    "\n",
    "y_kmeans = est.predict(X)\n",
    "centers = est.cluster_centers_\n",
    "\n",
    "fignum = 1\n",
    "fig = plt.figure(fignum, figsize=(4, 3))\n",
    "ax = Axes3D(fig, rect=[0, 0, .95, 1], elev=48, azim=134)\n",
    "ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=y_kmeans, s=50)\n",
    "ax.scatter(centers[:, 0], centers[:, 1], centers[:, 2], c='black', s=200, alpha=0.5);\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "ax.set_xlabel('standard')\n",
    "ax.set_ylabel('subjectivity')\n",
    "ax.set_zlabel('sentiment polarity')\n",
    "#ax.set_title(titles[fignum - 1])\n",
    "#ax.dist = 12\n",
    "fignum = fignum + 1\n",
    "for x,i in enumerate(zip(y_kmeans,dfs['clue_words'])):\n",
    "    try:\n",
    "        print(i[0],i[1],dfs['link'][x],dfs['publication'][x],dfs['clue_links'][x],dfs['sp_norm'][x],dfs['ss_norm'][x],dfs['uniqueness'][x])\n",
    "    except:\n",
    "        print(i)\n",
    "\n",
    "fig.savefig('3dCluster.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the parameter 'd' only seems important\n",
    "# C does not have to be too precise within a range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I consider the final gene populations for each of the eight tests. I compute the variance in each of the converged populations, I see that variance is low in many of the gene populations.\n",
    "\n",
    "When all variables are used to optomize only against one set of parameters, you expect their would be high variance in parameters, that don't matter much with respect to that error criteria (you expect redundancy of solutions).\n",
    "\n",
    "I compute std on errors over all the tests in order to estimate how amenable the problem is to multiobjective optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuronunit.models.reduced import ReducedModel\n",
    "from neuronunit.optimization.model_parameters import model_params, path_params\n",
    "LEMS_MODEL_PATH = path_params['model_path']\n",
    "import quantities as pq\n",
    "plt.figure(num=None, figsize=(11, 11), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "for k,v in test_opt.items():    \n",
    "    model = ReducedModel(LEMS_MODEL_PATH, name= str('vanilla'), backend=('RAW'))\n",
    "    model.attrs = v['out']['pf'][1].dtc.attrs\n",
    "    print(str(k), v['out']['pf'][1].dtc.get_ss())#fitness)\n",
    "    iparams = {}\n",
    "    iparams['injected_square_current'] = {}\n",
    "    iparams['injected_square_current']['amplitude'] =v['out']['pf'][1].rheobase['value']*pq.pA\n",
    "    #['amplitude']  = dtc.vtest[k]['injected_square_current']['amplitude']\n",
    "    DELAY = 100.0*pq.ms\n",
    "    DURATION = 1000.0*pq.ms\n",
    "    iparams['injected_square_current']['delay'] = DELAY\n",
    "    iparams['injected_square_current']['duration'] = int(DURATION)\n",
    "\n",
    "    model.inject_square_current(iparams)\n",
    "\n",
    "    plt.plot(model.get_membrane_potential().times,model.get_membrane_potential(),label=str(k))\n",
    "    plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#print([i.fitness.values for i in test_opt['t'][0]['pop']])#.keys()\n",
    "print(np.std([i[0] for i in test_opt['t'][0]['pop'][0:5]]))#.keys()\n",
    "print(np.std([i[1] for i in test_opt['t'][0]['pop'][0:5]]))#.keys()\n",
    "print(np.std([i[2] for i in test_opt['t'][0]['pop'][0:5]]))#.keys()\n",
    "print(np.std([i[3] for i in test_opt['t'][0]['pop'][0:5]]))#.keys()\n",
    "print(test_opt['t'][0]['pop'][0][0])\n",
    "print(test_opt['t'][0]['pop'][0][1])\n",
    "test_opt['t'][0]['pop'][0].dtc.attrs\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#values = { k:v for v in npcl['pop'][i].dtc.attrs.items() for i in npcl['pop'] }\n",
    "#print(values)    \n",
    "#print(stds.keys())\n",
    "#stds\n",
    "#dtc.variances[k] for k in dtc.attrs.keys() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "DO.seed_pop = npcl['pf'][0:MU]\n",
    "npcl, DO = om.run_ga(explore_param,10,reduced_tests,free_params=free_params,hc = hc, NSGA = False, MU = MU, seed_pop = DO.seed_pop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attrs_here = npcl['hardened'][0][0].attrs\n",
    "attrs_here.update(hc)\n",
    "attrs_here\n",
    "scores = npcl['hof'][0].dtc.scores\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "use_test = test_frame[\"Neocortex pyramidal cell layer 5-6\"]\n",
    "reduced_tests = [use_test[0], use_test[-1], use_test[len(use_test)-1]]\n",
    "bigger_tests = use_test[1:-2]\n",
    "bigger_tests.insert(0,use_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bigger_tests = bigger_tests[-1::]\n",
    "print(bigger_tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DO.seed_pop = npcl['hof'][0:MU]\n",
    "reduced_tests = [use_test[0], use_test[-1], use_test[len(use_test)-1]]\n",
    "npcl, DO = om.run_ga(explore_param,10,bigger_tests,free_params=free_params,hc = hc, NSGA = False, MU = MU)#, seed_pop = DO.seed_pop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(npcl['hardened'][0][0].attrs)\n",
    "print(npcl['hardened'][0][0].scores)\n",
    "print(npcl['pf'][0].fitness.values)\n",
    "print(npcl['hof'][0].dtc.scores)\n",
    "\n",
    "#for t in use_test:\n",
    "#    print(t.name)\n",
    "    \n",
    "    \n",
    "pop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the scores printed above, it looks like certain error criteria, are in conflict with each other.\n",
    "\n",
    "Tests, that are amenable to co-optimization appear to be:\n",
    "* Width test\n",
    "* Input resistance tets\n",
    "* Resting Potential Test,\n",
    "* Capicitance test.\n",
    "* Time constant\n",
    "\n",
    "Tests/criteria that seem in compatible with the above include: \n",
    "* Rheobase, \n",
    "* InjectedCurrentAPThresholdTest\n",
    "* InjectedCurrentAPAmplitudeTest\n",
    "\n",
    "Therefore a reduced set of lists is made to check if the bottom three are at least amenable to optimization togethor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "est = KMeans(n_clusters=2)\n",
    "est.fit(X)\n",
    "y_kmeans = est.predict(X)\n",
    "\n",
    "centers = est.cluster_centers_\n",
    "\n",
    "fig = plt.figure(fignum,figsize=(4,3))\n",
    "ax = Axes3D(fig,rect=[0,0,.95,1],elav=48,azim=134)\n",
    "ax.scatter(X[:,0],X[:,1],X[:,2],c=y_kmeans,s=50),\n",
    "ax.scatter(centres[:,0],centres[:,1],centres[:,2],c='black',s=200,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "print(reduced_tests)\n",
    "print(bigger_tests)\n",
    "\n",
    "DO.seed_pop = npcl['pf'][0:MU]\n",
    "npcl, DO = om.run_ga(explore_param,10,reduced_tests,free_params=free_params,hc = hc, NSGA = True, MU = 12)#, seed_pop = DO.seed_pop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#from neuronunit.optimization.optimization_management import wave_measure\n",
    "from neuronunit.models.reduced import ReducedModel\n",
    "from neuronunit.optimization.model_parameters import model_params, path_params\n",
    "LEMS_MODEL_PATH = path_params['model_path']\n",
    "import neuronunit.optimization as opt\n",
    "import quantities as pq\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "from neuronunit.optimization.data_transport_container import DataTC\n",
    "model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('RAW'))\n",
    "for i in npcl['pf'][0:2]:\n",
    "    iparams = {}\n",
    "    iparams['injected_square_current'] = {}\n",
    "    iparams['injected_square_current']['amplitude'] =i.dtc.rheobase\n",
    "    model = None\n",
    "    model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('RAW'))\n",
    "    model.set_attrs(i.dtc.attrs)\n",
    "\n",
    "    #['amplitude']  = dtc.vtest[k]['injected_square_current']['amplitude']\n",
    "    DELAY = 100.0*pq.ms\n",
    "    DURATION = 1000.0*pq.ms\n",
    "    iparams['injected_square_current']['delay'] = DELAY\n",
    "    iparams['injected_square_current']['duration'] = int(DURATION)\n",
    "    model.inject_square_current(iparams)\n",
    "    n_spikes = len(model.get_spike_train())\n",
    "    if n_spikes:\n",
    "        print(n_spikes)\n",
    "        #print(i[0].scores['RheobaseTestP']*pq.pA)\n",
    "        plt.plot(model.get_membrane_potential().times,model.get_membrane_potential())#,label='ground truth')\n",
    "        plt.legend()\n",
    "\n",
    "#gca().set_axis_off()\n",
    "#subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "#            hspace = 0, wspace = 0)\n",
    "#margins(0,0)\n",
    "#gca().xaxis.set_major_locator(NullLocator())\n",
    "#gca().yaxis.set_major_locator(NullLocator())\n",
    "\n",
    "plt.subplots_adjust(left=0.0, right=1.0, top=0.9, bottom=0.1)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"single_trace.png\", bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot\n",
    "\n",
    "\n",
    "from neuronunit.models.reduced import ReducedModel\n",
    "from neuronunit.optimization.model_parameters import model_params, path_params\n",
    "LEMS_MODEL_PATH = path_params['model_path']\n",
    "import neuronunit.optimization as opt\n",
    "import quantities as pq\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "from neuronunit.optimization.data_transport_container import DataTC\n",
    "for i in npcl['hardened']:\n",
    "    iparams = {}\n",
    "    iparams['injected_square_current'] = {}\n",
    "    iparams['injected_square_current']['amplitude'] = i[0].rheobase\n",
    "    model = None\n",
    "    model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('RAW'))\n",
    "    model.set_attrs(i[0].attrs)\n",
    "\n",
    "    #['amplitude']  = dtc.vtest[k]['injected_square_current']['amplitude']\n",
    "    DELAY = 100.0*pq.ms\n",
    "    DURATION = 1000.0*pq.ms\n",
    "    iparams['injected_square_current']['delay'] = DELAY\n",
    "    iparams['injected_square_current']['duration'] = int(DURATION)\n",
    "    model.inject_square_current(iparams)\n",
    "    n_spikes = len(model.get_spike_train())\n",
    "    if n_spikes:\n",
    "        print(n_spikes)\n",
    "        print(i[0].scores['RheobaseTestP']*pq.pA)\n",
    "        plt.plot(model.get_membrane_potential().times,model.get_membrane_potential())#,label='ground truth')\n",
    "        plt.legend()\n",
    "\n",
    "#gca().set_axis_off()\n",
    "#subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "#            hspace = 0, wspace = 0)\n",
    "#margins(0,0)\n",
    "#gca().xaxis.set_major_locator(NullLocator())\n",
    "#gca().yaxis.set_major_locator(NullLocator())\n",
    "\n",
    "plt.subplots_adjust(left=0.0, right=1.0, top=0.9, bottom=0.1)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"single_trace.png\", bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n",
    "\n",
    "\n",
    "'''\n",
    "hc = {}\n",
    "\n",
    "#free_params = ['c','k']\n",
    "for k,v in explore_param.items():\n",
    "    if k not in free_params:\n",
    "        hc[k] = v\n",
    "constants = npcl['hardened'][0][0].attrs\n",
    "hc.update(constants) \n",
    "npcl, _ = om.run_ga(explore_param,20,test_frame[\"Neocortex pyramidal cell layer 5-6\"],free_params=free_params,hc = hc, NSGA = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "free_params = ['a','b','k']#vt','c','k','d']#,'vt','k','c','C']#,'C'] # this can only be odd numbers.\n",
    "\n",
    "##\n",
    "# Use information that is available\n",
    "##\n",
    "hc = reduced_cells['RS']\n",
    "\n",
    "hc['vr'] = -65.2261863636364\n",
    "\n",
    "hc['vPeak'] = hc['vr'] + 86.364525297619\n",
    "hc['C'] = 89.7960714285714\n",
    "hc.pop('a',0)\n",
    "hc.pop('b',0)\n",
    "hc.pop('k',0)\n",
    "hc.pop('c',0)\n",
    "hc.pop('d',0)\n",
    "        \n",
    "use_test = test_frame[\"Neocortex pyramidal cell layer 5-6\"]\n",
    "DO.seed_pop = npcl['pf']\n",
    "ga_out = DO.run(max_ngen = 15)\n",
    "'''\n",
    "hc = {}\n",
    "\n",
    "free_params = ['C']\n",
    "\n",
    "for k,v in explore_param.items():\n",
    "    if k not in free_params:\n",
    "        hc[k] = v\n",
    "#,'vt','k','c','C']#,'C'] # this can only be odd numbers\n",
    "constants = npcl['hardened'][0][0].attrs\n",
    "hc.update(constants) \n",
    "npcl, _ = om.run_ga(explore_param,20,test_frame[\"Neocortex pyramidal cell layer 5-6\"],free_params=free_params,hc = hc, NSGA = True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas\n",
    "    \n",
    "try:\n",
    "    ne_raw = pandas.read_csv('article_ephys_metadata_curated.csv', delimiter='\\t')\n",
    "    !ls -ltr *.csv\n",
    "except:\n",
    "    !wget https://neuroelectro.org/static/src/article_ephys_metadata_curated.csv\n",
    "    ne_raw = pandas.read_csv('article_ephys_metadata_curated.csv', delimiter='\\t')\n",
    "\n",
    "blah = ne_raw[ne_raw['NeuronName'].str.match('Hippocampus CA1 pyramidal cell')]\n",
    "#ne_raw['NeuronName']\n",
    "#ne_raw['cell\\ capacitance']\n",
    "#blah = ne_raw[ne_raw['NeuronName'].str.match('Hippocampus CA1 pyramidal cell')]\n",
    "\n",
    "print([i for i in blah.columns])\n",
    "#rint(blah['rheobase'])\n",
    "#print(blah)\n",
    "#for i in ne_raw.columns:#['NeuronName']:\n",
    "#    print(i)\n",
    "\n",
    "#ne_raw['NeuronName'][85]\n",
    "#blah = ne_raw[ne_raw['TableID'].str.match('85')]\n",
    "#ne_raw['n'] = 84\n",
    "#here = ne_raw[ne_raw['Index']==85]\n",
    "here = ne_raw[ne_raw['TableID']==18]\n",
    "\n",
    "print(here['rheo_raw'])\n",
    "#!wget https://neuroelectro.org/apica/1/n/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ca1 = ne_raw[ne_raw['NeuronName'].str.match('Hippocampus CA1 pyramidal cell')]\n",
    "ca1['rheo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "test_frame[\"Dentate gyrus basket cell\"][0].observation['std'] = test_frame[\"Dentate gyrus basket cell\"][0].observation['mean']\n",
    "for t in test_frame[\"Dentate gyrus basket cell\"]:\n",
    "    print(t.name)\n",
    "\n",
    "    print(t.observation)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "'''\n",
    "Inibitory Neuron\n",
    "This can't pass the Rheobase test\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from neuronunit.optimization import optimization_management as om\n",
    "import pickle\n",
    "\n",
    "free_params = ['a','vr','b','vt','vPeak','c','k']\n",
    "for k,v in explore_param.items():\n",
    "    if k not in free_params:\n",
    "        hc[k] = v\n",
    "use_test = test_frame[\"Dentate gyrus basket cell\"]\n",
    "bcell, _ = om.run_ga(explore_param,20,use_test,free_params=free_params,hc = hc, NSGA = True, MU = 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "#test_frame[\"Dentate gyrus basket cell\"][0].observation['std'] = test_frame[\"Dentate gyrus basket cell\"][0].observation['mean']\n",
    "for t in test_frame[\"Hippocampus CA1 pyramidal cell\"]:\n",
    "    print(t.name)\n",
    "\n",
    "    print(t.observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "use_test = test_frame[\"Hippocampus CA1 pyramidal cell\"]\n",
    "bcell, _ = om.run_ga(explore_param,20,use_test,free_params=free_params,hc = hc, NSGA = True, MU = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from neuronunit.models.reduced import ReducedModel\n",
    "from neuronunit.optimization.model_parameters import model_params, path_params\n",
    "LEMS_MODEL_PATH = path_params['model_path']\n",
    "import neuronunit.optimization as opt\n",
    "import quantities as pq\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "from neuronunit.optimization.data_transport_container import DataTC\n",
    "for i in bcell['hardened'][0:6]:\n",
    "    iparams = {}\n",
    "    iparams['injected_square_current'] = {}\n",
    "    iparams['injected_square_current']['amplitude'] =i[0].rheobase\n",
    "    model = None\n",
    "    model = ReducedModel(LEMS_MODEL_PATH,name = str('vanilla'),backend = ('RAW'))\n",
    "    model.set_attrs(i[0].attrs)\n",
    "\n",
    "    #['amplitude']  = dtc.vtest[k]['injected_square_current']['amplitude']\n",
    "    DELAY = 100.0*pq.ms\n",
    "    DURATION = 1000.0*pq.ms\n",
    "    iparams['injected_square_current']['delay'] = DELAY\n",
    "    iparams['injected_square_current']['duration'] = int(DURATION)\n",
    "    model.inject_square_current(iparams)\n",
    "    n_spikes = len(model.get_spike_train())\n",
    "    if n_spikes:\n",
    "        print(n_spikes)\n",
    "        print(i[0].scores['RheobaseTestP']*pq.pA)\n",
    "        plt.plot(model.get_membrane_potential().times,model.get_membrane_potential())#,label='ground truth')\n",
    "        plt.legend()\n",
    "\n",
    "#gca().set_axis_off()\n",
    "#subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, \n",
    "#            hspace = 0, wspace = 0)\n",
    "#margins(0,0)\n",
    "#gca().xaxis.set_major_locator(NullLocator())\n",
    "#gca().yaxis.set_major_locator(NullLocator())\n",
    "\n",
    "plt.subplots_adjust(left=0.0, right=1.0, top=0.9, bottom=0.1)\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig.savefig(\"single_trace.png\", bbox_inches = 'tight',\n",
    "    pad_inches = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "use_test = test_frame[\"Hippocampus CA1 pyramidal cell\"]\n",
    "bcell, _ = om.run_ga(explore_param,20,use_test,free_params=free_params,hc = hc, NSGA = True, MU = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This cell is in markdown, but it won't be later.\n",
    "Later optimize a whole heap of cells in a loop.\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "    with open('data_dump.p','rb') as f:\n",
    "        test_opt = pickle.load(f)\n",
    "except:\n",
    "    MU = 12\n",
    "    NGEN = 25\n",
    "    cnt = 1\n",
    "    for t in use_test:        \n",
    "        if cnt==len(use_test):\n",
    "            MU = 12\n",
    "            NGEN = 20\n",
    "\n",
    "            npcl, DO = om.run_ga(explore_param,NGEN,[t],free_params=free_params, NSGA = True, MU = MU)\n",
    "        else:\n",
    "\n",
    "            npcl, DO = om.run_ga(explore_param,NGEN,[t],free_params=free_params, NSGA = True, MU = MU)\n",
    "\n",
    "        test_opt[str(t)] =  {'out':npcl}\n",
    "\n",
    "        ranges = {}\n",
    "        stds = npcl['pop'][0].dtc.attrs\n",
    "        for k in npcl['pop'][0].dtc.attrs.keys():    \n",
    "            stds[k] = []\n",
    "            ranges[k] = []\n",
    "\n",
    "\n",
    "        for i in npcl['pop'][::5]:\n",
    "            for k,v in i.dtc.attrs.items():\n",
    "                stds[k].append(v)\n",
    "                ranges[k].append(v)\n",
    "\n",
    "        for k in npcl['pop'][0].dtc.attrs.keys():\n",
    "            ranges[k] = (np.min(ranges[k][1::]),np.max(ranges[k][1::]))\n",
    "\n",
    "            stds[k] = np.std(stds[k][1::])\n",
    "        test_opt[str(t)]['stds'] = stds \n",
    "        test_opt[str(t)]['ranges'] = ranges \n",
    "\n",
    "        cnt+=1\n",
    "    \n",
    "    with open('data_dump.p','wb') as f:\n",
    "        pickle.dump(test_opt,f)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
