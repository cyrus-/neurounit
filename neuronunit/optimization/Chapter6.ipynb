{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AsyncResult: getcwd>\n",
      "{2064: 2, 2065: 3, 2067: 5, 2069: 4, 2070: 7, 2071: 6, 2062: 0, 2063: 1}\n",
      "/home/jovyan/mnt/neuronunit/neuronunit/optimization/../../neuronunit/__init__.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import ipyparallel as ipp\n",
    "from ipyparallel import depend, require, dependent\n",
    "\n",
    "rc = ipp.Client(profile='default');\n",
    "THIS_DIR = os.path.dirname(os.path.realpath('nsga_parallel.py'))\n",
    "this_nu = os.path.join(THIS_DIR,'../../')\n",
    "sys.path.insert(0,this_nu)\n",
    "#from neuronunit import tests\n",
    "#rc[:].use_cloudpickle()\n",
    "inv_pid_map = {}\n",
    "dview = rc[:]\n",
    "# lview = rc.load_balanced_view()\n",
    "ar = rc[:].apply_async(os.getpid)\n",
    "pids = ar.get_dict()\n",
    "inv_pid_map = pids\n",
    "pid_map = {}\n",
    "\n",
    "ar = rc[:].apply_async(os.getcwd)\n",
    "print(ar)\n",
    "\n",
    "# Map PIDs onto unique numeric global identifiers via a dedicated dictionary\n",
    "# The pid map can be used to make file names that are uniquely identify ranks, \n",
    "# in a way that has continuality between sessions\n",
    "# Unlike Process numbers.\n",
    "for k,v in inv_pid_map.items():\n",
    "    pid_map[v] = k\n",
    "print(pid_map)\n",
    "import neuronunit\n",
    "\n",
    "print(neuronunit.__file__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.VirtualModel object at 0x7f45880ffdd8>, <__main__.VirtualModel object at 0x7f45880ffda0>, <__main__.VirtualModel object at 0x7f4588102898>, <__main__.VirtualModel object at 0x7f45881028d0>, <__main__.VirtualModel object at 0x7f4588102908>, <__main__.VirtualModel object at 0x7f4588102940>, <__main__.VirtualModel object at 0x7f4588102978>, <__main__.VirtualModel object at 0x7f45881029b0>]\n",
      "[<__main__.VirtualModel object at 0x7f45880b11d0>, <__main__.VirtualModel object at 0x7f45880b1400>, <__main__.VirtualModel object at 0x7f45880b1080>, <__main__.VirtualModel object at 0x7f4588125da0>, <__main__.VirtualModel object at 0x7f4588125ef0>, <__main__.VirtualModel object at 0x7f45880b15c0>, <__main__.VirtualModel object at 0x7f45880b1780>, <__main__.VirtualModel object at 0x7f45880b1940>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class VirtualModel(object):\n",
    "    '''\n",
    "    This is a pickable dummy clone\n",
    "    version of the NEURON simulation model\n",
    "    It does not contain an actual model, but it can be used to\n",
    "    wrap the real model.\n",
    "    This Object class serves as a data type for storing rheobase search\n",
    "    attributes and other useful parameters,\n",
    "    with the distinction that unlike the NEURON model this class\n",
    "    can be transported across HOSTS/CPUs\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.lookup = {}\n",
    "        self.rheobase = None\n",
    "        self.previous = 0\n",
    "        self.run_number = 0\n",
    "        self.attrs = None\n",
    "        self.steps = None\n",
    "        self.name = None\n",
    "        self.results = None\n",
    "        self.error = None\n",
    "        self.score = None\n",
    "        self.boolean = False\n",
    "        self.init = False\n",
    "\n",
    "dview.push({'VirtualModel':VirtualModel}) # These classes need to be copied to the workers' namespaces.  \n",
    "vmpop = [ VirtualModel() for i in range(0,8) ]\n",
    "print(vmpop)\n",
    "def a(x):\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "returns = list(dview.map_sync(a, vmpop))\n",
    "print(returns)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Rheobase cached data value for from AIBS dataset 354190013\n",
      "{'value': array(130.0) * pA}\n",
      "attempting to recover from pickled file\n",
      "/home/jovyan/mnt/neuronunit/neuronunit/optimization/get_neab.py\n",
      "/home/jovyan/mnt/neuronunit/neuronunit/optimization/utilities.py\n"
     ]
    }
   ],
   "source": [
    "pid_map\n",
    "import get_neab\n",
    "import utilities\n",
    "from utilities import VirtualModel\n",
    "dview.push({'VirtualModel':VirtualModel})\n",
    "print(get_neab.__file__)\n",
    "print(utilities.__file__)\n",
    "#from utilities import print_stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Rheobase cached data value for from AIBS dataset 354190013\n",
      "{'value': array(130.0) * pA}\n",
      "attempting to recover from pickled file\n",
      "/home/jovyan/mnt/neuronunit/neuronunit/optimization/../../neuronunit/__init__.py\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def p_imports():\n",
    "    import os\n",
    "\n",
    "    THIS_DIR = os.path.dirname(os.path.realpath('nsga_parallel.py'))\n",
    "    this_nu = os.path.join(THIS_DIR,'../../')\n",
    "    import sys\n",
    "    sys.path.insert(0,this_nu)\n",
    "    import neuronunit\n",
    "    print(neuronunit.__file__)\n",
    "    import os,sys\n",
    "    \n",
    "import numpy as np\n",
    "import matplotlib as matplotlib\n",
    "matplotlib.use('agg',warn=False)\n",
    "import quantities as pq\n",
    "import sciunit\n",
    "\n",
    "#Over ride any neuron units in the PYTHON_PATH with this one.\n",
    "#only appropriate for development.\n",
    "THIS_DIR = os.path.dirname(os.path.realpath('nsga_parallel.py'))\n",
    "this_nu = os.path.join(THIS_DIR,'../..')\n",
    "sys.path.insert(0,this_nu)\n",
    "\n",
    "import neuronunit\n",
    "from neuronunit import aibs\n",
    "import pdb\n",
    "import pickle\n",
    "try:\n",
    "    IZHIKEVICH_PATH = os.path.join(os.getcwd(),'NeuroML2')\n",
    "    assert os.path.isdir(IZHIKEVICH_PATH)\n",
    "except AssertionError:\n",
    "    # Replace this with the path to your Izhikevich NeuroML2 directory.\n",
    "    IZHIKEVICH_PATH = os.path.join(THIS_DIR,'NeuroML2')\n",
    "\n",
    "LEMS_MODEL_PATH = os.path.join(IZHIKEVICH_PATH,'LEMS_2007One.xml')\n",
    "import time\n",
    "from pyneuroml import pynml\n",
    "import quantities as pq\n",
    "from neuronunit import tests as nu_tests, neuroelectro\n",
    "neuron = {'nlex_id': 'nifext_50'} # Layer V pyramidal cell\n",
    "tests = []\n",
    "\n",
    "dataset_id = 354190013  # Internal ID that AIBS uses for a particular Scnn1a-Tg2-Cre\n",
    "                        # Primary visual area, layer 5 neuron.\n",
    "observation = aibs.get_observation(dataset_id,'rheobase')\n",
    "print(observation)\n",
    "ne_pickle = os.path.join(THIS_DIR,\"neuroelectro.pickle\")\n",
    "\n",
    "if os.path.isfile(ne_pickle):\n",
    "    print('attempting to recover from pickled file')\n",
    "    with open(ne_pickle, 'rb') as f:\n",
    "        tests = pickle.load(f)\n",
    "else:\n",
    "    print('Checked path %s and no pickled file found. Commencing time intensive Download' % ne_pickle)\n",
    "    tests += [nu_tests.RheobaseTest(observation=observation)]\n",
    "    test_class_params = [(nu_tests.InputResistanceTest,None),\n",
    "                         (nu_tests.TimeConstantTest,None),\n",
    "                         (nu_tests.CapacitanceTest,None),\n",
    "                         (nu_tests.RestingPotentialTest,None),\n",
    "                         (nu_tests.InjectedCurrentAPWidthTest,None),\n",
    "                         (nu_tests.InjectedCurrentAPAmplitudeTest,None),\n",
    "                         (nu_tests.InjectedCurrentAPThresholdTest,None)]\n",
    "\n",
    "\n",
    "    for cls,params in test_class_params:\n",
    "        #use of the variable 'neuron' in this conext conflicts with the module name 'neuron'\n",
    "        #at the moment it doesn't seem to matter as neuron is encapsulated in a class, but this could cause problems in the future.\n",
    "        observation = cls.neuroelectro_summary_observation(neuron)\n",
    "        tests += [cls(observation,params=params)]\n",
    "\n",
    "    with open('neuroelectro.pickle', 'wb') as handle:\n",
    "        pickle.dump(tests, handle)\n",
    "def update_amplitude(test,tests,score):\n",
    "    rheobase = score.prediction['value']#first find a value for rheobase\n",
    "    #then proceed with other optimizing other parameters.\n",
    "    #for i in\n",
    "\n",
    "\n",
    "    for i in [tests[-3],tests[-2],tests[-1]]:\n",
    "        # Set current injection to just suprathreshold\n",
    "\n",
    "        i.params['injected_square_current']['amplitude'] = rheobase*1.01\n",
    "#Don't do the rheobase test. This is a serial bottle neck that must occur before any parallel optomization.\n",
    "#Its because the optimization routine must have apriori knowledge of what suprathreshold current injection values are for each model.\n",
    "hooks = {tests[0]:{'f':update_amplitude}} #This is a trick to dynamically insert the method\n",
    "\n",
    "#update amplitude at the location in sciunit thats its passed to, without any loss of generality.\n",
    "suite = sciunit.TestSuite(\"vm_suite\",tests,hooks=hooks)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "dview.apply_sync(p_imports)\n",
    "p_imports()\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing matplotlib on engine(s)\n",
      "importing neuronunit on engine(s)\n",
      "importing model_parameters from neuronunit.optimization on engine(s)\n",
      "importing utilities from neuronunit.optimization on engine(s)\n",
      "importing pdb on engine(s)\n",
      "importing array on engine(s)\n",
      "importing random on engine(s)\n",
      "importing sys on engine(s)\n",
      "importing numpy on engine(s)\n",
      "importing matplotlib.pyplot on engine(s)\n",
      "importing quantities on engine(s)\n",
      "importing algorithms from deap on engine(s)\n",
      "importing base from deap on engine(s)\n",
      "importing diversity,convergence,hypervolume from deap.benchmarks.tools on engine(s)\n",
      "importing creator from deap on engine(s)\n",
      "importing tools from deap on engine(s)\n",
      "importing os on engine(s)\n",
      "importing os.path on engine(s)\n",
      "importing deap on engine(s)\n",
      "importing neuronunit.capabilities on engine(s)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with dview.sync_imports(local=True): # Causes each of these things to be imported on the workers as well as here.\n",
    "    #import get_neab\n",
    "    import matplotlib\n",
    "    import neuronunit\n",
    "    from neuronunit.optimization import model_parameters \n",
    "    from neuronunit.optimization import utilities \n",
    "\n",
    "    matplotlib.use('Agg') # Need to do this before importing neuronunit on a Mac, because OSX backend won't work\n",
    "                          # on the worker threads.\n",
    "    import pdb\n",
    "    import array\n",
    "    import random\n",
    "    import sys\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import quantities as pq\n",
    "    from deap import algorithms\n",
    "    from deap import base\n",
    "    from deap.benchmarks.tools import diversity, convergence, hypervolume\n",
    "    from deap import creator\n",
    "    from deap import tools\n",
    "\n",
    "\n",
    "    import os\n",
    "    import os.path\n",
    "\n",
    "    import deap as deap\n",
    "\n",
    "\n",
    "    import quantities as pq\n",
    "    import neuronunit.capabilities as cap\n",
    "    history = tools.History()\n",
    "    import numpy as np\n",
    "\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def p_imports():\n",
    "    \n",
    "    from neuronunit.models import backends\n",
    "    from neuronunit.models.reduced import ReducedModel\n",
    "    #import get_neab\n",
    "    #new_file_path = str(get_neab.LEMS_MODEL_PATH)+str(int(os.getpid()))\n",
    "    try:\n",
    "        IZHIKEVICH_PATH = os.path.join(os.getcwd(),'NeuroML2')\n",
    "        assert os.path.isdir(IZHIKEVICH_PATH)\n",
    "    except AssertionError:\n",
    "        # Replace this with the path to your Izhikevich NeuroML2 directory.\n",
    "        IZHIKEVICH_PATH = os.path.join(THIS_DIR,'NeuroML2')\n",
    "\n",
    "    LEMS_MODEL_PATH = os.path.join(IZHIKEVICH_PATH,'LEMS_2007One.xml')\n",
    "    new_file_path = str(LEMS_MODEL_PATH)+str(pid_map[int(os.getpid())])\n",
    "    os.system('cp ' + str(LEMS_MODEL_PATH)+str(' ') + new_file_path)\n",
    "    model = ReducedModel(new_file_path,name='vanilla',backend='NEURON')\n",
    "\n",
    "    #model = ReducedModel(get_neab.LEMS_MODEL_PATH,name='vanilla',backend='NEURON')\n",
    "    model.load_model()\n",
    "    #utilities.get_neab = get_neab\n",
    "    #utilities.model = model\n",
    "    return\n",
    "\n",
    "#dview.apply_sync(p_imports)\n",
    "#p_imports()\n",
    "from deap import base\n",
    "from deap import creator\n",
    "toolbox = base.Toolbox()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class Individual(object):\n",
    "    '''\n",
    "    When instanced the object from this class is used as one unit of chromosome or allele by DEAP.\n",
    "    Extends list via polymorphism.\n",
    "    '''\n",
    "    def __init__(self, *args):\n",
    "        list.__init__(self, *args)\n",
    "        self.error=None\n",
    "        self.results=None\n",
    "        self.name=''\n",
    "        self.attrs = {}\n",
    "        self.params=None\n",
    "        self.score=None\n",
    "        self.fitness=None\n",
    "        self.lookup={}\n",
    "        self.rheobase=None\n",
    "        self.fitness = creator.FitnessMin\n",
    "dview.push({'Individual':Individual})\n",
    "with dview.sync_imports():\n",
    "    #import utilities\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "print('hi?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def p_imports():\n",
    "\n",
    "    #import utilities\n",
    "    toolbox = base.Toolbox()\n",
    "    from neuronunit.optimization import model_parameters \n",
    "\n",
    "    #from neuronunit.optimization import model_parameters as modelp\n",
    "    import numpy as np\n",
    "    #from neuronunit.tests import utilities as outils\n",
    "    BOUND_LOW = [ np.min(i) for i in model_parameters.model_params.values() ]\n",
    "    BOUND_UP = [ np.max(i) for i in model_parameters.model_params.values() ]\n",
    "    NDIM = len(BOUND_UP)\n",
    "    def uniform(low, up, size=None):\n",
    "        try:\n",
    "            return [random.uniform(a, b) for a, b in zip(low, up)]\n",
    "        except TypeError:\n",
    "            return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0, -1.0, -1.0, -1.0, -1.0, -1.0, -1.0))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "    toolbox.register(\"attr_float\", uniform, BOUND_LOW, BOUND_UP, NDIM)\n",
    "    toolbox.register(\"Individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.Individual)\n",
    "    toolbox.register(\"select\", tools.selNSGA2)\n",
    "    return\n",
    "    #model = outils.model\n",
    "dview.apply_sync(p_imports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO test tests with just the standard model. Ie why do some still return 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[RheobaseTest,\n",
       " InputResistanceTest,\n",
       " TimeConstantTest,\n",
       " CapacitanceTest,\n",
       " RestingPotentialTest,\n",
       " InjectedCurrentAPWidthTest,\n",
       " InjectedCurrentAPAmplitudeTest,\n",
       " InjectedCurrentAPThresholdTest]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignoring included LEMS file: Cells.xml\n",
      "Ignoring included LEMS file: Networks.xml\n",
      "Ignoring included LEMS file: Simulation.xml\n",
      "Mechanisms already loaded from path: /home/jovyan/mnt/neuronunit/neuronunit/optimization/NeuroML2.  Aborting.\n",
      "Ignoring included LEMS file: Cells.xml\n",
      "Ignoring included LEMS file: Networks.xml\n",
      "Ignoring included LEMS file: Simulation.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "vanilla"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuronunit.models import backends\n",
    "from neuronunit.models.reduced import ReducedModel\n",
    "\n",
    "new_file_path = str(get_neab.LEMS_MODEL_PATH)+str(int(os.getpid()))\n",
    "os.system('cp ' + str(get_neab.LEMS_MODEL_PATH)+str(' ') + new_file_path)\n",
    "model = ReducedModel(new_file_path,name='vanilla',backend='NEURON')\n",
    "\n",
    "#model = ReducedModel(get_neab.LEMS_MODEL_PATH,name='vanilla',backend='NEURON')\n",
    "model.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'utilities.VirtualModel'>\n",
      "[<__main__.VirtualModel object at 0x7f455da143c8>, <__main__.VirtualModel object at 0x7f455d9eee48>, <__main__.VirtualModel object at 0x7f455d9d9400>, <__main__.VirtualModel object at 0x7f455d9d9278>, <__main__.VirtualModel object at 0x7f455d9d9080>, <__main__.VirtualModel object at 0x7f455d9d9780>, <__main__.VirtualModel object at 0x7f455d9d9048>, <__main__.VirtualModel object at 0x7f455d9d9588>]\n",
      "[<__main__.VirtualModel object at 0x7f455da736d8>, <__main__.VirtualModel object at 0x7f455d7ce5c0>, <__main__.VirtualModel object at 0x7f455d7ce198>, <__main__.VirtualModel object at 0x7f455d7ceb38>, <__main__.VirtualModel object at 0x7f455d7ce978>, <__main__.VirtualModel object at 0x7f455d7cedd8>, <__main__.VirtualModel object at 0x7f455d7e60b8>, <__main__.VirtualModel object at 0x7f455d7ce470>]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_trans_dict(param_dict):\n",
    "    trans_dict = {}\n",
    "    for i,k in enumerate(list(param_dict.keys())):\n",
    "        trans_dict[i]=k\n",
    "    return trans_dict\n",
    "import model_parameters\n",
    "param_dict = model_parameters.model_params\n",
    "\n",
    "vm = VirtualModel\n",
    "dview.push({'VirtualModel':VirtualModel()})\n",
    "\n",
    "print(vm)\n",
    "\n",
    "class VirtualModel(object):\n",
    "    '''\n",
    "    This is a pickable dummy clone\n",
    "    version of the NEURON simulation model\n",
    "    It does not contain an actual model, but it can be used to\n",
    "    wrap the real model.\n",
    "    This Object class serves as a data type for storing rheobase search\n",
    "    attributes and other useful parameters,\n",
    "    with the distinction that unlike the NEURON model this class\n",
    "    can be transported across HOSTS/CPUs\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.lookup = {}\n",
    "        self.rheobase = None\n",
    "        self.previous = 0\n",
    "        self.run_number = 0\n",
    "        self.attrs = None\n",
    "        self.steps = None\n",
    "        self.name = None\n",
    "        self.results = None\n",
    "        self.error = None\n",
    "        self.score = None\n",
    "        self.boolean = False\n",
    "        self.init = False\n",
    "\n",
    "dview.push({'VirtualModel':VirtualModel}) # These classes need to be copied to the workers' namespaces.  \n",
    "vmpop = [ VirtualModel() for i in range(0,8) ]\n",
    "print(vmpop)\n",
    "def a(x):\n",
    "    print(x)\n",
    "    return x\n",
    "\n",
    "returns = list(dview.map_sync(a, vmpop))\n",
    "print(returns)            \n",
    "def update_vm_pop(pop, trans_dict):\n",
    "    '''\n",
    "    inputs a population of genes/alleles, the population size MU, and an optional argument of a rheobase value guess\n",
    "    outputs a population of genes/alleles, a population of individual object shells, ie a pickleable container for gene attributes.\n",
    "    Rationale, not every gene value will result in a model for which rheobase is found, in which case that gene is discarded, however to\n",
    "    compensate for losses in gene population size, more gene samples must be tested for a successful return from a rheobase search.\n",
    "    If the tests return are successful these new sampled individuals are appended to the population, and then their attributes are mapped onto\n",
    "    corresponding virtual model objects.\n",
    "    '''\n",
    "    \n",
    "    vm = VirtualModel()\n",
    "\n",
    "    from itertools import repeat\n",
    "    import numpy as np\n",
    "    import copy\n",
    "    def transform(ind):\n",
    "        vm = VirtualModel()\n",
    "        param_dict={}\n",
    "        for i,j in enumerate(ind):\n",
    "            param_dict[trans_dict[i]] = str(j)\n",
    "        vm.attrs = param_dict\n",
    "        vm.name = vm.attrs\n",
    "        return vm\n",
    "    if len(pop) > 1:\n",
    "        \n",
    "        pop = [toolbox.clone(i) for i in pop ]\n",
    "        vmpop = dview.map_sync(transform, pop)\n",
    "        vmpop = list(copy.copy(vmpop))\n",
    "    else:\n",
    "        vmpop = transform(copy.copy(pop))\n",
    "    return vmpop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#@depend(update_vm_pop,True)\n",
    "def check_rheobase(vmpop,pop=None):\n",
    "    '''\n",
    "    inputs a population of genes/alleles, the population size MU, and an optional argument of a rheobase value guess\n",
    "    outputs a population of genes/alleles, a population of individual object shells, ie a pickleable container for gene attributes.\n",
    "    Rationale, not every gene value will result in a model for which rheobase is found, in which case that gene is discarded, however to\n",
    "    compensate for losses in gene population size, more gene samples must be tested for a successful return from a rheobase search.\n",
    "    If the tests return are successful these new sampled individuals are appended to the population, and then their attributes are mapped onto\n",
    "    corresponding virtual model objects.\n",
    "    '''\n",
    "    def check_fix_range(vms):\n",
    "        '''\n",
    "        Inputs: lookup, A dictionary of previous current injection values\n",
    "        used to search rheobase\n",
    "        Outputs: A boolean to indicate if the correct rheobase current was found\n",
    "        and a dictionary containing the range of values used.\n",
    "        If rheobase was actually found then rather returning a boolean and a dictionary,\n",
    "        instead logical True, and the rheobase current is returned.\n",
    "        given a dictionary of rheobase search values, use that\n",
    "        dictionary as input for a subsequent search.\n",
    "        '''\n",
    "        import pdb\n",
    "        import copy\n",
    "        import numpy as np\n",
    "        import quantities as pq\n",
    "        sub=[]\n",
    "        supra=[]\n",
    "        steps=[]\n",
    "        vms.rheobase=0.0\n",
    "        for k,v in vms.lookup.items():\n",
    "            if v==1:\n",
    "                #A logical flag is returned to indicate that rheobase was found.\n",
    "                vms.rheobase=float(k)\n",
    "                vms.steps = 0.0\n",
    "                vms.boolean = True\n",
    "                return vms\n",
    "            elif v==0:\n",
    "                sub.append(k)\n",
    "            elif v>0:\n",
    "                supra.append(k)\n",
    "\n",
    "        sub=np.array(sub)\n",
    "        supra=np.array(supra)\n",
    "\n",
    "        if len(sub)!=0 and len(supra)!=0:\n",
    "            #this assertion would only be wrong if there was a bug\n",
    "            print(str(bool(sub.max()>supra.min())))\n",
    "            assert not sub.max()>supra.min()\n",
    "        if len(sub) and len(supra):\n",
    "            everything = np.concatenate((sub,supra))\n",
    "\n",
    "            center = np.linspace(sub.max(),supra.min(),7.0)\n",
    "            centerl = list(center)\n",
    "            for i,j in enumerate(centerl):\n",
    "                if i in list(everything):\n",
    "                    np.delete(center,i)\n",
    "                    del centerl[i]\n",
    "            #delete the index\n",
    "            #np.delete(center,np.where(everything is in center))\n",
    "            #make sure that element 4 in a seven element vector\n",
    "            #is exactly half way between sub.max() and supra.min()\n",
    "            center[int(len(center)/2)+1]=(sub.max()+supra.min())/2.0\n",
    "            steps = [ i*pq.pA for i in center ]\n",
    "\n",
    "        elif len(sub):\n",
    "            steps = np.linspace(sub.max(),2*sub.max(),7.0)\n",
    "            np.delete(steps,np.array(sub))\n",
    "            steps = [ i*pq.pA for i in steps ]\n",
    "\n",
    "        elif len(supra):\n",
    "            steps = np.linspace(-2*(supra.min()),supra.min(),7.0)\n",
    "            np.delete(steps,np.array(supra))\n",
    "            steps = [ i*pq.pA for i in steps ]\n",
    "\n",
    "        vms.steps = steps\n",
    "        vms.rheobase = None\n",
    "        return copy.copy(vms)\n",
    "\n",
    "\n",
    "    def check_current(ampl,vm):\n",
    "        '''\n",
    "        Inputs are an amplitude to test and a virtual model\n",
    "        output is an virtual model with an updated dictionary.\n",
    "        '''\n",
    "\n",
    "        global model\n",
    "        import quantities as pq\n",
    "        import get_neab\n",
    "\n",
    "        from neuronunit.models import backends\n",
    "        from neuronunit.models.reduced import ReducedModel\n",
    "\n",
    "        new_file_path = str(get_neab.LEMS_MODEL_PATH)+str(int(os.getpid()))\n",
    "\n",
    "        model = ReducedModel(new_file_path,name=str(vm.attrs),backend='NEURON')\n",
    "        model.load_model()\n",
    "        model.update_run_params(vm.attrs)\n",
    "\n",
    "        DELAY = 100.0*pq.ms\n",
    "        DURATION = 1000.0*pq.ms\n",
    "        params = {'injected_square_current':\n",
    "                  {'amplitude':100.0*pq.pA, 'delay':DELAY, 'duration':DURATION}}\n",
    "\n",
    "\n",
    "        print('print model name {0}'.format(model.name))\n",
    "        if float(ampl) not in vm.lookup or len(vm.lookup)==0:\n",
    "\n",
    "            current = params.copy()['injected_square_current']\n",
    "\n",
    "            uc = {'amplitude':ampl}\n",
    "            current.update(uc)\n",
    "            current = {'injected_square_current':current}\n",
    "            vm.run_number += 1\n",
    "            model.update_run_params(vm.attrs)\n",
    "            model.inject_square_current(current)\n",
    "            vm.previous = ampl\n",
    "            n_spikes = model.get_spike_count()\n",
    "            vm.lookup[float(ampl)] = n_spikes\n",
    "            if n_spikes == 1:\n",
    "                vm.rheobase = float(ampl)\n",
    "                print(type(vm.rheobase))\n",
    "                print('current {0} spikes {1}'.format(vm.rheobase,n_spikes))\n",
    "                vm.name = str('rheobase {0} parameters {1}'.format(str(current),str(model.params)))\n",
    "                return vm\n",
    "\n",
    "            return vm\n",
    "        if float(ampl) in vm.lookup:\n",
    "            return vm\n",
    "\n",
    "    from itertools import repeat\n",
    "    import numpy as np\n",
    "    import copy\n",
    "    import pdb\n",
    "   \n",
    "\n",
    "    def init_vm(vm):\n",
    "        import quantities as pq\n",
    "        import numpy as np\n",
    "        vm.boolean = False\n",
    "        steps = list(np.linspace(-50,200,7.0))\n",
    "        steps_current = [ i*pq.pA for i in steps ]\n",
    "        vm.steps = steps_current\n",
    "        return vm\n",
    "\n",
    "    def find_rheobase(vm):\n",
    "        from neuronunit.models import backends\n",
    "        from neuronunit.models.reduced import ReducedModel\n",
    "        import get_neab\n",
    "        print(pid_map[int(os.getpid())])\n",
    "\n",
    "        new_file_path = str(get_neab.LEMS_MODEL_PATH)+str(os.getpid())\n",
    "        model = ReducedModel(new_file_path,name=str(vm.attrs),backend='NEURON')\n",
    "        #model = ReducedModel(get_neab.LEMS_MODEL_PATH,name=str(vm.attrs),backend='NEURON')\n",
    "        model.load_model()\n",
    "        model.update_run_params(vm.attrs)\n",
    "        cnt = 0\n",
    "        while vm.boolean == False:# and cnt <21:\n",
    "            for step in vm.steps:\n",
    "                vm = check_current(step, vm)#,repeat(vms))\n",
    "                vm = check_fix_range(vm)\n",
    "                cnt+=1\n",
    "        return vm\n",
    "    print(vmpop)\n",
    "    vmpop = dview.map_sync(init_vm,vmpop)\n",
    "    vmpop = list(vmpop)\n",
    "\n",
    "    vmpop = lview.map_sync(find_rheobase,vmpop)\n",
    "    vmpop = list(vmpop)\n",
    "    #if type(pop) is not type(None):\n",
    "    #    vmpop, pop = final_check(vmpop,pop)\n",
    "    return vmpop, pop\n",
    "\n",
    "\n",
    "print('yes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def trivial(vms):#This method must be pickle-able for scoop to work.\n",
    "    '''\n",
    "    Inputs: An individual gene from the population that has compound parameters, and a tuple iterator that\n",
    "    is a virtual model object containing an appropriate parameter set, zipped togethor with an appropriate rheobase\n",
    "    value, that was found in a previous rheobase search.\n",
    "\n",
    "    outputs: a tuple that is a compound error function that NSGA can act on.\n",
    "\n",
    "    Assumes rheobase for each individual virtual model object (vms) has already been found\n",
    "    there should be a check for vms.rheobase, and if not then error.\n",
    "    Inputs a gene and a virtual model object.\n",
    "    outputs are error components.\n",
    "    '''\n",
    "    print('hello')\n",
    "    from neuronunit.models import backends\n",
    "    from neuronunit.models.reduced import ReducedModel\n",
    "    import quantities as pq\n",
    "    import numpy as np\n",
    "    import get_neab\n",
    "\n",
    "    new_file_path = str(get_neab.LEMS_MODEL_PATH)+str(os.getpid())\n",
    "    model = ReducedModel(new_file_path,name=str(vms.attrs),backend='NEURON')\n",
    "    model.load_model()\n",
    "    assert type(vms.rheobase) is not type(None)\n",
    "    DELAY = 100.0*pq.ms\n",
    "    DURATION = 1000.0*pq.ms\n",
    "    AMPLITUDE = 100.0*pq.pA\n",
    "    params = {'injected_square_current':\n",
    "              {'amplitude':AMPLITUDE, 'delay':DELAY, 'duration':DURATION}}\n",
    "\n",
    "    model.update_run_params(vms.attrs)\n",
    "\n",
    "\n",
    "    for k,v in enumerate(get_neab.suite.tests):\n",
    "        if k == 0:\n",
    "            v.prediction = {}\n",
    "            v.prediction['value'] = vms.rheobase * pq.pA\n",
    "        if k == 1 or k == 2 or k == 3:\n",
    "            v.params['injected_square_current']['duration'] = 100 * pq.ms\n",
    "            v.params['injected_square_current']['amplitude'] = -10 *pq.pA\n",
    "            v.params['injected_square_current']['delay'] = 30 * pq.ms\n",
    "\n",
    "    model.update_run_params(vms.attrs)\n",
    "    score = get_neab.suite.judge(model, stop_on_error = False)#, deep_error = True)\n",
    "    vms.score = score\n",
    "    model.run_number+=1\n",
    "    # Run the model, then:\n",
    "    error = []\n",
    "    other_mean = np.mean([i for i in score.sort_key.values.tolist()[0] if type(i) is not type(None)])\n",
    "    for my_score in score.sort_key.values.tolist()[0]:\n",
    "        if isinstance(my_score,sciunit.ErrorScore):\n",
    "            error.append(-100.0)\n",
    "        elif isinstance(my_score,type(None)):\n",
    "            error.append(other_mean)\n",
    "        else:\n",
    "            # The further away from zero the least the error.\n",
    "            # achieve this by going 1/RMS\n",
    "            if my_score == 0:\n",
    "                error.append(-100.0)\n",
    "            else:\n",
    "                error.append(-1.0/np.abs((my_score)))\n",
    "    return error[0],error[1],error[2],error[3],error[4],error[5],error[6],error[7],\n",
    "\n",
    "from neuronunit.optimization import model_parameters\n",
    "BOUND_LOW = [ np.min(i) for i in model_parameters.model_params.values() ]\n",
    "BOUND_UP = [ np.max(i) for i in model_parameters.model_params.values() ]\n",
    "NDIM = len(BOUND_UP)\n",
    "\n",
    "def uniform(low, up, size=None):\n",
    "    try:\n",
    "        return [random.uniform(a, b) for a, b in zip(low, up)]\n",
    "    except TypeError:\n",
    "        return [random.uniform(a, b) for a, b in zip([low] * size, [up] * size)]\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "toolbox.register(\"attr_float\", uniform, BOUND_LOW, BOUND_UP, NDIM)\n",
    "toolbox.register(\"Individual\", tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.Individual)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "\n",
    "toolbox.register(\"mate\", tools.cxSimulatedBinaryBounded, low=BOUND_LOW, up=BOUND_UP, eta=20.0)\n",
    "toolbox.register(\"mutate\", tools.mutPolynomialBounded, low=BOUND_LOW, up=BOUND_UP, eta=20.0, indpb=1.0/NDIM)\n",
    "toolbox.decorate(\"mate\", history.decorator)\n",
    "toolbox.decorate(\"mutate\", history.decorator)\n",
    "toolbox.register(\"select\", tools.selNSGA2)\n",
    "print('yes?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.VirtualModel object at 0x7f455d9ee080>, <__main__.VirtualModel object at 0x7f455da24e80>, <__main__.VirtualModel object at 0x7f455da14358>, <__main__.VirtualModel object at 0x7f455da24400>]\n",
      "<__main__.VirtualModel object at 0x7f455d9ee080>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'init_vm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-e9291c3fcc0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmpop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mvmpop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_sync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheck_rheobase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_vm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvmpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mvmpop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'init_vm'"
     ]
    }
   ],
   "source": [
    "\n",
    "##\n",
    "# Start of the Genetic Algorithm\n",
    "##\n",
    "\n",
    "\n",
    "#NGEN = 3\n",
    "#import numpy as np\n",
    "MU = 4\n",
    "CXPB = 0.9\n",
    "pf = tools.ParetoFront()\n",
    "dview.push({'pf':pf})\n",
    "trans_dict = get_trans_dict(param_dict)\n",
    "td = trans_dict\n",
    "dview.push({'trans_dict':trans_dict,'td':td})\n",
    "\n",
    "#except:\n",
    "pop = toolbox.population(n = MU)\n",
    "pop = [ toolbox.clone(i) for i in pop ]\n",
    "pf.update([toolbox.clone(i) for i in pop])\n",
    "vmpop = update_vm_pop(pop, td)\n",
    "print(vmpop)\n",
    "print(vmpop[0])\n",
    "vmpop = dview.map_sync(init_vm,vmpop)\n",
    "vmpop = list(vmpop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.VirtualModel object at 0x7f455d7e0198>, <__main__.VirtualModel object at 0x7f455d7e08d0>, <__main__.VirtualModel object at 0x7f455d7b3dd8>, <__main__.VirtualModel object at 0x7f455d7e0160>]\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <class '__main__.VirtualModel'>: it's not the same object as __main__.VirtualModel",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-4c38ce880c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvmpop\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcheck_rheobase\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvmpop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'the rheobase value is {0}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrheobase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-19-d4abd8fc365a>\u001b[0m in \u001b[0;36mcheck_rheobase\u001b[1;34m(vmpop, pop)\u001b[0m\n\u001b[0;32m    164\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mvmpop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_sync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_vm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvmpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[0mvmpop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvmpop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36mmap_sync\u001b[1;34m(self, f, *sequences, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"map_sync doesn't take a `block` keyword argument.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'block'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-139>\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, f, *sequences, **kwargs)\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36msync_results\u001b[1;34m(f, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_sync_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_sync_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, f, *sequences, **kwargs)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"must have some sequences to map onto!\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[0mpf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallelFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msync_results\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/remotefunction.py\u001b[0m in \u001b[0;36mmap\u001b[1;34m(self, *sequences)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[0mmismatched\u001b[0m \u001b[0msequence\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mpadded\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \"\"\"\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m__ipp_mapping\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[0m__all__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'remote'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'parallel'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'RemoteFunction'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ParallelFunction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-129>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *sequences, **kwargs)\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/remotefunction.py\u001b[0m in \u001b[0;36msync_view_results\u001b[1;34m(f, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_sync_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_sync_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/remotefunction.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *sequences, **kwargs)\u001b[0m\n\u001b[0;32m    257\u001b[0m             \u001b[0mview\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mbalanced\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtemp_flags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 259\u001b[1;33m                 \u001b[0mar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    260\u001b[0m                 \u001b[0mar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, *args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m         \"\"\"\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_really_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-138>\u001b[0m in \u001b[0;36m_really_apply\u001b[1;34m(self, f, args, kwargs, targets, block, track)\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36msync_results\u001b[1;34m(f, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_sync_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_sync_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-137>\u001b[0m in \u001b[0;36m_really_apply\u001b[1;34m(self, f, args, kwargs, targets, block, track)\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36msave_ids\u001b[1;34m(f, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mn_previous\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mnmsgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_previous\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/view.py\u001b[0m in \u001b[0;36m_really_apply\u001b[1;34m(self, f, args, kwargs, targets, block, track)\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mident\u001b[0m \u001b[1;32min\u001b[0m \u001b[0m_idents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m             future = self.client.send_apply_request(self._socket, f, args, kwargs, track=track,\n\u001b[1;32m--> 557\u001b[1;33m                                     ident=ident)\n\u001b[0m\u001b[0;32m    558\u001b[0m             \u001b[0mfutures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfuture\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/client/client.py\u001b[0m in \u001b[0;36msend_apply_request\u001b[1;34m(self, socket, f, args, kwargs, metadata, track, ident)\u001b[0m\n\u001b[0;32m   1393\u001b[0m         bufs = serialize.pack_apply_message(f, args, kwargs,\n\u001b[0;32m   1394\u001b[0m             \u001b[0mbuffer_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffer_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m             \u001b[0mitem_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem_threshold\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1396\u001b[0m         )\n\u001b[0;32m   1397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/serialize/serialize.py\u001b[0m in \u001b[0;36mpack_apply_message\u001b[1;34m(f, args, kwargs, buffer_threshold, item_threshold)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     arg_bufs = list(chain.from_iterable(\n\u001b[1;32m--> 166\u001b[1;33m         serialize_object(arg, buffer_threshold, item_threshold) for arg in args))\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0mkw_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/serialize/serialize.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     arg_bufs = list(chain.from_iterable(\n\u001b[1;32m--> 166\u001b[1;33m         serialize_object(arg, buffer_threshold, item_threshold) for arg in args))\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m     \u001b[0mkw_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/lib/python3.5/site-packages/ipyparallel/serialize/serialize.py\u001b[0m in \u001b[0;36mserialize_object\u001b[1;34m(obj, buffer_threshold, item_threshold)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[0mbuffers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_extract_buffers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_threshold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0mbuffers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPICKLE_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbuffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <class '__main__.VirtualModel'>: it's not the same object as __main__.VirtualModel"
     ]
    }
   ],
   "source": [
    "vmpop , _= check_rheobase(vmpop)\n",
    "for i in vmpop:\n",
    "    print('the rheobase value is {0}'.format(i.rheobase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fitnesses = list(dview.map_sync(trivial, copy.copy(vmpop) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##\n",
    "# Start of the Genetic Algorithm\n",
    "##\n",
    "\n",
    "\n",
    "#NGEN = 3\n",
    "#import numpy as np\n",
    "MU = 1\n",
    "CXPB = 0.9\n",
    "pf = tools.ParetoFront()\n",
    "dview.push({'pf':pf})\n",
    "trans_dict = get_trans_dict(param_dict)\n",
    "td = trans_dict\n",
    "dview.push({'trans_dict':trans_dict,'td':td})\n",
    "\n",
    "\n",
    "#except:\n",
    "pop = toolbox.population(n = MU)\n",
    "pop = [ toolbox.clone(i) for i in pop ]\n",
    "pf.update([toolbox.clone(i) for i in pop])\n",
    "vmpop = update_vm_pop(pop, td)\n",
    "print(vmpop)\n",
    "vmpop , _= check_rheobase(vmpop)\n",
    "for i in vmpop:\n",
    "    print('the rheobase value is {0}'.format(i.rheobase))\n",
    "\n",
    "fitnesses = list(dview.map_sync(trivial, copy.copy(vmpop) ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in fitnesses:\n",
    "    print('the fitness value is {0}'.format(i))\n",
    "\n",
    "    invalid_ind = [ ind for ind in pop if not ind.fitness.valid ]\n",
    "\n",
    "for gen in range(1, NGEN):\n",
    "\n",
    "\n",
    "    invalid_ind = [ ind for ind in pop if ind.fitness.valid ]\n",
    "    offspring = tools.selTournamentDCD(invalid_ind, len(invalid_ind))\n",
    "    offspring = tools.selNSGA2(pop, len(pop))\n",
    "    assert len(offspring)!=0\n",
    "    offspring = [toolbox.clone(ind) for ind in offspring]\n",
    "    assert len(offspring)!=0\n",
    "    for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() <= CXPB:\n",
    "            toolbox.mate(ind1, ind2)\n",
    "        toolbox.mutate(ind1)\n",
    "        toolbox.mutate(ind2)\n",
    "        del ind1.fitness.values, ind2.fitness.values\n",
    "\n",
    "    invalid_ind = [ ind for ind in offspring if ind.fitness.valid ]\n",
    "    for i in fitnesses:\n",
    "        print('the fitness value is {0}'.format(i))\n",
    "\n",
    "    vmpop = update_vm_pop(offspring, td)\n",
    "    vmpop = check_rheobase(vmpop)\n",
    "    #fitnesses = list(dview.map_sync(evaluate_e, vmpop))\n",
    "    fitnesses = list(dview.map_sync(trivial, vmpop))\n",
    "    for i in fitnesses:\n",
    "        print(i)\n",
    "    pop = apply_fitness(copy.copy(fitnesses),copy.copy(pop))\n",
    "    \n",
    "\n",
    "    checkpoint[gen] = [fitnesses,vmpop,offspring]#,evaluate_e.tests.suite]\n",
    "    import pickle\n",
    "    new_checkpoint_path = str(checkpoint)+str(pid_map[int(os.getpid())])+str('.p')\n",
    "    with open('new_checkpoint_path.p','wb') as handle:\n",
    "        pickle.dump(checkpoint,handle)\n",
    "        #pickle.dump(handle,checkpoint)\n",
    "\n",
    "    for ind, fit in zip(offspring, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "    size_delta = MU-len(offspring)\n",
    "    assert size_delta == 0\n",
    "    pop = toolbox.select(offspring, MU)\n",
    "    print('the pareto front is: {0}'.format(pf))\n",
    "\n",
    "pop,vmpop = list(update_vm_pop(pop,td))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "scores = []\n",
    "for j,i in enumerate(pf):\n",
    "    i.name = vmpop[j].attrs\n",
    "    scores.append(vmpop[j].score)\n",
    "    print(vmpop[j].score)\n",
    "\n",
    "sc = pd.DataFrame(scores[0])\n",
    "sc\n",
    "data = [ pf[0].name ]\n",
    "model_values0 = pd.DataFrame(data)\n",
    "model_values0\n",
    "rhstorage[0]\n",
    "\n",
    "data = [ pf[1].name ]\n",
    "model_values0 = pd.DataFrame(data)\n",
    "model_values0\n",
    "\n",
    "\n",
    "\n",
    "sc1 = pd.DataFrame(scores[1])\n",
    "sc1\n",
    "\n",
    "rhstorage[1]\n",
    "\n",
    "data = [ pf[1].name ]\n",
    "model_values1 = pd.DataFrame(data)\n",
    "model_values1\n",
    "\n",
    "pf[1].name\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    ground_error = pickle.load(open('big_model_evaulated.pickle','rb'))\n",
    "except:\n",
    "    # The exception code is only skeletal, it would not actually work, but its the right principles.\n",
    "    print('{0} it seems the error truth data does not yet exist, lets create it now '.format(str(False)))\n",
    "    ut = \n",
    "    import neuronunit.utilities.Utilities\n",
    "\n",
    "    ground_error = list(dview.map_sync(ut.func2map, ground_truth))\n",
    "    pickle.dump(ground_error,open('big_model_evaulated.pickle','wb'))\n",
    "\n",
    "# ground_error_nsga=list(zip(vmpop,pop,invalid_ind))\n",
    "# pickle.dump(ground_error_nsga,open('nsga_evaulated.pickle','wb'))\n",
    "\n",
    "sum_errors = [ i[0] for i in ground_error ]\n",
    "composite_errors = [ i[1] for i in ground_error ]\n",
    "attrs = [ i[2] for i in ground_error ]\n",
    "rheobase = [ i[3] for i in ground_error ]\n",
    "\n",
    "indexs = [i for i,j in enumerate(sum_errors) if j==np.min(sum_errors) ][0]\n",
    "indexc = [i for i,j in enumerate(composite_errors) if j==np.min(composite_errors) ][0]\n",
    "\n",
    "df_0 = pd.DataFrame([ (k,v,vmpop[0].attrs[k],float(v)-float(vmpop[0].attrs[k])) for k,v in ground_error[indexc][2].items() ])\n",
    "df_1 = pd.DataFrame([ (k,v,vmpop[1].attrs[k],float(v)-float(vmpop[1].attrs[k])) for k,v in ground_error[indexc][2].items() ])\n",
    "\n",
    "\n",
    "df_0\n",
    "\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
