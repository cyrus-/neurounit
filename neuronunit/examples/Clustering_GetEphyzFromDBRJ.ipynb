{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This failed because its saved as python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'multi_objective_izhi.p'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aa6c3b4a49c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mizhi_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multi_objective_izhi.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'multi_objective_izhi.p'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-aa6c3b4a49c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget wget -O ncp_cell_layer_5_6.p https://osf.io/6yba2/download'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'wget -O multi_objective_izhi https://osf.io/3vp8d/download'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mizhi_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multi_objective_izhi.p'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'multi_objective_izhi.p'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "try:\n",
    "    izhi_opt = pickle.load(open('multi_objective_izhi.p','rb')) \n",
    "except:\n",
    "    os.system('wget wget -O ncp_cell_layer_5_6.p https://osf.io/6yba2/download')\n",
    "    os.system('wget -O multi_objective_izhi https://osf.io/3vp8d/download')\n",
    "    izhi_opt = pickle.load(open('multi_objective_izhi.p','rb')) \n",
    "\n",
    "\n",
    "list(izhi_opt.values())[0]['pf'][0].dtc\n",
    "list(izhi_opt.values())[0]['pf'][0].dtc.scores\n",
    "list(izhi_opt.values())[0]['pf'][-1].dtc.scores\n",
    "list(izhi_opt.values())[0]['pf'][2].dtc.scores\n",
    "list(izhi_opt.values())[0]['pf'][1].dtc.scores\n",
    "list(izhi_opt.values())[0]['pf'][1].dtc.vtest\n",
    "list(izhi_opt.values())[0]['pf'][1].dtc.test\n",
    "list(izhi_opt.values())[0]['pf'][1].dtc.tests\n",
    "list(izhi_opt.values())[0]['pf'][1].dtc.tests[0].name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#from manager import ModelManager\n",
    "#from tables import Cells, Model_Waveforms, Models, Cell_Closest_Ephyz_Clusters\n",
    "try:\n",
    "    import manager\n",
    "    reload(manager)\n",
    "    from manager import ModelManager\n",
    "except:\n",
    "    !pip install hdbscan \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!conda install numpy\n",
    "!pip install pandas --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import string \n",
    "from scipy.stats import pearsonr\n",
    "import statsmodels.formula.api as smf\n",
    "import hdbscan\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', 20)\n",
    "from manager import ModelManager\n",
    "mgr = ModelManager()\n",
    "mgr.server.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "protocol_cost = {\n",
    "    'Steady State':       1, # 1s\n",
    "    'Standard':         5*2, # 5 repetitions of 1s SS 1s stim\n",
    "    'Strong':           5*2, # 5 repetitions of 1s SS 1s strong stim\n",
    "    'Input Resistance': 2*2, # 2 levels of 1s SS 1s stim\n",
    "}\n",
    "\n",
    "prop_protocol = {\n",
    "    'AP1Amplitude': 'Standard',\n",
    "    'AP2Amplitude': 'Standard',\n",
    "    'AP12AmplitudeDrop': 'Standard',\n",
    "    'AP12AmplitudeChangePercent': 'Standard',\n",
    "    'AP1SSAmplitudeChange': 'Standard'  ,\n",
    "    \n",
    "    'AP1WidthHalfHeight': 'Standard',\n",
    "    'AP2WidthHalfHeight': 'Standard',\n",
    "    'AP12HalfWidthChangePercent': 'Standard',\n",
    "    \n",
    "    'AP1WidthPeakToTrough': 'Standard',\n",
    "    'AP2WidthPeakToTrough': 'Standard',\n",
    "    \n",
    "    'AP1RateOfChangePeakToTrough': 'Standard',\n",
    "    'AP2RateOfChangePeakToTrough': 'Standard', \n",
    "    'AP12RateOfChangePeakToTroughPercentChange': 'Standard',\n",
    "    \n",
    "    'AP1AHPDepth': 'Standard',\n",
    "    'AP2AHPDepth': 'Standard',\n",
    "    'AP12AHPDepthPercentChange': 'Standard',\n",
    "    \n",
    "    'AP1DelayMean': 'Standard',\n",
    "    'AP2DelayMean': 'Standard',\n",
    "    \n",
    "    'AP1DelaySD': 'Standard',\n",
    "    'AP2DelaySD': 'Standard',\n",
    "    \n",
    "    'AP1DelayMeanStrongStim': 'Strong',\n",
    "    'AP2DelayMeanStrongStim': 'Strong',\n",
    "    \n",
    "    'AP1DelaySDStrongStim': 'Strong',\n",
    "    'AP2DelaySDStrongStim': 'Strong',\n",
    "    \n",
    "    'Burst1ISIMean': 'Standard',\n",
    "    'Burst1ISIMeanStrongStim': 'Strong',\n",
    "    \n",
    "    'Burst1ISISD': 'Standard',\n",
    "    'Burst1ISISDStrongStim': 'Strong',\n",
    "    \n",
    "    'InitialAccommodationMean': 'Standard',\n",
    "    'SSAccommodationMean': 'Standard',\n",
    "    'AccommodationRateToSS': 'Standard',\n",
    "    'AccommodationAtSSMean': 'Standard',\n",
    "    'AccommodationRateMeanAtSS': 'Standard',\n",
    "    \n",
    "    \n",
    "    'ISIMedian': 'Standard',\n",
    "    'ISICV': 'Standard',\n",
    "    'ISIBurstMeanChange': 'Standard',\n",
    "    \n",
    "    'SpikeRateStrongStim': 'Strong',\n",
    "    \n",
    "    'InputResistance': 'Input Resistance',\n",
    "    \n",
    "    'SteadyStateAPs': 'Steady State',\n",
    "}\n",
    "\n",
    "prop_names = [\n",
    "    'AP1Amplitude',\n",
    "    'AP2Amplitude',\n",
    "    'AP12AmplitudeDrop',\n",
    "    'AP12AmplitudeChangePercent',\n",
    "    'AP1SSAmplitudeChange',  \n",
    "    \n",
    "    'AP1WidthHalfHeight',\n",
    "    'AP2WidthHalfHeight',\n",
    "    'AP12HalfWidthChangePercent',\n",
    "    \n",
    "    'AP1WidthPeakToTrough',\n",
    "    'AP2WidthPeakToTrough',\n",
    "    \n",
    "    'AP1RateOfChangePeakToTrough',\n",
    "    'AP2RateOfChangePeakToTrough',    \n",
    "    'AP12RateOfChangePeakToTroughPercentChange',\n",
    "    \n",
    "    'AP1AHPDepth',\n",
    "    'AP2AHPDepth',\n",
    "    'AP12AHPDepthPercentChange',\n",
    "    \n",
    "    'AP1DelayMean',\n",
    "    'AP2DelayMean',\n",
    "    \n",
    "    'AP1DelaySD',\n",
    "    'AP2DelaySD',\n",
    "    \n",
    "    'AP1DelayMeanStrongStim',\n",
    "    'AP2DelayMeanStrongStim',\n",
    "    \n",
    "    'AP1DelaySDStrongStim',\n",
    "    'AP2DelaySDStrongStim',\n",
    "    \n",
    "    'Burst1ISIMean',\n",
    "    'Burst1ISIMeanStrongStim',\n",
    "    \n",
    "    'Burst1ISISD',\n",
    "    'Burst1ISISDStrongStim',\n",
    "    \n",
    "    'InitialAccommodationMean',\n",
    "    'SSAccommodationMean',\n",
    "    'AccommodationRateToSS',\n",
    "    'AccommodationAtSSMean',\n",
    "    'AccommodationRateMeanAtSS',\n",
    "    \n",
    "    \n",
    "    'ISIMedian',\n",
    "    'ISICV',\n",
    "    'ISIBurstMeanChange',\n",
    "    \n",
    "    'SpikeRateStrongStim',\n",
    "    \n",
    "    'InputResistance',\n",
    "    \n",
    "    'SteadyStateAPs',\n",
    "    \n",
    "    'FrequencyPassAbove',\n",
    "    'FrequencyPassBelow',\n",
    "    \n",
    "    'RampFirstSpike',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the remaining cell properties\n",
    "cells = list(Cells\\\n",
    "    .select(Cells,Model_Waveforms.Spikes,Models.Name)\\\n",
    "    .join(Model_Waveforms, on=(Cells.Model_ID == Model_Waveforms.Model_id))\\\n",
    "    .join(Models, on=(Cells.Model_ID == Models.Model_ID))\\\n",
    "    .where((Model_Waveforms.Protocol == \"STEADY_STATE\") & (Model_Waveforms.Variable_Name == \"Voltage\"))\\\n",
    "    .order_by(Cells.Model_ID)\n",
    "    .objects()\n",
    ")\n",
    "\n",
    "props = {}\n",
    "for c, cell in enumerate(cells):\n",
    "    for p, prop in enumerate(prop_names):\n",
    "        if prop not in props:\n",
    "            props[prop] = []\n",
    "        \n",
    "        if prop == 'SteadyStateAPs':\n",
    "            props[prop].append(cell.Spikes)\n",
    "            \n",
    "        else:\n",
    "            props[prop].append(getattr(cell, prop))\n",
    "        \n",
    "df = DataFrame(props, columns = prop_names)\n",
    "\n",
    "model_ids = [c.Model_ID for c in cells]        \n",
    "df.index = model_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['AP1Amplitude'].fillna(0, inplace=True)\n",
    "df['AP2Amplitude'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1SSAmplitudeChange'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1WidthHalfHeight'].fillna(0, inplace=True)\n",
    "df['AP2WidthHalfHeight'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1WidthPeakToTrough'].fillna(0, inplace=True)\n",
    "df['AP2WidthPeakToTrough'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1RateOfChangePeakToTrough'].fillna(0, inplace=True)\n",
    "df['AP2RateOfChangePeakToTrough'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1AHPDepth'].fillna(0, inplace=True)\n",
    "df['AP2AHPDepth'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1DelayMean'].fillna(2000, inplace=True)\n",
    "df['AP2DelayMean'].fillna(2000, inplace=True)\n",
    "\n",
    "df['AP1DelaySD'].fillna(0, inplace=True)\n",
    "df['AP2DelaySD'].fillna(0, inplace=True)\n",
    "\n",
    "df['AP1DelayMeanStrongStim'].fillna(2000, inplace=True)\n",
    "df['AP2DelayMeanStrongStim'].fillna(2000, inplace=True)\n",
    "\n",
    "df['AP1DelaySDStrongStim'].fillna(0, inplace=True)\n",
    "df['AP2DelaySDStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['Burst1ISIMean'].fillna(2000, inplace=True)\n",
    "df['Burst1ISIMeanStrongStim'].fillna(2000, inplace=True)\n",
    "\n",
    "df['Burst1ISISD'].fillna(0, inplace=True)\n",
    "df['Burst1ISISDStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['AccommodationRateMeanAtSS'].fillna(2000, inplace=True)\n",
    "\n",
    "df['ISIMedian'].fillna(2000, inplace=True)\n",
    "\n",
    "df['ISICV'].fillna(0, inplace=True)\n",
    "\n",
    "df['ISIBurstMeanChange'].fillna(0, inplace=True)\n",
    "\n",
    "df['SpikeRateStrongStim'].fillna(0, inplace=True)\n",
    "\n",
    "df['InputResistance'].fillna(df['InputResistance'].mean(), inplace=True)\n",
    "\n",
    "df['FrequencyPassAbove'].fillna(29, inplace=True)\n",
    "df['FrequencyPassBelow'].fillna(143, inplace=True)\n",
    "\n",
    "df['RampFirstSpike'].fillna(5000, inplace=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    \n",
    "    # No APs\n",
    "    if(row['AP1Amplitude'] == 0 and row['AP2Amplitude'] == 0):\n",
    "        df.at[index, 'AP12AmplitudeDrop'] = 0\n",
    "        df.at[index, 'AP12AmplitudeChangePercent'] = 0\n",
    "        df.at[index, 'AP1SSAmplitudeChange'] = 0\n",
    "        df.at[index, 'AP12HalfWidthChangePercent'] = 0\n",
    "        df.at[index, 'AP12RateOfChangePeakToTroughPercentChange'] = 0\n",
    "        df.at[index, 'AP12AHPDepthPercentChange'] = 0\n",
    "        df.at[index, 'InitialAccommodationMean'] = 0\n",
    "        df.at[index, 'SSAccommodationMean'] = 0\n",
    "        df.at[index, 'AccommodationRateToSS'] = 0\n",
    "        df.at[index, 'AccommodationAtSSMean'] = 0\n",
    "        \n",
    "    # Only 1 AP\n",
    "    if(row['AP1Amplitude'] > 0 and row['AP2Amplitude'] == 0):\n",
    "        df.at[index, 'AP12AmplitudeDrop'] = row['AP1Amplitude']\n",
    "        df.at[index, 'AP12AmplitudeChangePercent'] = -100\n",
    "        df.at[index, 'AP12HalfWidthChangePercent'] = -100\n",
    "        df.at[index, 'AP12RateOfChangePeakToTroughPercentChange'] = -100\n",
    "        df.at[index, 'AP12AHPDepthPercentChange'] = -100\n",
    "        df.at[index, 'AccommodationRateToSS'] = -1\n",
    "        df.at[index, 'AccommodationAtSSMean'] = -100\n",
    "    \n",
    "    # 1 AP and no SS APs\n",
    "    if row['AP1SSAmplitudeChange'] == 0 and row['AP1Amplitude'] > 0:\n",
    "        df.at[index, 'AP1SSAmplitudeChange'] = row['AP1Amplitude']\n",
    "            \n",
    "        \n",
    "    if np.isnan(row['AccommodationRateToSS']):\n",
    "        df.at[index, 'AccommodationRateToSS'] = -1\n",
    "        \n",
    "                \n",
    "    if np.isnan(row['AccommodationAtSSMean']):\n",
    "        df.at[index, 'AccommodationAtSSMean'] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_column(col):\n",
    "    # Bi-symmetric log-like transformation, from: \n",
    "    # http://iopscience.iop.org/article/10.1088/0957-0233/24/2/027001/pdf\n",
    "    trans = np.sign(df[col])*np.log(1+np.abs(df[col]*2.302585))\n",
    "    df[col] = trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_trans = df.copy()\n",
    "\n",
    "log_column(\"AP12AmplitudeDrop\")\n",
    "log_column(\"AP12AmplitudeChangePercent\")\n",
    "log_column(\"AP1SSAmplitudeChange\")\n",
    "log_column(\"AP1WidthPeakToTrough\")\n",
    "log_column(\"AP2WidthPeakToTrough\")\n",
    "log_column(\"AP1RateOfChangePeakToTrough\")\n",
    "log_column(\"AP2RateOfChangePeakToTrough\")\n",
    "log_column(\"AP12RateOfChangePeakToTroughPercentChange\")\n",
    "log_column(\"AP12AHPDepthPercentChange\")\n",
    "log_column(\"AP1DelayMean\")\n",
    "log_column(\"AP2DelayMean\")\n",
    "log_column(\"AP1DelayMeanStrongStim\")\n",
    "log_column(\"AP2DelayMeanStrongStim\")\n",
    "log_column(\"Burst1ISIMean\")\n",
    "log_column(\"Burst1ISIMeanStrongStim\")\n",
    "log_column(\"AccommodationRateToSS\")\n",
    "log_column(\"AccommodationRateMeanAtSS\")\n",
    "log_column(\"ISIBurstMeanChange\")\n",
    "log_column(\"SpikeRateStrongStim\")\n",
    "log_column(\"InputResistance\")\n",
    "log_column(\"RampFirstSpike\")\n",
    "log_column(\"ISICV\")\n",
    "log_column(\"FrequencyPassAbove\")\n",
    "log_column(\"FrequencyPassBelow\")\n",
    "\n",
    "log_column(\"ISIMedian\")\n",
    "log_column(\"AP1WidthHalfHeight\")\n",
    "log_column(\"AP2WidthHalfHeight\")\n",
    "log_column(\"AP12HalfWidthChangePercent\")\n",
    "log_column(\"AP1AHPDepth\")\n",
    "log_column(\"AP2AHPDepth\")\n",
    "\n",
    "log_column(\"SteadyStateAPs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_no_trans.to_csv(\"cell-ephyz-raw.csv\")\n",
    "df.to_csv(\"cell-ephyz-transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_all[\"ClusterPath\"] = \"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_path = \"/3/1.0/\"\n",
    "#parent_path = \"/1/1/\"\n",
    "\n",
    "# df = df_all\n",
    "\n",
    "df = df_all[df_all[\"ClusterPath\"].str.startswith(parent_path)]\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/\")]\n",
    "# df = df_all[df_all[\"Root_Cluster\"] == 0]\n",
    "# cluster_level = \"Multi-Spikers\" # 4 clusters\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers\"] == 0] # 4 sub clusters - gain of 20  \n",
    "# cluster_level = \"Multi-Spikers-0\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/0\")]\n",
    "#df = df_all[df_all[\"Multi-Spikers-0\"] == 0] \n",
    "#cluster_level = \"Multi-Spikers-0-0\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/1\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers-0\"] == 1] \n",
    "# cluster_level = \"Multi-Spikers-0-1\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/2\")] # NO MORE SUBCLUSTERS\n",
    "#df = df_all[df_all[\"Multi-Spikers-0\"] == 2] \n",
    "#cluster_level = \"Multi-Spikers-0-2\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/0/3\")] # NO MORE SUBCLUSTERS\n",
    "# df = df_all[df_all[\"Multi-Spikers-0\"] == 3]  \n",
    "# cluster_level = \"Multi-Spikers-0-3\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/2/\")]\n",
    "# df = df_all[df_all[\"Multi-Spikers\"] == 2] # 2 sub clusters - gain of 17\n",
    "# cluster_level = \"Multi-Spikers-2\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/\")]\n",
    "##df = df_all[df_all[\"Multi-Spikers\"] == 1]  # no gains from subclustering\n",
    "##cluster_level = \"Multi-Spikers-1\"\n",
    "\n",
    "# df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/3/\")]\n",
    "##df = df_all[df_all[\"Multi-Spikers\"] == 3]  # No gains from clustering further\n",
    "##cluster_level = \"Multi-Spikers-3\"\n",
    "\n",
    "#df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/0/1/3/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "x = ss.fit_transform(df.loc[:,prop_names].values)\n",
    "x = DataFrame(x,columns=prop_names)\n",
    "print('start dims', len(prop_names))\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(svd_solver='full',n_components=0.95)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "principalDf = DataFrame(data = principalComponents)\n",
    "X = principalDf\n",
    "X.index = df.index\n",
    "print('post-pca dims', len(principalDf.columns))\n",
    "print(X.shape[0],'rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pc = 0\n",
    "#col = \"AP12AmplitudeDrop\"\n",
    "#if col == \"AP12AmplitudeDrop\":\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        if np.abs(pearsonr(X[pc],df[col])[0]) >= 0:\n",
    "            plt.scatter(X[pc],df[col])\n",
    "            plt.title((col + str(pearsonr(X[pc],df[col]))))\n",
    "            plt.show();\n",
    "#             plt.scatter(X[pc],df_non_trans[col])\n",
    "#             plt.show();\n",
    "    except:\n",
    "        print('failed',col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from mpl_toolkits import mplot3d\n",
    "plt.figure(figsize=(15, 7))  \n",
    "plt.axes(projection='3d')\n",
    "plt.plot(X[0],X[1], X[2],'bo')\n",
    "plt.show()\n",
    "\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage  \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "linked = linkage(X, 'ward',optimal_ordering=False)\n",
    "\n",
    "plt.figure(figsize=(15, 7))  \n",
    "dendrogram(linked,  \n",
    "            orientation='top',\n",
    "            distance_sort='acending',\n",
    "            show_leaf_counts=True,\n",
    "            #truncate_mode='lastp',\n",
    "            #p=5,\n",
    "            show_contracted=True,\n",
    "          )\n",
    "plt.ylim(0,160)\n",
    "plt.show()  \n",
    "\n",
    "print(X.shape[0],'items')\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "range_n_clusters = range(2, 8)\n",
    "\n",
    "clusters = []\n",
    "widths = []\n",
    "for n_clusters in range_n_clusters:\n",
    "    from sklearn.cluster import AgglomerativeClustering\n",
    "    #clusterer = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "    clusterer = KMeans(n_clusters=n_clusters)  \n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "    \n",
    "    clusters.append(n_clusters)\n",
    "    widths.append(silhouette_avg)\n",
    "\n",
    "plt.plot(clusters, widths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "i=0\n",
    "comp_names = []\n",
    "for i in range(3):\n",
    "    \n",
    "    prop_r = np.array([stats.pearsonr(X[i],df[col])[0] if stats.pearsonr(X[i],df[col])[1] < 0.001 else 0 for col in df.columns[:-2]])\n",
    "    inds = (-np.abs(prop_r)).argsort()\n",
    "#     plt.plot(range(len(pca.components_[0])), pca.components_[i][inds])\n",
    "#     plt.show()\n",
    "    print(np.array(prop_names)[inds][:5])\n",
    "    print(prop_r[inds][:5])\n",
    "    \n",
    "    name = \"\"\n",
    "    for f in range(3):\n",
    "        name += (\"-\" if prop_r[inds][f] < 0 else \"+\") + prop_names[inds[f]]\n",
    "    comp_names.append(name)\n",
    "    print(name)\n",
    "    print(\"         -----            \")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_cluster_size=10\n",
    "n_clusters=6\n",
    "hide_noise = False\n",
    "remove_noise = False\n",
    "k_means = True\n",
    "\n",
    "X_w_noise = X\n",
    "\n",
    "if remove_noise:\n",
    "    #cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "    X = X[cluster.labels_ != -1]\n",
    "    \n",
    "if k_means:\n",
    "    cluster = KMeans(n_clusters=n_clusters,random_state=1)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "else:\n",
    "    #cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "    cluster.fit_predict(X)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if hide_noise:\n",
    "    ax.scatter(\n",
    "        X[cluster.labels_ != -1][0],\n",
    "        X[cluster.labels_ != -1][1], \n",
    "        X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_[cluster.labels_ != -1], \n",
    "        cmap='rainbow')\n",
    "    \n",
    "else:\n",
    "    ax.scatter(\n",
    "        X[0],\n",
    "        X[1], \n",
    "        X[2], depthshade=False,marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "# ax.set_xlabel(\"AP Onset\")\n",
    "# ax.set_ylabel(\"SS Spike Rate\")\n",
    "# ax.set_zlabel(\"SS Accommodation\")\n",
    "plt.tight_layout()\n",
    "\n",
    "centers = []\n",
    "\n",
    "if k_means:\n",
    "    centers = cluster.cluster_centers_\n",
    "else:\n",
    "    labels = np.unique(cluster.labels_) if not hide_noise else np.unique(cluster.labels_[cluster.labels_ != -1])\n",
    "    \n",
    "    for l in labels:\n",
    "        X_label = X[cluster.labels_ == l]\n",
    "        center = [np.mean(X_label[c]) for c in range(X.shape[1])]\n",
    "        centers.append(center)\n",
    "\n",
    "for i, center in enumerate(centers):\n",
    "    ax.text(center[0],center[1],center[2],string.ascii_uppercase[i],size=20)\n",
    "    \n",
    "plt.show()\n",
    "#%matplotlib inline\n",
    "\n",
    "import collections\n",
    "print(collections.Counter(cluster.labels_))\n",
    "\n",
    "\n",
    "for c, center in enumerate(centers):\n",
    "    dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "    dist_sort_is = dist.argsort()\n",
    "    from pprint import pprint as pp\n",
    "\n",
    "    pp({\"cluster\": c, \n",
    "        \"cells\": X.iloc[dist_sort_is].index[:5], \n",
    "        \"sd\":[\"{:12.2f}\".format(np.std(X.iloc[np.where(cluster.labels_ == c)][pc])) for pc in range(3)],\n",
    "        \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]],\n",
    "       })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib %notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_df = df_no_trans.ix[X.index]\n",
    "\n",
    "display_props = [\"ISIMedian\",\"AccommodationAtSSMean\",\"AP1DelayMeanStrongStim\"]\n",
    "#display_props = [\"AP1DelayMeanStrongStim\",\"ISIMedian\",\"AccommodationAtSSMean\"]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(\n",
    "    source_df[display_props[0]],\n",
    "    source_df[display_props[1]], \n",
    "    source_df[display_props[2]], \n",
    "    depthshade=True,\n",
    "    marker='o', \n",
    "    c=cluster.labels_, \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(display_props[0])\n",
    "ax.set_ylabel(display_props[1])\n",
    "ax.set_zlabel(display_props[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "centers = []\n",
    "sds = []\n",
    "\n",
    "labels = np.unique(cluster.labels_)\n",
    "\n",
    "print(display_props)\n",
    "\n",
    "for i, l in enumerate(labels):\n",
    "    X_label = source_df[cluster.labels_ == l]\n",
    "    center = [np.mean(X_label[prop]) for prop in display_props]\n",
    "    centers.append(center)\n",
    "    \n",
    "    sd = [np.std(X_label[prop]) for prop in display_props]\n",
    "    sds.append(sd)\n",
    "    \n",
    "    ax.text(center[0],center[1],center[2],string.ascii_uppercase[i],size=20)\n",
    "    \n",
    "    print(string.ascii_uppercase[i],[\"{:0.2f}+/-{:0.2f}\".format(centers[i][c],sds[i][c]) for c,_ in enumerate(center)])\n",
    "    \n",
    "    reg = smf.ols('AP1DelayMeanStrongStim~AccommodationAtSSMean+ISIMedian',data=X_label).fit()\n",
    "    print('reg params',reg._results.params)\n",
    "    print('reg p vals',reg._results.pvalues)\n",
    "    print(\"delay v accom\",stats.pearsonr(X_label[\"AP1DelayMeanStrongStim\"],X_label[\"AccommodationAtSSMean\"]))\n",
    "    print(\"delay v isi\",stats.pearsonr(X_label[\"AP1DelayMeanStrongStim\"],X_label[\"ISIMedian\"]))\n",
    "    \n",
    "    \n",
    "plt.show()        \n",
    "\n",
    "#%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir(smf.ols('AP1DelayMeanStrongStim~AccommodationAtSSMean+ISIMedian',data=X_label).fit()._results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comp_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_w_labels = DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X[\"Cluster\"] = cluster.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_w_noise.loc[X.index]['Cluster']#=cluster.labels_\n",
    "\n",
    "for label in X.index:\n",
    "    X_w_noise.at[label, \"Cluster\"] = X.at[label, \"Cluster\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(X_w_noise[\"Cluster\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "           delay       short aps/ISIs       accom    \n",
    "\n",
    "\n",
    "2 ['        1.37', '        1.29', '        2.55'] large accomodotation, mild delay, short aps\n",
    "regular spikers\n",
    "\n",
    "4 ['        2.97', '        1.24', '       -1.17'] delayed, regular spiking, mild accomodating\n",
    "non-accomodating regular spikers\n",
    "\n",
    "\n",
    "\n",
    "0 ['        3.43', '       -2.73', '       -0.49'] delayed, tall APs, long isis\n",
    "slow spikers\n",
    "\n",
    "3 ['       -1.98', '       -2.06', '        0.96'] non delayed, long isis, accommodating\n",
    "rapid onset slow spikers\n",
    "\n",
    "\n",
    "5 ['       -3.69', '        0.71', '        1.40'] rapid onset+accomodation (=burst?), reg? spiking\n",
    "bursters\n",
    "\n",
    "\n",
    "1 ['       -1.90', '        2.06', '       -2.26'] non delayed, non-accomodating, short aps, short isis\n",
    "rapid onset, non-accomodoating, fast spikers\n",
    "\n",
    "\n",
    "\n",
    "within clusters:\n",
    "\n",
    "correlation between \n",
    "\taccom and short ap/isis\n",
    "\tshort ap/isis and ap delay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Cluster\"] = X_w_noise[\"Cluster\"]\n",
    "\n",
    "df[\"ClusterPath\"] = parent_path + df[\"Cluster\"].map(str) + \"/\"\n",
    "\n",
    "for label in df.index:\n",
    "    df_all.at[label, \"ClusterPath\"] = df.at[label, \"ClusterPath\"]\n",
    "    df_all.at[label, \"Cluster\"] = df.at[label, \"Cluster\"]\n",
    "\n",
    "np.unique(df[\"ClusterPath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique(df_all[\"ClusterPath\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cl = 0\n",
    "cluster_rows = X[cluster.labels_ == cl]\n",
    "plt.scatter(cluster_rows[1],cluster_rows[2])\n",
    "plt.show()\n",
    "from scipy import stats\n",
    "def corrfunc(x, y, **kws):\n",
    "    r, p = stats.pearsonr(x, y)\n",
    "    ax = plt.gca()\n",
    "    ax.annotate(\"r = {:.2f}, p = {:.3f}\".format(r,p),\n",
    "                xy=(.1, .9), xycoords=ax.transAxes)\n",
    "    \n",
    "import seaborn as sns\n",
    "g = sns.PairGrid(df_all.ix[cluster_rows.index],vars=[\"ISIMedian\",\"SSAccommodationMean\",\"AccommodationAtSSMean\",\"InitialAccommodationMean\"])\n",
    "g.map_upper(plt.scatter, s=10)\n",
    "g.map_lower(plt.scatter, s=10)\n",
    "g.map_lower(corrfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_rows[cluster_rows[1].min() == cluster_rows[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_records = list(Cells\\\n",
    "    .select(Cells,Model_Waveforms.Spikes,Models.Name)\\\n",
    "    .join(Model_Waveforms, on=(Cells.Model_ID == Model_Waveforms.Model_id))\\\n",
    "    .join(Models, on=(Cells.Model_ID == Models.Model_ID))\\\n",
    "    .where((Model_Waveforms.Protocol == \"STEADY_STATE\") & (Model_Waveforms.Variable_Name == \"Voltage\"))\\\n",
    "    .order_by(Cells.Model_ID)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_all.loc[\"NMLCL001124\"][\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cell_id in df_all.index:\n",
    "    cell = next(cell for cell in cell_records if cell.Model_ID == cell_id)\n",
    "    cell.ClusterPath = df_all.loc[cell_id][\"ClusterPath\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.unique([cell.ClusterPath for cell in cell_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_w_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isimedian ~ delays + accomodations\n",
    "\n",
    "ISIMedian  \n",
    "AP1Amplitude\n",
    "AP2Amplitude\n",
    "\n",
    "AP1DelayMean\n",
    "AP2DelayMean\n",
    "\n",
    "InitialAccommodationMean\n",
    "SSAccommodationMean\n",
    "AccommodationAtSSMean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.pairplot(cl4_raw,vars=[\n",
    "    \"ISIMedian\",\n",
    "\"AP1Amplitude\",\n",
    "\"AP1DelayMean\",\n",
    "\"InitialAccommodationMean\",\n",
    "\"SSAccommodationMean\",\n",
    "\"AccommodationAtSSMean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "smf.ols('AP1DelayMean~InitialAccommodationMean+SSAccommodationMean+AccommodationAtSSMean+ISIMedian',data=cl4_raw).fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(cl4_raw[col])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "cols = [\"ISIMedian\"]\n",
    "\n",
    "for cl in range(6):\n",
    "    print(\"Cluster\", cl)\n",
    "    cl4 = np.where(cluster.labels_ == cl)\n",
    "    cl4_data = X.iloc[cl4]\n",
    "    \n",
    "    cl4_data.columns = [\"PC\" + str(c) for c in cl4_data.columns]\n",
    "    cl4_raw = df_all.loc[cl4_data.index]\n",
    "    \n",
    "    \n",
    "    for col in cols:\n",
    "        plt.scatter(cl4_raw[\"AP1DelayMean\"], cl4_raw[col]); plt.show();\n",
    "        print(\"AP1DelayMean\",col,pearsonr(cl4_raw[\"AP1DelayMean\"], cl4_raw[col]))\n",
    "        print(smf.ols('AP1DelayMean~'+col,data=cl4_raw).fit().summary())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fr._results.params[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "collections.Counter(df_all[\"ClusterPath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_w_noise_clusters = []\n",
    "X_w_noise_cluster_dists = []\n",
    "for row_id in X_w_noise.index:\n",
    "    cl_dists = []\n",
    "    for cl, center in enumerate(cluster.cluster_centers_):\n",
    "        cl_dists.append(euclidean(X_w_noise.loc[row_id], center))\n",
    "    dist_sorted = np.argsort(cl_dists)\n",
    "    X_w_noise_clusters.append(dist_sorted[0:3])\n",
    "    X_w_noise_cluster_dists.append(np.array(cl_dists)[dist_sorted[0:3]])\n",
    "X_w_noise_clusters = np.array(X_w_noise_clusters)\n",
    "X_w_noise_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_w_noise_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "record.Cell_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, cell_id in enumerate(X_w_noise.index):\n",
    "    print(cell_id)\n",
    "    for cli, cl in enumerate(X_w_noise_clusters[i]):\n",
    "        record = Cell_Closest_Ephyz_Clusters()\n",
    "        record.Cell_ID = cell_id\n",
    "        record.Cluster_ID = parent_path + str(cl) + \"/\"\n",
    "        record.Distance = X_w_noise_cluster_dists[i][cli]\n",
    "        record.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from database import NMLDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db = NMLDB()\n",
    "db.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(\n",
    "        X_w_noise[0],\n",
    "        X_w_noise[1], \n",
    "        X_w_noise[2], depthshade=False,marker='o', \n",
    "        c=X_w_noise_clusters[:,0], \n",
    "        cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(comp_names[0])\n",
    "ax.set_ylabel(comp_names[1])\n",
    "ax.set_zlabel(comp_names[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "for i, center in enumerate(cluster.cluster_centers_):\n",
    "    ax.text(center[0],center[1],center[2],str(i),size=20)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "from scipy.stats import pearsonr\n",
    "cols = [\n",
    "\"PC0\",\n",
    "#\"PC0\"\n",
    "]\n",
    "\n",
    "for cl in range(6):\n",
    "    print(\"Cluster\", cl)\n",
    "    cl_ids = np.where(X_w_noise_clusters[:,0] == cl)\n",
    "    cl_data = X_w_noise.iloc[cl_ids]\n",
    "    \n",
    "    cl_data.columns = [\"PC\" + str(c) for c in cl_data.columns]\n",
    "    cl_raw = df_all.loc[cl_data.index]\n",
    "    \n",
    "    \n",
    "    for col in cols:\n",
    "        corr = pearsonr(cl_data[\"PC1\"], cl_data[col])\n",
    "        \n",
    "        #plt.scatter(cl_data[\"PC1\"], cl_data[col]);plt.show();\n",
    "        fr = smf.ols('PC1~'+col,data=cl_data).fit()\n",
    "        print(\"PC1\",col,corr[0],corr[1] < 0.05)\n",
    "        print('coeff',fr._results.params[1])\n",
    "        #print(fr.summary())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import pearsonr\n",
    "y = \"AP1DelayMeanStrongStim\"\n",
    "cols = [\n",
    "\"ISIMedian\",\n",
    "#\"PC0\"\n",
    "]\n",
    "\n",
    "for cl in range(6):\n",
    "    print(\"Cluster\", cl)\n",
    "    cl_ids = np.where(X_w_noise_clusters[:,0] == cl)\n",
    "    cl_data = X_w_noise.iloc[cl_ids]\n",
    "    \n",
    "    cl_data.columns = [\"PC\" + str(c) for c in cl_data.columns]\n",
    "    cl_raw = df_all.loc[cl_data.index]\n",
    "    \n",
    "    \n",
    "    for col in cols:\n",
    "        corr = pearsonr(cl_raw[y], cl_raw[col])\n",
    "        \n",
    "        #%matplotlib inline\n",
    "        #plt.scatter(cl_raw[y], cl_raw[col]);plt.show();\n",
    "        fr = smf.ols(y+'~'+col,data=cl_raw).fit()\n",
    "        print(y,col,corr[0],corr[1] < 0.05)\n",
    "        print('coeff',fr._results.params[1])\n",
    "        #print(fr.summary())\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
