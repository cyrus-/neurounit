{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "consider installing pynn a heavier backend\n",
      "glif python Error\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "result_RAW = pickle.load(open('RAWall_data_tests.p','rb'))\n",
    "result_ADEXP = pickle.load(open('ADEXPall_data_tests.p','rb'))\n",
    "result_RAW = result_RAW['RAW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def result_to_dict(result_ADEXP,result_RAW):\n",
    "    RAW_dtc = {}\n",
    "    ADEXP_dtc = {}\n",
    "    RAW_dtc = {}\n",
    "    try:\n",
    "        RAW_dtc['Cerebellum Purkinje cell'] = result_RAW['purkine']\n",
    "    except:\n",
    "        RAW_dtc['Cerebellum Purkinje cell'] = result_RAW['purkinje']        \n",
    "    RAW_dtc['Olfactory bulb (main) mitral cell'] = result_RAW['olf']\n",
    "    RAW_dtc['Hippocampus CA1 pyramidal cell'] = result_RAW['ca1pyr']\n",
    "    RAW_dtc['Neocortex pyramidal cell layer 5-6'] = result_RAW['neo']\n",
    "    RAW_dtc['Hippocampus CA1 basket cell'] = result_RAW['ca1basket']\n",
    "    ADEXP_dtc = {}\n",
    "    try:\n",
    "        ADEXP_dtc['Cerebellum Purkinje cell'] = [d.dtc for d in result_ADEXP['ADEXP']['purkine']]\n",
    "    except:\n",
    "        ADEXP_dtc['Cerebellum Purkinje cell'] = [d.dtc for d in result_ADEXP['ADEXP']['purkinje']]        \n",
    "    ADEXP_dtc['Olfactory bulb (main) mitral cell'] = [d.dtc for d in result_ADEXP['ADEXP']['olf']]\n",
    "    ADEXP_dtc['Hippocampus CA1 pyramidal cell'] = [d.dtc for d in result_ADEXP['ADEXP']['ca1pyr']]\n",
    "    ADEXP_dtc['Neocortex pyramidal cell layer 5-6'] = [d.dtc for d in result_ADEXP['ADEXP']['neo']]\n",
    "    ADEXP_dtc['Hippocampus CA1 basket cell'] = [d.dtc for d in result_ADEXP['ADEXP']['ca1basket']]\n",
    "    return ADEXP_dtc,RAW_dtc\n",
    "\n",
    "ADEXP_dtc,RAW_dtc = result_to_dict(result_ADEXP,result_RAW)\n",
    "\n",
    "#RAW_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell in RAW_dtc.keys():\n",
    "    compare0 = {t.name:t.observation for t in RAW_dtc[cell][0].tests.values() }\n",
    "    compare0 = {k:(v,RAW_dtc[cell][0].predictions[k]) for k,v in compare0.items() }\n",
    "\n",
    "    compare1 = {t.name:t.observation for t in ADEXP_dtc[cell][0].tests.values() }\n",
    "    #print(compare1.keys())\n",
    "    #print(ADEXP_dtc[cell][0].predictions.keys())\n",
    "    compare1 = {k:(v,ADEXP_dtc[cell][0].predictions[k]) for k,v in compare1.items() if k in ADEXP_dtc[cell][0].predictions.keys()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_df = {}\n",
    "try:\n",
    "    import nbimporter\n",
    "except:\n",
    "    !pip install nbimporter\n",
    "    import nbimporter\n",
    "from importlib import reload\n",
    "import chapter1 as chapter1\n",
    "\n",
    "df6 = chapter1.format_nice_frame(compare0)\n",
    "df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7 = chapter1.format_nice_frame(compare1)#compare1\n",
    "df7.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In notebook cells below we compute Druckman and Allen SDK\n",
    "Features on the optimized cells, in order to see if the optimized cells fall into pre-defined clusters, differentally  associated with experimental data, and model output data.\n",
    "\n",
    "To say this another way, it has previously been observed that experimental cell data, and model data, falls into easily seperated categories in feature space. This probably reflects deficits in simple model realism.\n",
    "\n",
    "By using optimized cells as new data points, and plotting their positions in a reduced dimension feature space we will be able to see if optimized models, are more convincing imitations of experimental data, by testing if new data points are harder to seperate from the experimental data.\n",
    "### Get Druckman features using a parallel algorithm to save time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADEXP_dtc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "from neuronunit.optimisation.optimization_management import inject_and_plot, nuunit_dm_evaluation \n",
    "dfeatures={}\n",
    "druckman_feature_coordinatesadexp = {}\n",
    "for k,v in ADEXP_dtc.items():\n",
    "    bagged = db.from_sequence(ADEXP_dtc[k])\n",
    "    druckman_feature_coordinatesadexp[k] = list(bagged.map(nuunit_dm_evaluation).compute())\n",
    "    dfeatures[k] = [d.dm_test_features for d in  druckman_feature_coordinatesadexp[k] ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "druck1 = pd.DataFrame([dfeatures[k]])\n",
    "druck1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "izhidfeatures={}\n",
    "df_container = {}\n",
    "druckman_feature_coordinates_izhi ={}\n",
    "for k,v in RAW_dtc.items():\n",
    "    bagged = db.from_sequence(RAW_dtc[k])\n",
    "    druckman_feature_coordinates_izhi[k] = list(bagged.map(nuunit_dm_evaluation).compute())\n",
    "    izhidfeatures[k] = [d.dm_test_features for d in druckman_feature_coordinates_izhi[k] ]\n",
    "    druck0 = pd.DataFrame([izhidfeatures[k][0]])\n",
    "    druck0 = druck0.rename(index={0: str('Izhikivitch')})\n",
    "    druck1 = dfeatures[k]\n",
    "    druck1 = druck1.rename(index={0: str('ADEXP')})\n",
    "    \n",
    "    #druck4 = pd.DataFrame([izhidfeatures[k][-1]])\n",
    "    #druck4 = druck4.rename(index={0: str('Izhi_last')})\n",
    "    #druck3 = pd.DataFrame([dfeatures[k][-1]])\n",
    "    #druck3 = druck3.rename(index={0: str('ADEXP_last')})\n",
    "    #druck2 = druck1\n",
    "    druck2 = druck1.append(druck0)\n",
    "    #druck2 = druck2.append(druck3)\n",
    "    #druck2 = druck2.append(druck4)\n",
    "    df_container[k] = druck2\n",
    "df_container[k]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "import numpy as np\n",
    "# Open the 1.5x rheobase file\n",
    "filename = os.path.join(cwd,'onefive_df.pkl')\n",
    "with open(filename, 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    \n",
    "df.iloc[0][192:195]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RAW_dtc = [d.dtc for d in RAW[k]]\n",
    "\n",
    "from neuronunit.optimisation.optimization_management import just_allen_predictions\n",
    "RAW_dtc = [d.dtc for d in RAW[k]]\n",
    "RAW_dtc[0].protocols[1].keys()\n",
    "\n",
    "RAW_dtc[0].ampl = RAW_dtc[0].protocols[1]['injected_square_current']['amplitude']*1.5\n",
    "RAW_dtc[0].ampl\n",
    "#for i in RAW_dtc:\n",
    "    \n",
    "def cell_to_allen(dtc):    \n",
    "    dtc.pre_obs = None\n",
    "    dtc.ampl = dtc.protocols[1]['injected_square_current']['amplitude']*3.0\n",
    "    dtc = just_allen_predictions(dtc)\n",
    "    return dtc\n",
    "bagged = db.from_sequence(RAW_dtc)\n",
    "RAW_dtc = list(bagged.map(cell_to_allen).compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = RAW_dtc[1][0].preds\n",
    "RAW_dtc[1][0].preds.pop('spikes',None)\n",
    "preds = {k:v['mean'] for k,v in RAW_dtc[1][0].preds.items()}\n",
    "preds\n",
    "allen_df = pd.DataFrame([preds])\n",
    "allen_df.T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
