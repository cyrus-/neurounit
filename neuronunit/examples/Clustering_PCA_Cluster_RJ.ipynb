{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: sklearn in /opt/conda/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: scikit-learn in /opt/conda/envs/python2/lib/python2.7/site-packages (from sklearn)\n",
      "Requirement already up-to-date: numpy>=1.8.2 in /opt/conda/envs/python2/lib/python2.7/site-packages (from scikit-learn->sklearn)\n",
      "Requirement already up-to-date: scipy>=0.13.3 in /opt/conda/envs/python2/lib/python2.7/site-packages (from scikit-learn->sklearn)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: numpy in /opt/conda/envs/python2/lib/python2.7/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already up-to-date: pandas in /opt/conda/envs/python2/lib/python2.7/site-packages\n",
      "Requirement already up-to-date: python-dateutil>=2.5.0 in /opt/conda/envs/python2/lib/python2.7/site-packages (from pandas)\n",
      "Requirement already up-to-date: pytz>=2011k in /opt/conda/envs/python2/lib/python2.7/site-packages (from pandas)\n",
      "Requirement already up-to-date: numpy>=1.12.0 in /opt/conda/envs/python2/lib/python2.7/site-packages (from pandas)\n",
      "Requirement already up-to-date: six>=1.5 in /opt/conda/envs/python2/lib/python2.7/site-packages (from python-dateutil>=2.5.0->pandas)\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bfailed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - reinstall\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/linux-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/free/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/free/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/pro/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/pro/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn --upgrade\n",
    "!pip install numpy --upgrade\n",
    "!pip install pandas --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCache entry deserialization failed, entry ignored\u001b[0m\n",
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/f3/413bab4ff08e1fc4828dfc59996d721917df8e8583ea85385d51125dceff/pip-19.0.3-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 170kB/s ta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 9.0.1\n",
      "    Uninstalling pip-9.0.1:\n",
      "      Successfully uninstalled pip-9.0.1\n",
      "Successfully installed pip-19.0.3\n",
      "Solving environment: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bfailed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - reinstall\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/conda-forge/linux-64\n",
      "  - https://conda.anaconda.org/conda-forge/noarch\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/free/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/free/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "  - https://repo.anaconda.com/pkgs/pro/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/pro/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install pip --upgrade\n",
    "\n",
    "!conda install numpy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing required dependencies ['numpy']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-18da6b0643af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/opt/conda/envs/python2/lib/python2.7/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     raise ImportError(\n\u001b[1;32m---> 19\u001b[1;33m         \"Missing required dependencies {0}\".format(missing_dependencies))\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mdel\u001b[0m \u001b[0mhard_dependencies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdependency\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmissing_dependencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing required dependencies ['numpy']"
     ]
    }
   ],
   "source": [
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import pandas\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import string \n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "import hdbscan\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "pandas.set_option('display.max_columns', None)\n",
    "pandas.set_option('display.max_rows', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read raw and bi-symmetric log transformed values\n",
    "df_no_trans = pandas.read_csv(\"cell-ephyz-raw.csv\")\n",
    "df_all =      pandas.read_csv(\"cell-ephyz-transformed.csv\")\n",
    "\n",
    "#Set index to be the model ID\n",
    "df_no_trans.set_index('Unnamed: 0', inplace=True)\n",
    "df_all.set_index('Unnamed: 0', inplace=True)\n",
    "df_no_trans.index.name = df_all.index.name = \"Cell_ID\"\n",
    "\n",
    "#create default cluster path\n",
    "df_all[\"ClusterPath\"] = \"/\"\n",
    "df_all[\"Cluster\"] = -1\n",
    "df_all[\"WasNoise\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prop_names = [\n",
    "    'AP1Amplitude',\n",
    "    'AP2Amplitude',\n",
    "    'AP12AmplitudeDrop',\n",
    "    'AP12AmplitudeChangePercent',\n",
    "    'AP1SSAmplitudeChange',  \n",
    "    \n",
    "    'AP1WidthHalfHeight',\n",
    "    'AP2WidthHalfHeight',\n",
    "    'AP12HalfWidthChangePercent',\n",
    "    \n",
    "    'AP1WidthPeakToTrough',\n",
    "    'AP2WidthPeakToTrough',\n",
    "    \n",
    "    'AP1RateOfChangePeakToTrough',\n",
    "    'AP2RateOfChangePeakToTrough',    \n",
    "    'AP12RateOfChangePeakToTroughPercentChange',\n",
    "    \n",
    "    'AP1AHPDepth',\n",
    "    'AP2AHPDepth',\n",
    "    'AP12AHPDepthPercentChange',\n",
    "    \n",
    "    'AP1DelayMean',\n",
    "    'AP2DelayMean',\n",
    "    \n",
    "    'AP1DelaySD',\n",
    "    'AP2DelaySD',\n",
    "    \n",
    "    'AP1DelayMeanStrongStim',\n",
    "    'AP2DelayMeanStrongStim',\n",
    "    \n",
    "    'AP1DelaySDStrongStim',\n",
    "    'AP2DelaySDStrongStim',\n",
    "    \n",
    "    'Burst1ISIMean',\n",
    "    'Burst1ISIMeanStrongStim',\n",
    "    \n",
    "    'Burst1ISISD',\n",
    "    'Burst1ISISDStrongStim',\n",
    "    \n",
    "    'InitialAccommodationMean',\n",
    "    'SSAccommodationMean',\n",
    "    'AccommodationRateToSS',\n",
    "    'AccommodationAtSSMean',\n",
    "    'AccommodationRateMeanAtSS',\n",
    "    \n",
    "    \n",
    "    'ISIMedian',\n",
    "    'ISICV',\n",
    "    'ISIBurstMeanChange',\n",
    "    \n",
    "    'SpikeRateStrongStim',\n",
    "    \n",
    "    'InputResistance',\n",
    "    \n",
    "    'SteadyStateAPs',\n",
    "    \n",
    "    'FrequencyPassAbove',\n",
    "    'FrequencyPassBelow',\n",
    "    \n",
    "    'RampFirstSpike',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def PCA_and_Cluster(parent_path = \"/\", \n",
    "                    hide_noise = False, \n",
    "                    remove_noise = False, \n",
    "                    k_means = False, \n",
    "                    interactive=False,\n",
    "                    cluster_captions=string.ascii_uppercase,\n",
    "                    axis_captions=['PC0','PC1','PC2']):\n",
    "    \n",
    "    min_cluster_size=10 # IF k_means == False:\n",
    "    kmeans_n_clusters=6        # IF k_means == True\n",
    "\n",
    "    #Subselect rows based on selected cluster\n",
    "    df = df_all[df_all[\"ClusterPath\"].str.startswith(parent_path)]\n",
    "\n",
    "    # Perform PCA\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    ss = StandardScaler()\n",
    "    x = ss.fit_transform(df.loc[:,prop_names].values)\n",
    "    x = DataFrame(x,columns=prop_names)\n",
    "    print('start dims', len(prop_names))\n",
    "    from sklearn.decomposition import PCA\n",
    "    pca = PCA(svd_solver='full',n_components=0.95)\n",
    "    principalComponents = pca.fit_transform(x)\n",
    "    principalDf = DataFrame(data = principalComponents)\n",
    "    X = principalDf\n",
    "    X.index = df.index\n",
    "    print('post-pca dims', len(principalDf.columns))\n",
    "    print(X.shape[0],'rows')\n",
    "\n",
    "\n",
    "    #Exploratory cluster analysis of the PCA space - 3D plot, dendrogram, and silhouette analysis\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "    #%matplotlib inline\n",
    "    from mpl_toolkits import mplot3d\n",
    "    plt.figure(figsize=(15, 7))  \n",
    "    plt.axes(projection='3d')\n",
    "    plt.plot(X[0],X[1], X[2],'bo')\n",
    "    plt.show()\n",
    "\n",
    "    print(X.shape[0],'items')\n",
    "\n",
    "    from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "    import numpy as np\n",
    "\n",
    "    range_n_clusters = range(2, 8)\n",
    "\n",
    "    clusters = []\n",
    "    widths = []\n",
    "    for n_clusters in range_n_clusters:\n",
    "        from sklearn.cluster import AgglomerativeClustering\n",
    "        #clusterer = AgglomerativeClustering(n_clusters=n_clusters, affinity='euclidean', linkage='ward')  \n",
    "        clusterer = KMeans(n_clusters=n_clusters)  \n",
    "        cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "        silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "        print(\"For n_clusters =\", n_clusters,\n",
    "              \"The average silhouette_score is :\", silhouette_avg)\n",
    "\n",
    "        # Compute the silhouette scores for each sample\n",
    "        sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "        y_lower = 10\n",
    "        for i in range(n_clusters):\n",
    "            ith_cluster_silhouette_values = \\\n",
    "                sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "            ith_cluster_silhouette_values.sort()\n",
    "\n",
    "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "            y_upper = y_lower + size_cluster_i\n",
    "\n",
    "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "\n",
    "        clusters.append(n_clusters)\n",
    "        widths.append(silhouette_avg)\n",
    "\n",
    "    plt.plot(clusters, widths)\n",
    "    plt.show()\n",
    "\n",
    "    # Find the properties that are most highly correlated with the first 3 PCA components\n",
    "\n",
    "    %matplotlib inline\n",
    "    i=0\n",
    "    comp_names = []\n",
    "    for i in range(3):\n",
    "\n",
    "        prop_r = np.array([stats.pearsonr(X[i],df[col])[0] if stats.pearsonr(X[i],df[col])[1] < 0.001 else 0 for col in df.columns[:-3]])\n",
    "        inds = (-np.abs(prop_r)).argsort()\n",
    "    #     plt.plot(range(len(pca.components_[0])), pca.components_[i][inds])\n",
    "    #     plt.show()\n",
    "        print(np.array(prop_names)[inds][:5])\n",
    "        print(prop_r[inds][:5])\n",
    "\n",
    "        name = \"\"\n",
    "        for f in range(3):\n",
    "            name += (\"-\" if prop_r[inds][f] < 0 else \"+\") + prop_names[inds[f]]\n",
    "        comp_names.append(name)\n",
    "        print(name)\n",
    "        print(\"         -----            \")\n",
    "    \n",
    "\n",
    "    if interactive:\n",
    "        %matplotlib notebook\n",
    "        %matplotlib notebook\n",
    "\n",
    "\n",
    "    # 3D plot of clusters in PCA space\n",
    "    X_w_noise = X.copy()\n",
    "    X_w_noise[\"Cluster\"] = -1\n",
    "    X_w_noise[\"WasNoise\"] = False\n",
    "\n",
    "    if remove_noise:\n",
    "        cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "        cluster.fit_predict(X)\n",
    "        X = X[cluster.labels_ != -1]\n",
    "\n",
    "    if k_means:\n",
    "        cluster = KMeans(n_clusters=kmeans_n_clusters,random_state=1)\n",
    "        cluster.fit_predict(X)\n",
    "\n",
    "    else:\n",
    "        cluster = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size)\n",
    "        cluster.fit_predict(X)\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    if hide_noise:\n",
    "        ax.scatter(\n",
    "            X[cluster.labels_ != -1][0],\n",
    "            X[cluster.labels_ != -1][1], \n",
    "            X[cluster.labels_ != -1][2], depthshade=False,marker='o', \n",
    "            c=cluster.labels_[cluster.labels_ != -1], \n",
    "            cmap='rainbow')\n",
    "\n",
    "    else:\n",
    "        ax.scatter(\n",
    "            X[0],\n",
    "            X[1], \n",
    "            X[2], depthshade=False,marker='o', \n",
    "            c=cluster.labels_, \n",
    "            cmap='rainbow')\n",
    "\n",
    "    ax.set_xlabel(axis_captions[0])\n",
    "    ax.set_ylabel(axis_captions[1])\n",
    "    ax.set_zlabel(axis_captions[2])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    centers = []\n",
    "\n",
    "    if k_means:\n",
    "        centers = cluster.cluster_centers_\n",
    "    else:\n",
    "        labels = np.unique(cluster.labels_) if not hide_noise else np.unique(cluster.labels_[cluster.labels_ != -1])\n",
    "\n",
    "        for l in labels:\n",
    "            X_label = X[cluster.labels_ == l]\n",
    "            center = [np.mean(X_label[c]) for c in range(X.shape[1])]\n",
    "            centers.append(center)\n",
    "\n",
    "    pca_centers = centers\n",
    "            \n",
    "    # Show clusters as letters in the plot\n",
    "    for i, center in enumerate(centers):\n",
    "        ax.text(center[0],center[1],center[2],cluster_captions[i],size=20)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    for key in locals().keys():\n",
    "        globals()[key] = locals()[key]\n",
    "\n",
    "    import collections\n",
    "    print(collections.Counter(cluster.labels_))\n",
    "\n",
    "    # Print cluster summary stats\n",
    "    for c, center in enumerate(centers):\n",
    "        dist = np.apply_along_axis(euclidean, 1, X, center)\n",
    "        dist_sort_is = dist.argsort()\n",
    "        from pprint import pprint as pp\n",
    "\n",
    "        pp({\"cluster\": c, \n",
    "            \"cells\": X.iloc[dist_sort_is].index[:5], \n",
    "            \"sd\":[\"{:12.2f}\".format(np.std(X.iloc[np.where(cluster.labels_ == c)][pc])) for pc in range(3)],\n",
    "            \"center\":[\"{:12.2f}\".format(c) for c in center[0:3]],\n",
    "           })\n",
    "\n",
    "    # 3D plot of clusters in RAW feature space\n",
    "    source_df = df_no_trans.ix[X.index]\n",
    "\n",
    "    display_props = [\"ISIMedian\",\"AccommodationAtSSMean\",\"AP1DelayMeanStrongStim\"]\n",
    "    #display_props = [\"AP1DelayMeanStrongStim\",\"ISIMedian\",\"AccommodationAtSSMean\"]\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    ax.scatter(\n",
    "        source_df[display_props[0]],\n",
    "        source_df[display_props[1]], \n",
    "        source_df[display_props[2]], \n",
    "        depthshade=True,\n",
    "        marker='o', \n",
    "        c=cluster.labels_, \n",
    "        cmap='rainbow')\n",
    "\n",
    "    ax.set_xlabel(display_props[0])\n",
    "    ax.set_ylabel(display_props[1])\n",
    "    ax.set_zlabel(display_props[2])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    centers = []\n",
    "    sds = []\n",
    "\n",
    "    labels = np.unique(cluster.labels_)\n",
    "\n",
    "    print(display_props)\n",
    "\n",
    "    for i, l in enumerate(labels):\n",
    "        X_label = source_df[cluster.labels_ == l]\n",
    "        center = [np.mean(X_label[prop]) for prop in display_props]\n",
    "        centers.append(center)\n",
    "\n",
    "        sd = [np.std(X_label[prop]) for prop in display_props]\n",
    "        sds.append(sd)\n",
    "\n",
    "        ax.text(center[0],center[1],center[2],cluster_captions[i],size=20)\n",
    "\n",
    "        print(cluster_captions[i],[\"{:0.2f}+/-{:0.2f}\".format(centers[i][c],sds[i][c]) for c,_ in enumerate(center)])\n",
    "\n",
    "        reg = smf.ols('AP1DelayMeanStrongStim~ISIMedian',data=X_label).fit()\n",
    "        print('reg isi v delay params p-s r', reg._results.params, reg._results.pvalues, reg._results.rsquared_adj)\n",
    "\n",
    "        reg = smf.ols('AP1DelayMeanStrongStim~AccommodationAtSSMean',data=X_label).fit()\n",
    "        print('reg accom v delay params p-s r', reg._results.params, reg._results.pvalues, reg._results.rsquared_adj)\n",
    "        \n",
    "        print(\"delay v accom\",stats.pearsonr(X_label[\"AP1DelayMeanStrongStim\"],X_label[\"AccommodationAtSSMean\"]))\n",
    "        print(\"delay v isi\",stats.pearsonr(X_label[\"AP1DelayMeanStrongStim\"],X_label[\"ISIMedian\"]))\n",
    "\n",
    "\n",
    "    plt.show()        \n",
    "\n",
    "    #%matplotlib inline\n",
    "\n",
    "\n",
    "    # Set cluster ids in the transformed DataFrame\n",
    "    X[\"Cluster\"] = cluster.labels_\n",
    "\n",
    "    # Set cluster in the DF that also has any noise rows\n",
    "    for label in X.index:\n",
    "        X_w_noise.at[label, \"Cluster\"] = X.at[label, \"Cluster\"]    \n",
    "\n",
    "    # Assign noise models to the cluster with the closest center\n",
    "    noise_models = X_w_noise[X_w_noise[\"Cluster\"] == -1].index\n",
    "    for model in noise_models:    \n",
    "        #find the closest pca space cluster center\n",
    "        dist = np.apply_along_axis(euclidean, 1, pca_centers, X_w_noise.ix[model][:-2])\n",
    "        dist_sort_is = dist.argsort()\n",
    "        X_w_noise.at[model, \"Cluster\"] = dist_sort_is[0] #[0] stores the closest cluster ID\n",
    "        X_w_noise.at[model, \"WasNoise\"] = True\n",
    "\n",
    "    df[\"Cluster\"] = X_w_noise[\"Cluster\"]\n",
    "    df[\"WasNoise\"] = X_w_noise[\"WasNoise\"]\n",
    "    df[\"ClusterPath\"] = parent_path + df[\"Cluster\"].map(str) + \"/\"\n",
    "    \n",
    "\n",
    "    for label in df.index:\n",
    "        df_all.at[label, \"ClusterPath\"] = df.at[label, \"ClusterPath\"]\n",
    "        df_all.at[label, \"Cluster\"] = df.at[label, \"Cluster\"]\n",
    "        df_all.at[label, \"WasNoise\"] = df.at[label, \"WasNoise\"]\n",
    "\n",
    "    # Sanity checks\n",
    "    print('current subset clusters',np.unique(df[\"ClusterPath\"]))\n",
    "    print('all clusters',np.unique(df_all[\"ClusterPath\"]))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PCA_and_Cluster(parent_path = \"/\", \n",
    "                hide_noise = True, \n",
    "                remove_noise = False, \n",
    "                k_means = False, \n",
    "                interactive=False,\n",
    "                cluster_captions=['AS','npRB','RA','MS'],\n",
    "                axis_captions=['PC1 ~Delay to 1st AP (StDevs)', 'PC2 ~2nd AP Amplitude Change (StDevs)', 'PC3 ~AP Width (StDevs)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PCA_and_Cluster(parent_path = \"/3/\", \n",
    "                hide_noise = True, \n",
    "                remove_noise = True, \n",
    "                k_means = False, \n",
    "                interactive=False,\n",
    "                cluster_captions=['awMS','rMS'],\n",
    "                axis_captions=['PC1 ~Delay to 1st AP (StDevs)', 'PC2 ~Accommodation (StDevs)', 'PC3 ~AP Width (StDevs)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PCA_and_Cluster(parent_path = \"/3/1/\", \n",
    "                hide_noise = False, \n",
    "                remove_noise = True, \n",
    "                k_means = True, \n",
    "                interactive=False,\n",
    "                cluster_captions=['aFS','dRS','naRS','RS','B','FS'],\n",
    "                axis_captions=['PC1 ~Delay to 1st AP (StDevs)', 'PC2 ~Mean ISI (StDevs)', 'PC3 ~Accommodation (StDevs)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3D plot of clusters in RAW feature space\n",
    "source_df = df_all[df_all[\"ClusterPath\"].str.startswith(\"/3/1/\")]\n",
    "#source_df = source_df[source_df[\"WasNoise\"] == False]\n",
    "clusters = source_df[\"Cluster\"]\n",
    "\n",
    "source_df = df_no_trans.ix[source_df.index]\n",
    "\n",
    "cluster_captions=['aFS','dRS','naRS','RS','B','FS']\n",
    "display_props = [\"ISIMedian\",\"AccommodationAtSSMean\",\"AP1DelayMeanStrongStim\"]\n",
    "#display_props = [\"AP1DelayMeanStrongStim\",\"ISIMedian\",\"AccommodationAtSSMean\"]\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(\n",
    "    source_df[display_props[0]],\n",
    "    source_df[display_props[1]], \n",
    "    source_df[display_props[2]], \n",
    "    depthshade=False,\n",
    "    marker='o', \n",
    "    c=clusters, \n",
    "    cmap='rainbow')\n",
    "\n",
    "ax.set_xlabel(\"Median Interspike Interval (ms)\")\n",
    "ax.set_ylabel(\"Mean Accomodation at Steady State (%)\")\n",
    "ax.set_zlabel(\"Delay to 1st AP (ms)\")\n",
    "\n",
    "ax.set_xlim([0,250])\n",
    "ax.set_ylim([-100,0])\n",
    "ax.set_zlim([0,50])\n",
    "\n",
    "labels = np.unique(clusters)\n",
    "\n",
    "for i, l in enumerate(labels):\n",
    "    X_label = source_df[clusters == l]\n",
    "    center = [np.mean(X_label[prop]) for prop in display_props]\n",
    "    ax.text(center[0],center[1],center[2],cluster_captions[i],size=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_tetrahedron_projection(dim_x = 1, dim_y = 2, invert_x=False):\n",
    "    %matplotlib inline\n",
    "\n",
    "    ax_labels = [\"Median Interspike Interval (ms)\", \n",
    "                 \"Mean Accomodation at Steady State (%)\", \n",
    "                 \"Delay to 1st AP (ms)\"]\n",
    "\n",
    "    fig = plt.figure()#figsize=(12, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax.scatter(\n",
    "        source_df[display_props[dim_x]],\n",
    "        source_df[display_props[dim_y]], \n",
    "        marker='o', \n",
    "        c=clusters, \n",
    "        cmap='rainbow')\n",
    "\n",
    "    ax.set_xlabel(ax_labels[dim_x])\n",
    "    ax.set_ylabel(ax_labels[dim_y])\n",
    "\n",
    "    labels = np.unique(clusters)\n",
    "\n",
    "    for i, l in enumerate(labels):\n",
    "        X_label = source_df[clusters == l]\n",
    "        center = [np.mean(X_label[prop]) for prop in display_props]\n",
    "        ax.text(center[dim_x],center[dim_y],cluster_captions[i],size=12,backgroundcolor=\"#2E917A\",color=\"w\",bbox={'linewidth':0,'alpha':0.75})\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if invert_x:\n",
    "        plt.gca().invert_xaxis()\n",
    "\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_tetrahedron_projection(0,1)\n",
    "plot_tetrahedron_projection(0,2)\n",
    "plot_tetrahedron_projection(1,2,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CLUSTER naRS RELATIONSHIP EXAMPLES\n",
    "#display_props = [\"ISIMedian\",\"AccommodationAtSSMean\",\"AP1DelayMeanStrongStim\"]\n",
    "\n",
    "min_x = source_df.ix[np.where(clusters == 1)][\"AccommodationAtSSMean\"].min()\n",
    "print(source_df[source_df[\"AccommodationAtSSMean\"] == min_x][\"AP1DelayMeanStrongStim\"])\n",
    "\n",
    "max_x = source_df.ix[np.where(clusters == 1)][\"AccommodationAtSSMean\"].max()\n",
    "print(source_df[source_df[\"AccommodationAtSSMean\"] == max_x][\"AP1DelayMeanStrongStim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#CLUSTER dRS RELATIONSHIP EXAMPLES\n",
    "#display_props = [\"ISIMedian\",\"AccommodationAtSSMean\",\"AP1DelayMeanStrongStim\"]\n",
    "\n",
    "min_x = source_df.ix[np.where(clusters == 2)][\"ISIMedian\"].min()\n",
    "print(source_df[source_df[\"ISIMedian\"] == min_x][\"AP1DelayMeanStrongStim\"])\n",
    "\n",
    "max_x = source_df.ix[np.where(clusters == 2)][\"ISIMedian\"].max()\n",
    "print(source_df[source_df[\"ISIMedian\"] == max_x][\"AP1DelayMeanStrongStim\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from manager import ModelManager\n",
    "from tables import Cells, Model_Waveforms, Models\n",
    "\n",
    "import manager\n",
    "reload(manager)\n",
    "mgr = ModelManager()\n",
    "mgr.server.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Update database with cluster assignments\n",
    "cell_records = list(Cells\\\n",
    "    .select(Cells,Model_Waveforms.Spikes,Models.Name)\\\n",
    "    .join(Model_Waveforms, on=(Cells.Model_ID == Model_Waveforms.Model_id))\\\n",
    "    .join(Models, on=(Cells.Model_ID == Models.Model_ID))\\\n",
    "    .where((Model_Waveforms.Protocol == \"STEADY_STATE\") & (Model_Waveforms.Variable_Name == \"Voltage\"))\\\n",
    "    .order_by(Cells.Model_ID)\n",
    ")\n",
    "   \n",
    "for cell_id in df_all.index:\n",
    "    cell = next(cell for cell in cell_records if cell.Model_ID == cell_id)\n",
    "    cell.Ephyz_Cluster_ID = df_all.loc[cell_id][\"ClusterPath\"]\n",
    "    \n",
    "with mgr.server.db.atomic():\n",
    "    for cell_id in df_all.index:\n",
    "        cell = next(cell for cell in cell_records if cell.Model_ID == cell_id)\n",
    "        cell.save()\n",
    "        print(cell_id)\n",
    "    \n",
    "    print('saving...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
