{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10\n",
    "In this chapter we look at:\n",
    "\n",
    "* Grid/Exhaustive search\n",
    "* Previous Chapters\n",
    "\n",
    "In [chapter 1](chapter1.ipynb) (a closely related notebook see hyperlink) We look at optimization outputs that came from an optimization using spike waveform shape. \n",
    "\n",
    "In [chapter 2](chapter2.ipynb) (a closely related notebook see hyperlink) I demonstrate optimization using spike time statistics via the allen SDK Chapter 2\n",
    "\n",
    "In [chapter 3](chapter3.ipynb) (a closely related notebook see hyperlink) We will take a closer at the neuroelectro data used to perform the fits in notebook1/Chapter 1. Specifically we will look at where optimized model behavior fits back onto the distribution of neuroelectro data.\n",
    "\n",
    "In [chapter 5](chapter5.ipynb) (a closely related notebook see hyperlink) We will look at projections of Optimized cells onto a Druckman feature space, we will also look at extracting Allen SDK features from the optimized cells. Chapter 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([0],[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a very simple example below. The OptMan class is instanced and used to perform simple optimization jobs including:\n",
    "Exhaustive Search, running a genetic algorithm (nsga3), or round trip testing with simulated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'mint_generic_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-05354228bed4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mallensdk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mephys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_cell_features\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mextract_cell_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuronunit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization_management\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptMan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTSD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuronunit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuronunit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_parameters\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMODEL_PARAMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/safe2/neuronunit/neuronunit/optimisation/optimization_management.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuronunit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSciUnitOptimisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuronunit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplottools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minject_and_plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneuronunit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSciUnitOptimisation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/safe2/neuronunit/neuronunit/plottools.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbs4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mJavascript\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneuronunit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimisation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimization_management\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmint_generic_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0mKERNEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'ipykernel'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabc\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'mint_generic_model'"
     ]
    }
   ],
   "source": [
    "\n",
    "%%capture\n",
    "from allensdk.ephys.extract_cell_features import extract_cell_features\n",
    "import pickle\n",
    "from neuronunit.optimisation.optimization_management import OptMan, TSD\n",
    "from neuronunit.optimisation import model_parameters\n",
    "from neuronunit.optimisation.model_parameters import MODEL_PARAMS\n",
    "import pandas as pd\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TSD' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-661cd5927a0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mtest_frame\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobs_frame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlocal_tests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_frame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Hippocampus CA1 pyramidal cell'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mlocal_tests\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTSD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_tests\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mlocal_tests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_rheobase_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TSD' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "electro_path = str(os.getcwd())+'/../tests/russell_tests.p'\n",
    "\n",
    "assert os.path.isfile(electro_path) == True\n",
    "with open(electro_path,'rb') as f:\n",
    "    (test_frame,obs_frame) = pickle.load(f)\n",
    "local_tests = test_frame['Hippocampus CA1 pyramidal cell']\n",
    "local_tests = TSD(local_tests)\n",
    "local_tests.use_rheobase_score = True    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Hogkin Huxley model\n",
    "* via brian2/neural dynamics codes as a backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.models.backends import bhh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture\n",
    "free_params=['gK','gNa','ENa','C']\n",
    "import copy\n",
    "for f in free_params:\n",
    "    hold_constant = copy.copy(MODEL_PARAMS['BHH'])\n",
    "    hold_constant.pop(f,'None')\n",
    "\n",
    "    OM = OptMan(local_tests,backend=str('BHH'),\\\n",
    "        boundary_dict=MODEL_PARAMS['BHH'],\\\n",
    "        protocol={'elephant':True,'allen':False,'dm':False},hc=hold_constant)#'tsr':spk_range})\n",
    "\n",
    "ga_results = OM.optimize(free_params=['gK','gNa','ENa','C'],MU=4,NGEN=4)#,hold_constant=hold_constant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronunit.plottools import inject_and_plot\n",
    "\n",
    "from collections.abc import Iterable\n",
    "import seaborn as sns\n",
    "from neuronunit.optimisation.optimization_management import mint_generic_model\n",
    "from neuronunit.tests.base import AMPL, DELAY, DURATION\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "\n",
    "dtcpop = [d.dtc for d in ga_results['pf']]\n",
    "dtcpop = inject_and_plot(dtcpop)\n",
    "vm_pop = [d.vm for d in dtcpop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%capture#\n",
    "free_params=['b','C','peak_v']\n",
    "import copy\n",
    "for f in free_params:\n",
    "    hold_constant = copy.copy(MODEL_PARAMS['ADEXP'])\n",
    "    hold_constant.pop(f,'None')\n",
    "\n",
    "OM = OptMan(local_tests,backend=str('ADEXP'),\\\n",
    "            boundary_dict=MODEL_PARAMS['ADEXP'],\\\n",
    "            protocol={'elephant':True,'allen':False,'dm':False},hc=hold_constant)\n",
    "ga_results = OM.optimize(free_params=['b','C','peak_v'],MU=5,NGEN=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = OM.round_trip_test(local_tests,str('RAW'),MU=1,NGEN=1)#,stds = easy_standards)\n",
    "ga_results['pf'][0].dtc.scores\n",
    "ga_results['pf'][0].dtc.scores_ratio\n",
    "print(ga_results['dtc_pop'][0].scores)\n",
    "local_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# restrict the number of free parameters to 3, to make the grid search computationally tractable.\n",
    "#MODEL_PARAMS['ADEXP']\n",
    "%%timeit grid_results,sorted_pop = OM.run_simple_grid(2,free_params=['b','C','peak_v'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=ga_results['pf'][0].dtc.scores_ratio\n",
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(opt) is not type(None):\n",
    "    print('its {0}, that ga beat grid'.format(opt<grid_results[0].dtc.scores))\n",
    "    grid_results[-1].dtc.scores\n",
    "    len(grid_results)\n",
    "    print(grid_results[-1].dtc.scores_ratio)\n",
    "    print(grid_results[0].dtc.scores_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%%capture\n",
    "%%timeit OM = OptMan(local_tests,backend=str('RAW'),boundary_dict=MODEL_PARAMS['RAW'],protocol={'elephant':True,'allen':False,'dm':False})#'tsr':spk_range})\n",
    "# restrict the number of free parameters to 3, to make the grid search computationally tractable.\n",
    "grid_results,sp = OM.run_simple_grid(5,free_params=['a','b','C'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%%timeit ga_results_izh = OM.optimize(free_params=['a','b','C'],MU=3,NGEN=3)\n",
    "\n",
    "len([ (gr.dtc.scores,gr.dtc.attrs) for gr in grid_results ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[ (gr.dtc.scores,gr.dtc.attrs,gr) for gr in grid_results ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sort this list to find optimal solution from grid search.\n",
    "* Use optimal solution to seed a genetic algorithm.\n",
    "\n",
    "This will be a fast way of showing that the genetic algorithm can find a better solution. Alternatively we could start the GA from scratch, but if the genetic algorithm was not working at all, this would be a faster way to demonstrate it. Since time is short, let us do it the fast way first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_pop = sorted([ (gr.dtc.scores_ratio,gr.dtc.attrs,gr) for gr in grid_results ], key=lambda tup: tup[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ground truth via exhaustive search is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The model implied by parameters: {0}'.format(dtc_pop[0][1]))\n",
    "print('Yields the scores: {0}'.format(dtc_pop[0][2].dtc.scores))\n",
    "print('Yields the ratio scores: {0}'.format(dtc_pop[0][2].dtc.scores_ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now lets create a seed population from the top 10 exhaustive search results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_pop = [d[2] for d in dtc_pop[0:10]]\n",
    "len(dtc_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "%%timeit results = local_tests.optimize(MODEL_PARAMS['RAW'],backend='RAW',protocol={'allen': False, 'elephant': True},\\\n",
    "                               NGEN=len(gene_pop)+len(gene_pop),MU=len(gene_pop)+len(gene_pop), free_params=dtc_pop[0][1].keys(), \\\n",
    "                               seed_pop=gene_pop)\n",
    "#(NGEN = 10, MU=len(gene_pop), seed_pop = gene_pop,backend='RAW',)\n",
    "#[ (gr.dtc.scores,gr.dtc.attrs) for gr in grid_results ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization management classes: \n",
    "* can also do things like round-trip testing (test the simulators internal performance, as if to bench mark itself with simulated neural data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['dtc_pop'][0].scores\n",
    "opt_out = results[0]['dtc_pop'][0].scores_ratio\n",
    "opt_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_out = dtc_pop[0][2].dtc.scores_ratio\n",
    "\n",
    "print('its true that ga beat exhaustive search {0}'.format(opt_out<grid_out))\n",
    "print('its true that ga was no worse than exhaustive search {0}'.format(opt_out==grid_out))\n",
    "\n",
    "print(results[0]['dtc_pop'][0].attrs,'grid best parameters')\n",
    "print(dtc_pop[0][2].dtc.attrs,'grid best parameters')\n",
    "grid_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_out = dtc_pop[0][2].dtc.scores_ratio\n",
    "opt_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_seed = local_tests.optimize(MODEL_PARAMS['RAW'],backend='RAW',protocol={'allen': False, 'elephant': True},\\\n",
    "                               NGEN=len(gene_pop)+len(gene_pop),MU=len(gene_pop)+len(gene_pop),\\\n",
    "                               free_params=dtc_pop[0][1].keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_4 = OM.run_simple_grid(4,free_params=['a','b','c','C'])\n",
    "results_no_seed_4 = local_tests.optimize(MODEL_PARAMS['RAW'],backend='RAW',protocol={'allen': False, 'elephant': True},\\\n",
    "                               NGEN=len(gene_pop)+len(gene_pop),MU=len(gene_pop)+len(gene_pop),\\\n",
    "                               free_params=dtc_pop[0][1].keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_no_seed_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Yields the scores: {0}'.format(results_no_seed_4[0]['pf'][0].dtc.scores))\n",
    "print('Yields the ratio scores: {0}'.format(results_no_seed_4[0]['pf'][0].dtc.scores_ratio))\n",
    "print('The model implied by parameters: {0}'.format(grid_results_4[0][1].dtc.scores_ratio))\n",
    "print('it seems like the optimizer can often beat the grid search but it really depends')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
